<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Discrete notes</title>
    <description>Blog</description>
    <link>https://discrete-notes.github.io/</link>
    <atom:link href="https://discrete-notes.github.io//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Simulation argument II. Edge-labelings on 2-colored trees, and polynomials</title>
        <description>&lt;p&gt;This is the second post of a series that starts 
&lt;a href=&quot;https://discrete-notes.github.io/simulation-1&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/puzzle-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;In the previous post, we saw an overview of the simulation technique. 
In this post, we are going to see a more precise and usable approach, for the case edge 
labelings on 2-colored regular trees.&lt;/p&gt;

&lt;p&gt;The explanation differs a bit from the 
&lt;a href=&quot;https://arxiv.org/abs/1901.02441&quot;&gt;original paper&lt;/a&gt;, 
because we talk about polynomials, whereas they talk about regular expressions. 
This is mainly a vocabulary change, because there is not 
much algebra going on (but it is easier for me to see it this way).&lt;/p&gt;

&lt;h2 id=&quot;arestricted-setting&quot;&gt;A restricted setting&lt;/h2&gt;
&lt;p&gt;Let us describe the special case we are interested in, and why it is relevant.&lt;/p&gt;

&lt;h3 id=&quot;delta-regular-trees&quot;&gt;$\Delta$-regular trees&lt;/h3&gt;

&lt;p&gt;We consider that we are in the middle of a $\Delta$-regular tree. Here “middle”
means that we cannot see the leaves. 
As a consequence, the method works only for the regime below time 
$\Theta(\log n)$, because time $\Omega(\log n)$ you can always see a leaf in a 
$\Delta$-regular tree.
If we can prove a lower bound for this area of the tree, then we
have a lower bound for our problem.&lt;/p&gt;

&lt;h3 id=&quot;bicoloring&quot;&gt; Bicoloring&lt;/h3&gt;
&lt;p&gt;We will consider graphs that are 2-colored (trees are bipartite), and we assume 
that every node knows on which side of the partition it is (black or white). So 
we work on this kind of graph (with omitted port-numbers):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/fig-delta-regulier.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This, in addition to port-numbers, is a powerful way to break symmetry between 
adjacent nodes.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;A &lt;em&gt;white algorithm&lt;/em&gt; for a problem $\Pi$ in $k$ rounds is an algorithm such that, 
after $k$ rounds the white nodes label their edges in a correct way, with 
respect to $\Pi$. 
In such an algorithm, the 
black nodes do not label the edges, they “trust” the white nodes. 
A &lt;em&gt;black algorithm&lt;/em&gt; is defined the same way, but for black nodes.&lt;/p&gt;

&lt;h2 id=&quot;encoding-of-edge-problems&quot;&gt;Encoding of edge problems&lt;/h2&gt;

&lt;h3 id=&quot;using-the-2-coloring&quot;&gt; Using the 2-coloring&lt;/h3&gt;
&lt;p&gt;We consider edge problems defined the following way. 
The multiset of edges adjacent to any vertex should follow some rule, that
depends on the color of the node. 
For example: there are three labels $a,b,c$, the white nodes should either 
have 2 edges labeled with $a$, and the rest with $c$, or 3 edges labeled with 
$a$ and the rest with $b$; and black nodes should have at least one label $a$, 
one label $b$ and one label $c$. (I just made up this example, it’s probably 
silly.)&lt;/p&gt;

&lt;p&gt;Most problems we are usually interested in are defined in general graphs, not in 
bipartite graphs, thus the problem does not refer to a coloring. 
Hence one expects the constraints on white nodes and black nodes to be the same, 
unlike in the example above. 
Actually, it is often useful to make them different (we’ll see that in the two 
next posts).&lt;/p&gt;

&lt;h3 id=&quot;polynomial-point-of-view&quot;&gt; Polynomial point of view&lt;/h3&gt;

&lt;p&gt;We now introduce the polynomial point of view. 
Consider a node $u$ in a graph where the edges are labeled.
We can define the product of the labels of $u$ as a polynomial $M_u$, whose 
variables are the labels of the problem. 
Note that $M_u$ is a monomial: it’s just a product of labels.&lt;/p&gt;

&lt;p&gt;One can now express the toy problem above in terms of two polynomials:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$L_W(a,b,c)=a^2c^{\Delta-2}+a^3b^{\Delta-3}$&lt;/li&gt;
  &lt;li&gt;$L_B(a,b,c)=abc(a+b+c)^{\Delta-3}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We denote $P \subseteq P’$ the fact that the monomials of P are all 
present in $P’$. Then the labeling of $u$ is correct for problem $\Pi$, if and only if, 
$M_u \subseteq L_{C(u)}$, where $C(u)$ is the color of $u$.&lt;/p&gt;

&lt;p&gt;Note that, in our example, all the polynomials we play with have three variables, 
because there are three labels, and that they are homogeneous of degree 
$\Delta$, because every node has $\Delta$ adjacent edges.&lt;/p&gt;

&lt;h2 id=&quot;simulation-step-and-independence&quot;&gt;Simulation step and independence&lt;/h2&gt;

&lt;h3 id=&quot;polynomial-point-of-view-1&quot;&gt; Polynomial point of view&lt;/h3&gt;
&lt;p&gt;In the previous post, we said that the simulation step is basically about having 
a view at distance $T-1$, imagining everything that could appear in the nodes 
at distance $T$, and labeling edges with all the labels that could be correct 
in one of these extensions.&lt;/p&gt;

&lt;p&gt;Now let us restate this in terms of polynomials. 
After the simulation, every edge is labeled with a set of labels, that can be 
transfered to a sum of labels for polynomials. 
Then the polynomial associated with a set labeling at a node $u$ could be for 
example $P_u=(a+b)^3(a+b+c)^4c^{\Delta-7}$ (this polynomial would not be 
possible for our toy language as we will see later).&lt;/p&gt;

&lt;p&gt;Note that the polynomial we get for a set labeling is not a monomial in general, 
but it is factorized.&lt;/p&gt;

&lt;h3 id=&quot;simulation-for-2-colored-trees&quot;&gt;Simulation for 2-colored trees&lt;/h3&gt;
&lt;p&gt;For 2-colored trees we can be more specific in the description of the simulation 
(and actually we will change the simulation outline a bit too).&lt;/p&gt;

&lt;p&gt;We have a white algorithm in time $T$, and we want a black algorithm 
in time $T-1$ (this will be our setting until the end of the post). 
Consider a black node $u$.
The black node $u$ will first imagine all the extensions of its $(T-1)$-view 
into a $(T+1)$-view. 
(Note that we simulate at distance $T+1$ and not just $T$, as stated in the 
previous post.) 
The black node will then simulate the run of its white neighbors with the 
algorithm in time $T$, and gather the set of labels possible for each edge.&lt;/p&gt;

&lt;p&gt;Note that we have fixed the topology to $\Delta$-regular trees, so the only 
thing to imagine for the extension is the port-number assignment.&lt;/p&gt;

&lt;h3 id=&quot;independence&quot;&gt; Independence&lt;/h3&gt;
&lt;p&gt;The key point here is the following: the $T$-view of a white 
neighbour $v$ of $u$ consists of: 
(1) the $(T-1)$-view of $u$, and 
(2) the extension of this view &lt;em&gt;in the direction of $v$&lt;/em&gt;. 
In the following picture, this means that this view includes only the 
black part and the red part.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/fig-simulation-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As a consequence when simulating node $v$, the black node does not need to 
imagine something for the other parts of its imaginary $(T+1)$-view (e.g. the blue 
parts on the figure). 
In other words the labeling of the edge $(u,v)$ comes only from the different 
version of the red part, and is independent of what happens in the blue parts. 
Obviously this independence property is true for every white neighbor of $u$, 
with its “own” extension.&lt;/p&gt;

&lt;h2 id=&quot;two-key-properties&quot;&gt;Two key properties&lt;/h2&gt;

&lt;p&gt;There are two key properties about the set labelings given by the simulation.&lt;/p&gt;

&lt;h3 id=&quot;product-property&quot;&gt;Product property&lt;/h3&gt;
&lt;p&gt;This property is about the neighborhood of the black nodes.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Claim:&lt;/em&gt;
Let $S_1, S_2, …, S_{\Delta}$ be the sets of labels on the edges after the 
simulation step (with an arbitrary order of the edges). Then any tuple of the form
$(s_1, s_2,…, s_{\Delta})$, with $s_i\in S_i$, has to be in the language (for 
the black side).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof:&lt;/em&gt; Suppose it is not the case, and let $(s_1, s_2,…, s_{\Delta})$ be a 
tuple of $S_1, S_2, …, S_{\Delta}$ that is not in the language. 
Then we build an extension such that the $T$-round 
algorithm would label the edges with $(s_1, s_2,…, s_{\Delta})$, which is a 
contradiction with the correctness of the algorithm.
Start with $s_1$. 
If $s_1$ is in $S_1$ it means that there is an extension, in 
the direction of the first edge (in the figure, suppose $(u,v)$ is the first 
edge, then we are talking about the red part), such that the first edge is 
labeled with $s_1$, and we take this extension. 
But, because of the independence property stated above, we can continue with 
$s_2$, and then $s_3$ etc., which leads to the desired structure.&lt;/p&gt;

&lt;p&gt;We can restate this in terms of polynomials.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Product property:&lt;/em&gt;
$P_u \subseteq L_B$.&lt;/p&gt;

&lt;p&gt;This means that every monomial of $P_u$ has to be a monomial of $L_B$, which is
just a reformulation of the claim above.&lt;/p&gt;

&lt;h3 id=&quot;superposition-property&quot;&gt;Superposition property&lt;/h3&gt;

&lt;p&gt;And now a property for the neighborhoods of the white nodes. An important thing 
here is that we are considering the simulation of the black node $u$ only (see 
the subtleties at the end of this post).&lt;/p&gt;

&lt;p&gt;Let a &lt;em&gt;set addition&lt;/em&gt; of two vectors $(s_1,s_2, …s_{\Delta})$ and 
$(s_1’,s_2’, …s_{\Delta}’)$ be $(s_1+s_1’,s_2+s_2’, …s_{\Delta}+s_{\Delta}’)$,
where the addition $s_i+s_i’$ is a set addition, that is if $s_i=s_i’$ then 
$s_i+s_i’=s_i$. 
A superposition of a set of vectors is the set addition of all the vectors.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Claim:&lt;/em&gt;
The set labeling around a white node is the superposition of correct labelings 
for the white language.&lt;/p&gt;

&lt;p&gt;This directly follows from the definition of the simulation.&lt;/p&gt;

&lt;p&gt;In terms of polynomials, I couldn’t find a nice algebraic analogue (one can 
easily find clumsy complicated analogues), so let say that the superposition 
property can be stated the following way.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Superposition property&lt;/em&gt;:
After the simulation, $P_v$ is the superposition of permutations of monomials 
from $P_W$.&lt;/p&gt;

&lt;p&gt;This property is somehow weaker than the first one, but still it’s 
going to be useful in our second example.&lt;/p&gt;

&lt;h2 id=&quot;typical-transformation-step&quot;&gt;Typical transformation step&lt;/h2&gt;

&lt;p&gt;The typical way to prove that one has a transformation from an algorithm in $T$ 
rounds for a problem $\Pi$, to an algorithm in $T-1$ rounds for a problem $\Pi’$,
is the following.&lt;/p&gt;

&lt;p&gt;First make the simulation. 
In our example, the black node $u$ has a polynomial included in 
$(a+b+c)^{\Delta}$. 
But this is a very rough over-approximation, and $P_u$ is probably much smaller. 
Then one can use the two key properties to rule out many labelings and have a 
more precise idea of what $P_u$ is. 
Once this is done, we can go for a simplification step: replace sets of labels by labels. 
If everything works fine you have a labeling that is correct for your problem 
$P’$.&lt;/p&gt;

&lt;h2 id=&quot;subtleties&quot;&gt;Subtleties&lt;/h2&gt;
&lt;p&gt;There are two subtleties that blocked me at some point.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First, in this 2-colored framework, it is not enough to have a general way to 
go from a white T-round algorithm to a black (T-1)-round algorithm, you also 
need to go from a black algorithm to a white algorithm. In some cases, the two 
are very different.&lt;/li&gt;
  &lt;li&gt;Second, one should be careful when talking about the edges that are not 
adjacent to the node we consider. 
For example, in the simulation, the node $u$ computes what 
its white neighbor $v$ would put on an edge $(v,z)$, and we consider it in our 
superposition property.Bbut the edge $(v,z)$ is probably labeled in different 
manner by $z$, and this has to be taken into account in the simplification step.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Indeed &lt;a href=&quot;https://users.ics.aalto.fi/suomela/mm-lb/&quot;&gt;previous lower bound techniques&lt;/a&gt; cannot work in the 2-colored model.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 12 Feb 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///simulation-2</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///simulation-2</guid>
      </item>
    
      <item>
        <title>Simulation argument I. General technique</title>
        <description>&lt;p&gt;As
&lt;a href=&quot;https://discrete-notes.github.io/january-2019-notes&quot;&gt;said earlier&lt;/a&gt; 
on this blog, a 
&lt;a href=&quot;https://arxiv.org/abs/1901.02441&quot;&gt;recent preprint&lt;/a&gt; 
proves a set of long-expected lower bounds for distributed graph algorithms. 
This post is the first of a (short) series of (short) posts about the basics of 
this paper.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/puzzle-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;a-series-of-posts&quot;&gt;A series of posts&lt;/h2&gt;

&lt;p&gt;In this first post we give an overview of the &lt;em&gt;simulation argument&lt;/em&gt;, which is 
the framework used for the lower bound.&lt;/p&gt;

&lt;p&gt;The next posts will be about:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;specific construction for edge labelings on bicolored trees&lt;/li&gt;
  &lt;li&gt;Example 1: sinkless orientation&lt;/li&gt;
  &lt;li&gt;Example 2: maximal matching&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most of the content of this series is probably better explained in the 
preprint cited above, so you may want to look at it instead of these posts! 
The main difference will appear in the second post where I propose a slightly 
different vocabulary, based on polynomials. The posts assume familiarity with 
the local model.&lt;/p&gt;

&lt;h3 id=&quot;a-few-bits-of-context&quot;&gt;A few bits of context&lt;/h3&gt;

&lt;p&gt;The simulation technique can be traced back to Linial, 
and his $\Omega(\log^*n)$ lower bound for coloring.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;
However, it did a come-back with 
&lt;a href=&quot;https://arxiv.org/pdf/1511.00900.pdf&quot;&gt;a 2015 paper&lt;/a&gt; that had a different point 
of view. 
It was then simplified and improved.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 
The technique was an important part of 
&lt;a href=&quot;http://adga.hiit.fi/2017/hirvonen.pdf&quot;&gt;the talk of Juho Hirvonen&lt;/a&gt; 
at the 
&lt;a href=&quot;http://adga.hiit.fi/2017/&quot;&gt;2017 ADGA workshop&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;overview-of-the-simulation-argument&quot;&gt;Overview of the simulation argument&lt;/h2&gt;

&lt;p&gt;The core question of the simulation argument is the following. 
Suppose that in time $T$ you can solve a problem. Then what can you solve 
if you have only $T-1$ rounds? 
For lower bounds, the basic line of reasoning is the following.&lt;/p&gt;

&lt;h3 id=&quot;base-step-0-rounds&quot;&gt;Base step: 0 rounds&lt;/h3&gt;
&lt;p&gt;Fix a problem $P$.
Suppose you have a way to do the following transformation.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Transformation:&lt;/em&gt;&lt;br /&gt;
Start with:&lt;br /&gt;
an algorithm $A$ in $T$ rounds for a problem $P$. &lt;br /&gt;
change it into:&lt;br /&gt;
an algorithm $A’$ in $T-1$ rounds for another problem $P’$.&lt;/p&gt;

&lt;p&gt;Then, say you want to prove that solving $P$ requires more than 1 
round. 
Then you only need to prove that you have a transformation as above, with $T=1$, 
and that $P’$ is not trivial (that is, to prove that 
$P’$ cannot be solved in zero round) 
Indeed if there is an algorithm in 1 round for $P$, then you can transform it 
into an algorithm in 0 round for $P’$, which would contradict the 
non-triviality of $P’$. 
Then you known that $P$ requires at least 2 rounds. 
This may sound silly as we have just moved the problem: now you are left 
with proving that $P’$ is non-trivial. But this is usually much simpler.&lt;/p&gt;

&lt;h3 id=&quot;induction&quot;&gt;Induction&lt;/h3&gt;
&lt;p&gt;Now, you want to prove lower bounds above one round, say $k+1$ rounds. 
The argument goes the following way.
For the sake of contradiction, suppose there is an algorithm in $k$ rounds for 
your problem $P$.
Now you prove that there exists a family of problems $P_0, P_1, P_2, …,P_k$, with 
$P_0=P$, such that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;none of them is trivial&lt;/li&gt;
  &lt;li&gt;given an algorithm for $P_i$ in $k-i$ rounds, you can transform it into an 
algorithm in $k-i-1$ rounds for $P_{i+1}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The last point implies that $P_k$ can be solved in $0$ rounds, which impossible 
because the first point states that it is non-trivial. 
Thus $P$ needs at least $k+1$ rounds.&lt;/p&gt;

&lt;h3 id=&quot;simulation-argument&quot;&gt;Simulation argument&lt;/h3&gt;
&lt;p&gt;The question now: how do you define a transformation? &lt;br /&gt;
Suppose you know an algorithm in $T$ rounds, but you have only a view of 
$T-1$ rounds. Then you can do the following.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Imagine all the possible ways your $T-1$ neighbourhood could be extended to a 
$T$ neighbourhood.&lt;/li&gt;
  &lt;li&gt;Compute a solution for each of these extensions, using you $T$-round algorithm.&lt;/li&gt;
  &lt;li&gt;Label you node/edges with the set of all the labels that the T-round algorithm
would use in one of the extensions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Obviously you are not solving the original problem because you are labeling your
node/edges with sets of labels, instead of labeling them with only one label. 
Also this labeling may be uninteresting: every node/edge could be labeled with 
all the possible labels. 
But maybe it &lt;em&gt;is&lt;/em&gt; interesting. 
And then you may be able to define a non-trivial problem $P’$ 
(probably a quite artificial problem but it’s ok) such that this set-labeling 
is a proper labeling for $P’$.&lt;/p&gt;

&lt;h3 id=&quot;simplification-step&quot;&gt;Simplification step&lt;/h3&gt;
&lt;p&gt;You may also want to have a simplification step. 
This is a step that you perform after you have labeled your nodes/edges with 
sets of labels.
The goal is to simplify the proof, by replacing the sets of labels by something 
simpler, typically simple labels. For example you decide that every set of labels 
{$a,b$} is replaced by $a$. For this step to be useful you need that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;one can compute the simplification without further communication (e.g. no 
synchronization with neighbours)&lt;/li&gt;
  &lt;li&gt;the new labels fit into a language that has good properties, in particular, it 
is not trivial.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;The simulation argument appears more clearly in the &lt;a href=&quot;https://users.ics.aalto.fi/suomela/doc/linial-easy.pdf&quot;&gt;modern version of the proof&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;There is an soon coming note by &lt;a href=&quot;https://disco.ethz.ch/alumni/brandts&quot;&gt;Sebastian Brandt&lt;/a&gt; that formalizes precisely the approach.&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 11 Feb 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///simulation-1</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///simulation-1</guid>
      </item>
    
      <item>
        <title>January notes</title>
        <description>&lt;p&gt;A few notes for January 2019.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/dino.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;a href=&quot;http://www.jardindesplantesdeparis.fr/en/activities-events/galleries-gardens-zoo-libraries/illuminated-species-2931&quot;&gt;Illuminated species&lt;/a&gt; in Jardin des Plantes in Paris.&lt;/center&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;maximal-matching-lower-bound&quot;&gt;Maximal matching lower bound&lt;/h2&gt;

&lt;p&gt;They did it! A key problem of distributed computing on graphs has 
been solved by a team supervised by
&lt;a href=&quot;https://users.ics.aalto.fi/suomela/&quot;&gt;Jukka Suomela&lt;/a&gt;. 
&lt;a href=&quot;https://arxiv.org/abs/1901.02441&quot;&gt;The preprint&lt;/a&gt; has been 
uploaded to arxiv recently, and is not reviewed yet, so this should be taken 
with a grain of salt, but given the authors list, and what I have read of the 
paper, there is little doubt it is correct.&lt;/p&gt;

&lt;p&gt;The setting can be explained the following way. There are jobs available,
and people looking for jobs. Every job has at most $\Delta$ candidates, 
and each person has at most $\Delta$ jobs (s)he is interested in. 
There is no central entity, so the decisions of which job is matched
to which person have to be taken based on communication 
between the “jobs” and the people. 
At the end, we want that (1) every person
either has been assigned a job or all the jobs (s)he was interested in have been 
assigned to someone else, and (2) every job is either assigned to someone, or all 
the candidates for this job have been assigned another job. 
Note that there is no preference list, and that
this problem would be very easy if we had a central entity managing the job 
market.&lt;/p&gt;

&lt;p&gt;A strategy to solve the problem is the following: first every person chooses a 
job among the ones it has selected, and sends a proposal to this job, second the 
“jobs” choose one of the persons that have sent a proposal to it (if any). 
After this first round, some people and jobs are already matched, and they leave 
the game. 
The other jobs and persons continue, until we have reached a situation that 
fulfils the conditions (1) and (2) above.&lt;/p&gt;

&lt;p&gt;This strategy requires $O(\Delta)$ phases. The new result tells us
that this is basically optimal.&lt;/p&gt;

&lt;h2 id=&quot;search-vs-decision&quot;&gt;Search vs decision&lt;/h2&gt;

&lt;p&gt;My PhD was about distributed decision, and a sentence that often appears in 
papers on this topic is some variation of “unlike in the centralized setting,
search and decision are very different in the distributed setting”. This makes
me a bit uncomfortable because I don’t have a very strong statement to support 
the claim that in centralized computing search and decision are similar.&lt;/p&gt;

&lt;p&gt;Lance Fortnow 
&lt;a href=&quot;https://blog.computationalcomplexity.org/2019/01/search-versus-decision.html&quot;&gt;blogged about this&lt;/a&gt; 
early this month.&lt;/p&gt;

&lt;h2 id=&quot;fragile-complexity&quot;&gt;Fragile complexity&lt;/h2&gt;

&lt;p&gt;An interesting recent line of research is to go “beyond worst-case complexity”, 
that is to consider other measures of complexity/efficiency than the time on the
worst input, as the later can be inadequate for many purposes.
There are very nice concepts there, such as the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Smoothed_analysis&quot;&gt;smoothed complexity&lt;/a&gt;. 
See also the &lt;a href=&quot;http://timroughgarden.org/f14/l/top10.pdf&quot;&gt;top 10 ideas&lt;/a&gt; in this 
area, by &lt;a href=&quot;http://timroughgarden.org/&quot;&gt;Tim Roughgarden&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A new measure was introduced in 
&lt;a href=&quot;https://export.arxiv.org/abs/1901.02857&quot;&gt;an arxiv preprint&lt;/a&gt; this month: fragile 
complexity. I just read the abstract, and I don’t know why it is called ‘fragile’, 
but I understand the definition for sorting: the fragile complexity of a sorting
algorithm is the maximal number of comparisons that an element of the list can 
be part of.&lt;/p&gt;

&lt;h2 id=&quot;lipics-without-logos&quot;&gt;LIPIcs without logos&lt;/h2&gt;

&lt;p&gt;I like LIPIcs latex class, which is now used for many conferences (basically the 
ones that switched to open access). 
I would like to use 
it for my preprints (because it looks nice, and because if the conference is in 
lipics, it avoids extra-work). One problem is that preprints should not have the
official lipics logos, and other feature that are relevant only for conference 
publications. 
Following the example of a colleague, I used to use a modified version of the 
class file. This is not useful any more: the class now provides the command 
\hideLIPIcs that hides the conference-only features. (See the
&lt;a href=&quot;http://drops.dagstuhl.de/styles/lipics-v2019/lipics-v2019-authors/lipics-v2019-authors-guidelines.pdf&quot;&gt;authors guidelines&lt;/a&gt;, 
page 8.)&lt;/p&gt;

&lt;h2 id=&quot;pac-learning-and-deep-learning&quot;&gt;PAC learning and deep learning&lt;/h2&gt;

&lt;p&gt;It seems that deep learning is becoming popular among almost everybody (at least 
from a scientific point of view), except theoretical computer scientists, who 
criticize it for its lack of proven guarantees. As a reaction, 
there are several efforts to better understand ML from a theoretical point of 
view (for example in &lt;a href=&quot;http://people.csail.mit.edu/madry/lab/&quot;&gt;Alexander Mądry’s group&lt;/a&gt;
and in the &lt;a href=&quot;http://mltheory.cs.princeton.edu/&quot;&gt;ML theory group at Princeton&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The month in the Theory Dish blog, Amit Daniely and Roy Frostig 
&lt;a href=&quot;https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/&quot;&gt;blog about&lt;/a&gt;
the performances of deep learning on well-defined theoretical tasks in the 
context of &lt;a href=&quot;https://en.wikipedia.org/wiki/Probably_approximately_correct_learning&quot;&gt;PAC learning&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Incidentally, Leslie Valiant published a &lt;a href=&quot;http://www.probablyapproximatelycorrect.com/&quot;&gt;book&lt;/a&gt;
about PAC learning (that he defined in the eighties), and its relation with 
nature and evolution.&lt;/p&gt;

&lt;h2 id=&quot;wind-turbines-machine-learning-and-algorithms&quot;&gt;Wind turbines, machine learning and algorithms&lt;/h2&gt;

&lt;p&gt;Lance Fortnow also &lt;a href=&quot;https://blog.computationalcomplexity.org/2019/01/machine-learning-and-wind-turbines.html&quot;&gt;blogged about wind turbines and ML&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Basically, a problem for wind turbines is to predict sudden changes of the wind, 
that could cause damage. One could use complex fluid simulations, but these are 
slow therefore there is an increasing trend in using ML for these predictions.&lt;/p&gt;

&lt;p&gt;So there is a way to make things in a “deterministic” well-defined way, but one 
prefers the ML version that is quicker. 
This reminds me of a 
&lt;a href=&quot;https://cstheory.stackexchange.com/questions/38095/if-machine-learning-techniques-keep-improving-whats-the-role-of-algorithmics-i&quot;&gt;stack exchange topic&lt;/a&gt;
that was basically asking: will algorithms be really useful in the future, knowing
that most of the time we are interested in “good enough” solution, and that we 
don’t even want some approximation guarantees, or even worse, we want solutions 
that are good, with the definition of good given only by examples. Unfortunately 
there were not many answers…&lt;/p&gt;

&lt;h2 id=&quot;power-diagrams-to-represents-fluids&quot;&gt;Power diagrams to represents fluids&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://11011110.github.io/blog/2019/01/15/linkage.html&quot;&gt;11011110 blog&lt;/a&gt; links 
to
&lt;a href=&quot;https://twitter.com/BrunoLevy01/status/1080085027210309632&quot;&gt;nice fluid simulations&lt;/a&gt;
using &lt;a href=&quot;https://en.wikipedia.org/wiki/Power_diagram&quot;&gt;power diagram&lt;/a&gt;, 
to picture units of fluid. Power diagrams are generalizations of 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Voronoi_diagram&quot;&gt;Voronoi diagrams&lt;/a&gt; but special 
cases of &lt;a href=&quot;https://en.wikipedia.org/wiki/Weighted_Voronoi_diagram&quot;&gt;weighted Voronoi diagrams&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;order-types&quot;&gt;Order types&lt;/h2&gt;

&lt;p&gt;Suppose you have a configuration with four points in the plane, such that no 
three of them are aligned. Then, either all the points are extreme points, and 
they form a kind of quadrilateral, or there are three points forming a triangle, 
and the last point is in the triangle. These two cases are called the order types
(for four points in the plane). As you can expect, this gets more tricky when 
you look at more points.&lt;/p&gt;

&lt;p&gt;There was a &lt;a href=&quot;https://epubs.siam.org/doi/10.1137/1.9781611975482.27&quot;&gt;paper at SODA 2019&lt;/a&gt;
about this topic.&lt;/p&gt;

</description>
        <pubDate>Wed, 30 Jan 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///january-2019-notes</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///january-2019-notes</guid>
      </item>
    
      <item>
        <title>October batch, forgotten notions</title>
        <description>&lt;p&gt;&lt;img src=&quot;assets/arbre-bw.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I saw many talks in October and I plan to blog a bit about those in some 
posts to come. This first post is about some notions a somehow knew but couldn’t 
really define.&lt;/p&gt;

&lt;h2 id=&quot;epsilon-nets&quot;&gt;$\epsilon$-nets&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/%CE%95-net_(computational_geometry)&quot;&gt;$\epsilon$-nets&lt;/a&gt; 
are often appear in computational geometry. Consider a set of points $X$ in 
a geometric space, and a collection $C$ of subsets of $X$ (for example you have 
a collection of balls, then it defines the collection of subsets of $X$: the 
points contained in each ball). 
Now you are given an $\epsilon\in [0,1]$. 
An $\epsilon$-net $E$ is a subset of $X$, such that for every element $c$ of $C$ 
that is large enough, $c$ contains an element of $X$, and large enough means: 
&lt;script type=&quot;math/tex&quot;&gt;\frac{|c|}{|X|}\geq \epsilon.&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;As one can imagine this is a useful tool to build approximation algorithm, as 
one may be able to focus on the net, that is hopefully much smaller than $X$.&lt;/p&gt;

&lt;p&gt;The concept is related to the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_dimension&quot;&gt;VC dimension&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A nice introduction with a chocolate-consumer example can be found 
&lt;a href=&quot;https://www.ti.inf.ethz.ch/ew/lehre/CG12/lecture/Chapter%2015.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ptas-qptas-etc&quot;&gt;PTAS, QPTAS etc.&lt;/h2&gt;

&lt;p&gt;A small list of the accronyms for approximation schemes (PTAS is fine for me, 
but after that…):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Polynomial-time_approximation_scheme&quot;&gt;PTAS&lt;/a&gt;, 
polynomial-time approximation scheme: for every $\epsilon$, you get 
approximation $(1+\epsilon)$, in polynomial time. That is when you fix 
$\epsilon$ you get a polynomial in $n$. Typically you have time complexity 
$f(\epsilon)\times n^{g(\epsilon)}$, 
where $f$ and $g$ can be arbitrarily bad.&lt;/li&gt;
  &lt;li&gt;EPTAS, for efficient-PTAS: here the exponent should not depend on $\epsilon$. 
With the example above, $g$ is a constant, and $f$ can still be arbitrary.&lt;/li&gt;
  &lt;li&gt;FPTAS, for fully-PTAS: the algorithm is polynomial in both $n$ and $1/\epsilon$.
Typically, $g$ is a constant, and $f$ a polynomial in $1/\epsilon$.&lt;/li&gt;
  &lt;li&gt;QPTAS, quasi-polynomial-time approximation scheme: this is worse than PTAS, 
because you allow that even for a fixed $\epsilon$ the complexity is only
quasi-polynomial, for example some $n^{\log n}$.&lt;/li&gt;
  &lt;li&gt;PRAS, EPRAS, FPRAS: the same as PTAS, EPTAS, FPTAS, but randomized (the result 
has to be a correct approximation with high probability).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(Both this section and the previous one originate from the talk of 
&lt;a href=&quot;https://www.lamsade.dauphine.fr/~bonnet/&quot;&gt;Edouard Bonnet&lt;/a&gt; for the paper 
&lt;em&gt;&lt;a href=&quot;http://ieee-focs.org/FOCS-2018-Papers/pdfs/59f568.pdf&quot;&gt;EPTAS for Max Clique on Disks and Unit Balls&lt;/a&gt;&lt;/em&gt; 
at FOCS 2018.)&lt;/p&gt;

&lt;h2 id=&quot;doubling-dimension&quot;&gt;Doubling dimension&lt;/h2&gt;

&lt;p&gt;A lot of recent papers prove nice results in doubling metrics. The &lt;a href=&quot;https://en.wikipedia.org/wiki/Doubling_space&quot;&gt;doubling 
dimension&lt;/a&gt; 
of a metric space is the smallest positive $k$ such that every ball of 
the space can be covered by $2^k$ balls of half the radius. You can think of 
the plane, and show that you can cover a ball of radius 1, with 7 balls of 
radius 1/2, which gives doubling dimension 3. More generally for the euclidian 
space $R^d$, the doubling dimension is known to be in $O(d)$. Thus bounded 
doubling dimension is a natural generalization of bounded dimension.&lt;/p&gt;

&lt;p&gt;(The notion appears for example in &lt;em&gt;&lt;a href=&quot;http://ieee-focs.org/FOCS-2018-Papers/pdfs/59f814.pdf&quot;&gt;$ε$-Coresets for Clustering (with Outliers) 
in Doubling Metrics&lt;/a&gt;&lt;/em&gt; also 
presented at FOCS.)&lt;/p&gt;

</description>
        <pubDate>Thu, 24 Jan 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///october-batch-forgotten</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///october-batch-forgotten</guid>
      </item>
    
      <item>
        <title>December notes</title>
        <description>&lt;p&gt;&lt;img src=&quot;assets/arbre.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;karchmer-wigderson-theorem&quot;&gt;Karchmer-Wigderson theorem&lt;/h2&gt;

&lt;p&gt;Karchmer-Wigderson theorem makes a precise link between circuit and 
communication complexity. More precisely it 
 relates the depth of a boolean
circuit computing some function $f$, to the communication complexity of a game 
based on $f$. The game is the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Inputs: Alice has an input $x$ such that $f(x)=1$, 
and Bob has another input $y$ such that $f(y)=0$.&lt;/li&gt;
  &lt;li&gt;Task: find $i$ such that $x_i \neq y_i$ (such an $i$ must exist).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The way to go from the circuit to a communication protocol is the following. 
Alice and Bob each run the circuit on their inputs, the usual bottom-up way. 
Thus each of them knows the 
evaluation after each gate (“after this gate, this wire holds a 0, after this 
one it’s a 1” etc.). Now the protocol will go top-down.
As after the final gate (that is, the top gate), 
Alice gets a 1 and Bob gets a 0, we know that the two wires 
entering this gate cannot both have the same value for Alice and Bob. 
Alice and Bob can communicate to agree on one wire that has different value. 
This takes constant number of bits. And then you just follow the wire to the 
next gate and continue. At the end Alice and Bob agree on an input wire that has different 
value and they win the game. The communication complexity is the circuit depth.&lt;/p&gt;

&lt;p&gt;For the other direction, see the Internet.&lt;/p&gt;

&lt;p&gt;(I learnt about Karchmer-Wigderson theorem recently by watching parts of an 
&lt;a href=&quot;https://www.youtube.com/watch?v=t1EsRm1dmw0&quot;&gt;online talk&lt;/a&gt; by 
&lt;a href=&quot;http://www.math.ias.edu/~mika/&quot;&gt;Mika Göös&lt;/a&gt;.)&lt;/p&gt;

&lt;h2 id=&quot;counting-crows&quot;&gt;Counting crows&lt;/h2&gt;

&lt;p&gt;These days I often cross the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Jardin_des_plantes&quot;&gt;Jardin des Plantes&lt;/a&gt;
in Paris, and I saw a sign giving information about the counting of crows in 
Paris. Basically a large number of crows now have a ring with a specific number. 
The problem is that the rings tend to fall, disappear etc. To evaluate this 
loss rate, the birds are rung with two rings. Then 
by counting the number of crows with zero, one and two rings, one can evaluate 
the loss rate, and then the population.&lt;/p&gt;

&lt;p&gt;This sounded very much like CS to me, for example in networks, 
sending packets that may disappear, and trying to know the message loss for 
example.&lt;/p&gt;

&lt;h2 id=&quot;minimum-degree-spanning-tree&quot;&gt;Minimum degree spanning tree&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Degree-constrained_spanning_tree&quot;&gt;Minimum-degree spanning tree&lt;/a&gt;, 
consists in finding a spanning tree of a graph, 
with the constraint that the maximum degree of the tree should be as small as 
possible. This problem is NP-hard, because if the answer is 2 then it means that 
you have an Hamiltonian path. But one can get an approximation with additive 
constant 1.
The algorithm (from 
&lt;a href=&quot;https://doi.org/10.1006%2Fjagm.1994.1042&quot;&gt;this paper&lt;/a&gt;, explained in 
&lt;a href=&quot;http://pages.cs.wisc.edu/~shuchi/courses/880-S07/scribe-notes/lecture08.pdf&quot;&gt;these lecture notes&lt;/a&gt;)
consists in a local search, with swapping of edges to as local moves.&lt;/p&gt;

&lt;p&gt;This problems looks very natural and potentially very useful. I’d be curious 
to know if there are real-world applications.&lt;/p&gt;

&lt;p&gt;(I discovered this problem in
&lt;a href=&quot;https://doi.org/10.1109/ICDCS.2015.66&quot;&gt;this distributed computing paper&lt;/a&gt;.)&lt;/p&gt;

&lt;h2 id=&quot;cycle-cover&quot;&gt;Cycle cover&lt;/h2&gt;
&lt;p&gt;An &lt;a href=&quot;https://en.wikipedia.org/wiki/Edge_cycle_cover&quot;&gt;(edge) cycle-cover&lt;/a&gt;
is a set of cycles of a graph, such that every edge of the graph 
is contained in at least one cycle. There are several problems associated with 
this object, for example related to the total length of the cycles in such a 
cover. I want to mention a super-cute-super-hard open problem: the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Cycle_double_cover&quot;&gt;cycle double cover conjecture&lt;/a&gt;. 
The conjecture is: in every graph with no 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Bridge_(graph_theory)&quot;&gt;bridge&lt;/a&gt;, 
there is a list of cycles so that every edge is 
contained in exactly two.&lt;/p&gt;

&lt;p&gt;If you think “How can this be open?!”, I’ll just add that it is listed in the 
&lt;a href=&quot;http://www.openproblemgarden.org/op/cycle_double_cover_conjecture&quot;&gt;open problem garden&lt;/a&gt; 
as of “outstanding importance”. See there, or on the wikipedia page linked above 
for the details.&lt;/p&gt;

&lt;p&gt;(&lt;a href=&quot;https://arxiv.org/abs/1812.04492&quot;&gt;A paper about cycle covers&lt;/a&gt; recently 
appeared on the arxiv, reminded me this problem.)&lt;/p&gt;

&lt;h2 id=&quot;mst-algorithms&quot;&gt;MST algorithms&lt;/h2&gt;
&lt;p&gt;Consider the following algorithm for finding a minimum weight spanning tree, similar to 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Bor%C5%AFvka%27s_algorithm&quot;&gt;Borůvka’s algorithm&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Every node begins has a so-called fragment.&lt;/li&gt;
  &lt;li&gt;Until there is only one fragment: choose an arbitrary fragment, find the 
lightest edge linking a node of 
this fragment to another fragment, merge the two fragments into a new one by 
adding this edge.&lt;/li&gt;
  &lt;li&gt;Output the final fragment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This algorithm is actually a generalization of Borůvka, Prim and Kruskal algorithm! 
For Borůvka’s algorithm, one would basically choose an 
outgoing edge for all fragments in parallel. For Prim, one would always choose 
the same fragment to enlarge. F	or Kruskal, one would choose the lightest 
outgoing edge of all the fragments.&lt;/p&gt;

&lt;p&gt;This can probably be explained with red-blue rules, but I like this point of
view with a kind of scheduler, with different strategies.&lt;/p&gt;

&lt;p&gt;(I’m working again on some minimum spanning tree distributed problems, and it 
reminded me about this fact, that I discovered a few years ago, but that I’ve 
never seen in undergraduate courses.)&lt;/p&gt;

&lt;h2 id=&quot;squashed-cube-conjecture-and-distance-labelling&quot;&gt;Squashed cube conjecture and distance labelling&lt;/h2&gt;
&lt;p&gt;Distance labelling are labels given to the nodes of a graph such that given the 
labels of two arbitrary nodes $u$ and $v$, and without seeing the graph, one can compute 
the distance between $u$ and $v$. One usually tries to minimize the size of 
the labels.
A strategy for this is to find some metric embedding of the graph, because then 
one can 
simply give the coordinates of the nodes as labels. 
In this direction, a natural thing to do is to try the embed the graph in an 
hypercube with the Hamming distance. This cannot be done in general, but the 
squashed cube conjecture (that is actually a theorem) provides a result close to 
this.&lt;/p&gt;

&lt;p&gt;Consider that instead of two symbols, there are three: 0, 1, and *, and 
that the “distance” between $x$ and $y$ is the number of indices such that $x=0$ 
and $y=1$ or $x=1$ and $y=0$. That is * is at distance zero from 0 and 1. 
(Note that this distance is not a proper distance.)
Now how many symbols do you need to have a distance preserving embedding? 
Exactly $n-1$, as proved in &lt;a href=&quot;https://doi.org/10.1007/BF02579350&quot;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;(I discovered this in the related works section of 
&lt;a href=&quot;https://doi.org/10.1007/3-540-44676-1_40&quot;&gt;this paper&lt;/a&gt;.)&lt;/p&gt;

&lt;h2 id=&quot;jaccard-metric&quot;&gt;Jaccard metric&lt;/h2&gt;
&lt;p&gt;Lipton and Regan talk about the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Jaccard_index&quot;&gt;Jaccard metric&lt;/a&gt; in 
&lt;a href=&quot;https://rjlipton.wordpress.com/2018/12/14/explaining-the-jaccard-metric/&quot;&gt;a post&lt;/a&gt;
of their blog, &lt;em&gt;Gödel’s lost letter&lt;/em&gt;, in particular why it is a metric. I didn’t 
know about this distance over sets, so here is the definition.&lt;/p&gt;

&lt;p&gt;Let $A$ and $B$ 
be two sets, the distance is:
&lt;script type=&quot;math/tex&quot;&gt;d(A,B)=1-\frac{|A \cap B|}{|A \cup B|}.&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;preprints&quot;&gt;Preprints&lt;/h2&gt;
&lt;p&gt;I have two new preprints this month:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1812.05913&quot;&gt;Graph classes and forbidden patterns on three vertices&lt;/a&gt;
with &lt;a href=&quot;https://www.irif.fr/~habib/&quot;&gt;Michel Habib&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;xxx&quot;&gt;Lower bounds for text indexing with mismatches and differences&lt;/a&gt; with
&lt;a href=&quot;https://www.di.ens.fr/~vcohen/&quot;&gt;Vincent Cohen-Addad&lt;/a&gt; and 
&lt;a href=&quot;https://starikovskaya.github.io/homepage/&quot;&gt;Tatiana Starikoskaya&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I really like both papers, I hope I’ll find some time to blog about it soon.&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Dec 2018 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///december-2018-notes</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///december-2018-notes</guid>
      </item>
    
      <item>
        <title>November notes</title>
        <description>&lt;p&gt;A few notes for November 2018.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;a-new-paper-on-descriptive-complexity-of-distributed-computing&quot;&gt;A new paper on descriptive complexity of distributed computing&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Descriptive_complexity_theory&quot;&gt;Descriptive complexity&lt;/a&gt; 
basically aims at characterizing complexity classes through logic. A classic 
results is &lt;a href=&quot;https://en.wikipedia.org/wiki/Descriptive_complexity_theory&quot;&gt;Fagin’s Theorem&lt;/a&gt;
that characterizes NP. 
Descriptive complexity for distributed computing is a relatively new topic,&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;
and a &lt;a href=&quot;https://arxiv.org/abs/1811.08197&quot;&gt;new paper&lt;/a&gt; just came out on arxiv.
I’m not a specialist, but from what I understood, the classic assumption of the
LOCAL model that there are unique identifiers, is pretty difficult to transfer 
into logic, and this paper seems to make a step in this direction.&lt;/p&gt;

&lt;h2 id=&quot;a-map-of-the-theory-of-distributed-computing-community&quot;&gt;A map of the theory of distributed computing community&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://users.ics.aalto.fi/suomela/&quot;&gt;Jukka Suomela&lt;/a&gt; published
&lt;a href=&quot;https://plus.google.com/+JukkaSuomela/posts/JgWYFk4XzWW&quot;&gt;a nice map&lt;/a&gt; of the 
PODC/DISC communities. (PODC and DISC are the two main conferences in theory 
of distributed computing.)&lt;br /&gt;
It is a graph where the nodes are the authors, and the edges between them 
have different thickness, 
depending on how much they have collaborated, or have had papers in the same 
sessions. There are strong thematic clusters, which is no surprise.&lt;/p&gt;

&lt;h2 id=&quot;symmetries-in-lps-and-sos&quot;&gt;Symmetries in LPs and SOS&lt;/h2&gt;
&lt;p&gt;I attended the PhD defense of 
&lt;a href=&quot;https://www.lip6.fr/actualite/personnes-fiche.php?ident=D1634&quot;&gt;Cécile Rottner&lt;/a&gt;
who was a student in the OR team of &lt;a href=&quot;https://www.lip6.fr/?LANG=en&quot;&gt;LIP6&lt;/a&gt;. 
Her thesis was about a problem that
any electric utility company faces: how to manage the different the power plants
to meet the demand while using the less energy possible, given that there are 
many constraints on these plants (a nuclear reactor cannot be switched on and 
off in a minute, some other stuff has to cool down, etc.). As often in OR (as far as
I know) this is done by having big LPs and playing with them, adding new 
inequalities, trying to use the structure to speed the computation, having 
branch and cut routines etc.&lt;/p&gt;

&lt;p&gt;One of the big challenges that one has to tackle when solving these big LPs 
in an industrial context is to break the symmetries.
Suppose you have two identical 
nuclear reactors in your system. Then if you use one or the other in your solution, 
you will have the same cost. This implies that you can have many many optimal 
solutions. This is bad for a branch and cut 
strategy, where the ideal case is to have only one optimal solution, and to be 
cutting all the other branches quickly. Cécile showed ways to solve this problem.&lt;/p&gt;

&lt;p&gt;This reminded me of another PhD defense with symmetries: the one of 
&lt;a href=&quot;https://sites.google.com/view/vverdugo/&quot;&gt;Victor Verdugo&lt;/a&gt;. Victor had a part of 
his PhD work on how to break symmetry for 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Sum-of-squares_optimization&quot;&gt;sum-of-squares&lt;/a&gt;. The
timing for this blog post is pretty good: the paper of Victor on this topic 
just appeared on arxiv, 
&lt;a href=&quot;https://arxiv.org/abs/1811.08539&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;double-blind-for-disc&quot;&gt;Double-blind for DISC&lt;/h2&gt;
&lt;p&gt;The conference &lt;a href=&quot;http://www.disc-conference.org/wp/&quot;&gt;DISC&lt;/a&gt; will go 
double-blind next year (that is the names of both the reviewers and the authors will
be anonymized).&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; At first I was sceptical about this idea, 
because of the usual reasons: extra-care in the process (e.g. when talking to 
people) with probably no big impact, etc. But recently I reviewed a paper by 
authors from a university I had never heard of, and I felt that before even 
starting I had a negative bias. I think double-blind is exactly about 
protecting authors from this bias.&lt;/p&gt;

&lt;p&gt;I heard many times that the 
problem is that well-known people get their papers accepted although 
they are not good enough, and I think this cannot really change (because 
of arxiv, favourite topics, writing style), but it’s the other side of the 
spectrum that can be made more fair. So let’s see how it goes.&lt;/p&gt;

&lt;h2 id=&quot;a-few-points-on-networks-and-games&quot;&gt;A few points on networks and games&lt;/h2&gt;
&lt;p&gt;I attended a talk at LIP6 by 
&lt;a href=&quot;http://webee.technion.ac.il/Sites/People/ArielOrda/&quot;&gt;Ariel Orda&lt;/a&gt; on game theory 
and networks. The talk described two very interesting works, but 
I just picked a few non-specific things that caught my interest.&lt;/p&gt;

&lt;h3 id=&quot;network-formation-games&quot;&gt;Network formation games&lt;/h3&gt;
&lt;p&gt;The first topic is about understanding the structure of real-world networks, by 
finding ways to build algorithmically networks that have similar properties. 
A well-known generation algorithm is the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Barab%C3%A1si%E2%80%93Albert_model&quot;&gt;Barabási–Albert model&lt;/a&gt; 
where nodes basically arrive one by one and choose who to be linked to, 
based on the degree of the nodes that already arrived. There is a second 
type of network formation model that I didn’t know,&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;sup&gt;,&lt;/sup&gt;&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; which is to start 
with a fixed set of nodes, and to make them play a game to decide 
which edges are in the graph. 
For example, the nodes want to maximize their pay-offs in a game where every 
link cost something, but having short paths to every node is rewarded. 
These are called network formation games.&lt;/p&gt;

&lt;h3 id=&quot;monetary-transfer&quot;&gt;Monetary transfer&lt;/h3&gt;
&lt;p&gt;The second idea is about introducing money in games.
Suppose you have a Nash equilibrium 
that is very bad (for some definition of bad) because each player, when 
maximizing its gain, is hurting the other players a lot. Then you can introduce
monetary transfer, that consists for two players A and B to agree that if the 
A does this thing that decreases its pay-off but increases the pay-off 
of B, then B will give part of its 
pay-off to reimburse A, and both will be happier. Natural idea to 
consider, but that I had never heard of.&lt;/p&gt;

&lt;h3 id=&quot;using-motifs-to-validate-a-model&quot;&gt;Using motifs to validate a model&lt;/h3&gt;
&lt;p&gt;I knew that people studying social 
networks are obsessed with finding motifs (small graphs that appear more 
often than others), but I was not sure why. It could be just to have 
more knowledge about the relationships, but in Orda’s talk, it was 
also a way to validate a model. Basically: in real-world graphs this and that 
motifs are very common, we don’t know why, and previous generative 
models did not have this property, but their model could capture this. 
As far as I know, parameters such as the diameter, or the clustering 
coefficient are more classic ways to validate such models.&lt;/p&gt;

&lt;h3 id=&quot;about-the-price-of-anarchy-selfishness-and-collaboration&quot;&gt;About the price of anarchy, selfishness and collaboration&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Price_of_anarchy&quot;&gt;price of anarchy&lt;/a&gt;, 
is the ratio between the social cost when each players tries to optimize 
its own pay-off, and when all the players play the strategy that minimize 
the social cost. It is often said that this price is the price to pay 
when players are selfish. But it is not completely true, it is also the 
price of not collaborating. You can image scenarios in which players have
the option of collaborating but each player will agree only if it ensures 
 a better pay-off. That is the players are still selfish but 
they can talk to each other and make agreements. 
This can change the outcome a lot. Then one 
will consider what is called a Nash bargaining solution.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;If you are interested, see &lt;a href=&quot;https://arxiv.org/abs/1805.06238&quot;&gt;Fabian Reiter’s very nice PhD thesis&lt;/a&gt;, and the &lt;a href=&quot;https://semidoc.github.io/reiter-dga&quot;&gt;gentle introduction&lt;/a&gt; to the topic I wrote on semidoc.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;See &lt;a href=&quot;https://twitter.com/JukkaSuomela/status/1065259077738082304&quot;&gt;this tweet&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;There seems that there is no third well-known way to generate networks, at least in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Network_formation&quot;&gt;wikipedia article about network formation&lt;/a&gt;.&amp;nbsp;&lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Actually I somehow knew because of &lt;a href=&quot;https://dl.acm.org/citation.cfm?doid=3178876.3186122&quot;&gt;this paper&lt;/a&gt; by my PhD advisor and colleges, but I had forgotten.&amp;nbsp;&lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 30 Nov 2018 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///november-2018-notes</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///november-2018-notes</guid>
      </item>
    
      <item>
        <title>Popular matchings</title>
        <description>&lt;p&gt;&lt;em&gt;Popular matchings&lt;/em&gt; are a nice variant of the classic
&lt;a href=&quot;https://en.wikipedia.org/wiki/Stable_marriage_problem&quot;&gt;stable matchings&lt;/a&gt;. 
In this post introduce these matchings, and give some bits of information about 
them.&lt;/p&gt;

&lt;h2 id=&quot;stable-matchings&quot;&gt;Stable matchings&lt;/h2&gt;
&lt;p&gt;Remember what a stable matching is. There is bipartite graph, where 
every node holds an ordering of its neighbours, known as the &lt;em&gt;preference list&lt;/em&gt;. 
A matching $M$ in this graph is stable, if no edge $(u,v)$ that is &lt;em&gt;not&lt;/em&gt; in $M$ 
is such that both $u$ and $v$, would prefer to be matched together instead of 
the way they are matched (or unmatched) in $M$. Note that such matchings are 
maximal.&lt;/p&gt;

&lt;p&gt;A stable matching always exists and can be computed in linear-time using the 
famous Gale-Shapley algorithm. Something frustrating with stable matchings is 
that they may be small with respect to the maximum matching (if one forgets 
about the preference lists). For example, in the following picture, the stable 
matching matches the top node on the left, with the bottom node on the right, 
and prevent the two other nodes from being matched, although all could be 
matched.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/popular.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This example shows that the size of a stable matching can be half of the size of 
a maximum matching. 
If you are in a context where you would like to (at least partially) satisfy 
the nodes in terms of preference lists, but you would also like to satisfy as many 
nodes as possible, then you need another form of optimality, and (max-size) 
popular matchings is a good one.&lt;/p&gt;

&lt;h2 id=&quot;popular-matchings&quot;&gt;Popular matchings&lt;/h2&gt;
&lt;p&gt;With a stable matching the matched nodes are happy, because they are at a kind 
of equilibrium, but the other nodes are unhappy because they are not matched at 
all. 
What happens if you make the nodes vote for their favourite matching? 
This makes sense if you do a tournament: for every couple of matchings you make 
an election, and the winner is the matching that is prefered by the majority of 
the nodes. In such an election the vertices perfer to be 
matched, and if matched consider their preference list. Also if there is an 
ex-eaquo then both matchings win.
A matching is popular if it wins every election.&lt;/p&gt;

&lt;h2 id=&quot;relation-with-stable-matchings-and-size-considerations&quot;&gt;Relation with stable matchings and size considerations&lt;/h2&gt;
&lt;p&gt;It is known that every stable matching is popular. 
Thus popularity is a relaxation of stability. 
Unlike stable matchings, popular matchings can have different sizes, and in 
particular they can be
larger the stable matchings (that why we look at them in the first place).
Actually, stable matchings are the worst popular matchings with respect to size: 
stable matchings are the popular matchings of minimum size.&lt;/p&gt;

&lt;p&gt;We then look for &lt;em&gt;max-size popular matching&lt;/em&gt;.
The good news it that a max-size popular matching can be computed in polynomial 
time, and that they have size at least 2/3 of the maximum size matching.&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;
&lt;p&gt;I got aware of this topic at a seminar of 
&lt;a href=&quot;http://www.tcs.tifr.res.in/~kavitha/&quot;&gt;Telikepalli Kavitha&lt;/a&gt; at &lt;a href=&quot;https://www.irif.fr&quot;&gt;IRIF&lt;/a&gt; 
in September. After a nice introduction, she told us about her recent papers on 
the topic (there is a lot to say, with many relevant variants and nice 
algorithmic techniques).&lt;/p&gt;

&lt;p&gt;The concept of popular matchings was introduced by Gärdenfors in the seventies, 
who also proved that stable matchings are popular.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 
The polynomial algorithm for computing a max-size popular matching is much more 
recent, it was designed by Telikepalli and Chien-Chung Huang in 2011.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 
And popular matchings are still a hot topic.&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;P. Gärdenfors, &lt;a href=&quot;https://doi.org/10.1002/bs.3830200304&quot;&gt;Match making: Assignments based on bilateral preferences&lt;/a&gt;. (I couldn’t find it on Google Scholar, but it is accessible on Wiley.)&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;T. Kavitha, C. Huang, &lt;a href=&quot;https://doi.org/10.1016/j.ic.2012.10.012&quot;&gt;Popular matchings in the stable marriage problem&lt;/a&gt;.S&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;See &lt;a href=&quot;https://dblp.uni-trier.de/search?q=popular+matching&quot;&gt;DBLP “popular matching” search&lt;/a&gt;.&amp;nbsp;&lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 13 Nov 2018 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///popular-matchings</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///popular-matchings</guid>
      </item>
    
      <item>
        <title>Start</title>
        <description>&lt;p&gt;Hello. The start of the new blog.&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Sep 2018 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///start</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///start</guid>
      </item>
    
  </channel>
</rss>
