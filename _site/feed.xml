<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Discrete notes</title>
    <description>Blog</description>
    <link>https://discrete-notes.github.io/</link>
    <atom:link href="https://discrete-notes.github.io//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Network decomposition 3&amp;#58; Centralized construction</title>
        <description>&lt;p&gt;[Temporary note: one of the authors will present the network decomposition paper 
at the Aalto seminar on Wednesday! See 
&lt;a href=&quot;https://users.aalto.fi/~uittoj3/seminar.html&quot;&gt;here&lt;/a&gt;.]&lt;/p&gt;

&lt;p&gt;This is the third post of a series on distributed network decomposition. 
The introductory post of this series is 
&lt;a href=&quot;https://discrete-notes.github.io/network-decomposition-0&quot;&gt;here&lt;/a&gt;. 
This post explains how to build a network decomposition in a centralized manner.
As a consequence it also shows that such decompositions exist with nice 
parameters.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/caravane-4.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;recap-of-previous-episodes&quot;&gt;Recap of previous episodes&lt;/h3&gt;

&lt;p&gt;In the previous posts we saw how network decomposition can be useful to build 
efficient local algorithms. Such algorithms are efficient only if the network 
decomposition has good parameters, that is a small number of colors, and a small
diameter for each component. 
We won’t bother with multiplicative constants, or even constant exponents, 
so let’s say that basically, we look for something like in the following picture, 
with $\log n$ colors, and $\log n$ diameter.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/network-decomposition-log.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;basic-technique-to-get-a-coloring&quot;&gt;Basic technique to get a coloring&lt;/h2&gt;

&lt;p&gt;Suppose you want to compute a coloring in a graph in the most simple way. 
You can start with the first color $c_1$, pick a node $v$, put color $c_1$ on it, 
then choose a second node that is not a neighbor of $v$, put again color $c_1$, 
and so on and so forth,
until you cannot use color $c_1$ anymore. Then you take color $c_2$, and repeat 
the process, considering only the nodes that do not have color $c_1$, etc.&lt;/p&gt;

&lt;p&gt;This is basically repeating an algorithm for MIS we mentionned in the 
&lt;a href=&quot;https://discrete-notes.github.io/network-decomposition-1-local-algorithms&quot;&gt;post about local algorithms&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-0.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-4.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-5.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
Step by step construction of a coloring. (1) The graph, (2) the result of the 
computation of the first color class (exactly as in the MIS algorithm), with the 
frozen nodes in grey, (3) the remaining nodes and edges after deletion of the 
colored nodes, (4) second color, (5) third color, and (6) the computed coloring.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;adapting-the-technique-to-network-decomposition&quot;&gt; Adapting the technique to network decomposition&lt;/h2&gt;

&lt;p&gt;We adapt the technique from the previous section to network decomposition. 
That is, instead of picking a 
node and coloring it, we pick a node, and color the ball of radius $\log n$ 
around it. Similarly to what happens in the coloring algorithm above, 
every time we color a ball, we freeze all the nodes that are adjacent to it. 
That is, they will not be considered any more for the color at hand. Once we are 
finished with a color, we go to the next color, remove the nodes of the previous 
colors, defreeze the frozen nodes, and start again.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
Computation of the first color class: (1) choose a node, and select all the 
nodes at distance at most $\log n$ from it, (2) freeze all the nodes that are 
adjacent to a selected node, and (3) repeat the operation until all nodes are
either selected or frozen.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-4.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-5.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-6.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
Computation of the second color class: (1) and (2) remove all the 
nodes of the first color class, and defreeze all frozen nodes. (3) Run the same 
procedure as for the first color class. 
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-7.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-8.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/coloring-log-9.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
Computation of the third color class: again, (1) and (2) remove all the 
nodes of the previous color classes, and defreeze all frozen nodes. (3) Run the 
same procedure as for the first color classes. Now all nodes are selected, thus 
the algorithm stops.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/coloring-log-10.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
The network decomposition produced by the algorithm.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;an-unbalanced-coloring&quot;&gt;An unbalanced coloring&lt;/h2&gt;

&lt;p&gt;The first thing one can note on the picture above is that the decomposition is 
not balanced at all: a huge part of the network is red, a small part is yellow, 
and a tiny part is blue. That might look like a bad thing, as for algorithms 
having balanced decomposition is usually a nice feature. But actually this is not a 
problem for the algorithms built on a network decomposition, as presented in 
the &lt;a href=&quot;https://discrete-notes.github.io/network-decomposition-2-impact&quot;&gt;previous post&lt;/a&gt;. 
And, in fact this imbalance is good for us. Indeed suppose that each color 
covers at least half of the remaining nodes, then after at most $\log n$ steps, 
all nodes are colored. This, in turns, implies that the number of colors is 
logarithmically bounded, which is what we were looking for.&lt;/p&gt;

&lt;p&gt;But, is this always the case? No, you can have a situation like the one on the 
following picture: you pick a node and in its $\log n $ neighborhood, there are 
very few nodes, but the number of nodes that is frozen at the border is huge. 
If this happens everywhere, the number of nodes colored by a the first color 
class is not a constant fraction of the total number of nodes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/blow-up.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Therefore, a bad situation for us is when the ratio between what is inside 
the ball, and its border is small.&lt;/p&gt;

&lt;p&gt;We could try to show that we can choose the centers in a smart way to avoid this 
behavior, but it wouldn’t help much with the distributed construction that 
follows, as such smart choice could require a large view of the graph.
Instead we control the size of the balls.&lt;/p&gt;

&lt;h2 id=&quot;growing-a-ball&quot;&gt; Growing a ball&lt;/h2&gt;

&lt;p&gt;A technique to ensure that the interior/border ratio is large is to build the 
ball around the selected center in the following way.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Start with only the center&lt;/li&gt;
  &lt;li&gt;Iterate the following:&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Measure the number of nodes in the border&lt;/li&gt;
  &lt;li&gt;If it is at least twice the number of nodes in the ball, take all these nodes 
in the ball, and restart the loop.&lt;/li&gt;
  &lt;li&gt;Otherwise leave the loop.&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Freeze all the nodes of the border.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the loop can be run for at most $\log n$ iterations, as otherwise 
the ball would contain more than $n$ nodes. Thus the balls built this way are ok
with the definition of the network decomposition.&lt;/p&gt;

&lt;p&gt;By construction, the size of the border of the ball is at most the size of the
interior of the ball. That is, if we select $m$ nodes to be in the ball, we 
freeze at most $m$ new nodes. This is enough for the whole construction to work.&lt;/p&gt;

</description>
        <pubDate>Mon, 20 Apr 2020 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///network-decomposition-3-centralized</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///network-decomposition-3-centralized</guid>
      </item>
    
      <item>
        <title>Online talks</title>
        <description>&lt;p&gt;Many things have gone online, including talks and conferences. A small post with
pointers.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/plume.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;online-seminars&quot;&gt;Online seminars&lt;/h2&gt;

&lt;p&gt;Many seminars have moved to online settings.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Terence Tao has a 
&lt;a href=&quot;https://terrytao.wordpress.com/2020/04/07/mathematics-seminars-list/&quot;&gt;list of list of online maths seminars&lt;/a&gt;, 
including &lt;a href=&quot;http://math.mit.edu/~aosun/online_seminars.html&quot;&gt;Online maths seminars&lt;/a&gt; 
that has more than 15 talks per day (in all kinds of mathematics).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The same thing but speciafically for TCS can be found 
&lt;a href=&quot;https://cstheorytalks.wordpress.com/&quot;&gt;here&lt;/a&gt;. (One or two talks per day.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Aalto university also has &lt;a href=&quot;https://users.aalto.fi/~uittoj3/seminar.html&quot;&gt;its seminar&lt;/a&gt; 
(that is not listed (yet?) in the lists above).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The online TCS seminar, &lt;a href=&quot;https://sites.google.com/site/plustcs/&quot;&gt;TCS+&lt;/a&gt; has 
increased its frequency from one per month to one per week (and all the previous 
talks are available).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The Simons Institute also has a lot of good videos, see 
&lt;a href=&quot;https://simons.berkeley.edu/videos&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;online-courses&quot;&gt;Online courses&lt;/h2&gt;

&lt;p&gt;Many universities have MOOCs, or at least videos of some classes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Jukka Suomela has just started a new iteration of his parallel programming 
class, and this year of course everything is online. The videos are 
&lt;a href=&quot;https://www.youtube.com/playlist?list=PL2RY7P3JxZN9Eeu2-XUbD4E4N3UNL6PV8&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MIT has, for example, videos lectures 
&lt;a href=&quot;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-890-algorithmic-lower-bounds-fun-with-hardness-proofs-fall-2014/&quot;&gt;about lower bounds&lt;/a&gt;,
and &lt;a href=&quot;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-851-advanced-data-structures-spring-2012/&quot;&gt;advanced data structures&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;online-conferences&quot;&gt;Online conferences&lt;/h2&gt;

&lt;p&gt;Conferences that were suppose to take place this spring or this summer decide one
by one to held virtually. This is the case of &lt;a href=&quot;https://icalp2020.saarland-informatics-campus.de/&quot;&gt;ICALP&lt;/a&gt;
and &lt;a href=&quot;http://acm-stoc.org/stoc2020/&quot;&gt;STOC&lt;/a&gt; for example.&lt;/p&gt;

&lt;p&gt;The ACM issued a guide on how to organize such online conferences. The pdf is 
&lt;a href=&quot;https://people.clarkson.edu/~jmatthew/acm/VirtualConferences_GuideToBestPractices_CURRENT.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Tue, 14 Apr 2020 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///online-talks</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///online-talks</guid>
      </item>
    
      <item>
        <title>Network decomposition 2&amp;#58; Impact on distributed algorithms</title>
        <description>&lt;p&gt;This is the second post of a series on distributed network decomposition. 
The introductory post of this series is 
&lt;a href=&quot;https://discrete-notes.github.io/network-decomposition-0&quot;&gt;here&lt;/a&gt;. 
This post explains why network decomposition is useful.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/caravane-2.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;recap-of-previous-episodes&quot;&gt;Recap of previous episodes&lt;/h3&gt;

&lt;p&gt;We saw in the 
&lt;a href=&quot;https://discrete-notes.github.io/network-decomposition-1-local-algorithms&quot;&gt;first post&lt;/a&gt; 
of the series that one can simulate the greedy centralized algorithm in the local 
model, by using the identifiers as a schedule, but that this was horribly slow.
We also looked at an algorithm that gather the whole topology of the graph, this
will be useful here.&lt;/p&gt;

&lt;h2 id=&quot;everything-is-easier-with-a-coloring&quot;&gt;Everything is easier with a coloring&lt;/h2&gt;

&lt;p&gt;It is easy to see how we could use less time steps to run the greedy algorithm: 
if you have two nodes that are far enough one from the other, you can select 
both without running into trouble. And then instead of two, you can select a
large number of nodes, as long as they are far away one from the other. 
This way in one round you can select and de-select a lot of nodes.&lt;/p&gt;

&lt;p&gt;Now, more generally, imagine that a mysterious friend gives you a (proper) 
$k$-coloring of the graph. You can use it to parallelize the algorithm the 
following way. First, pick the first color, select all of its nodes, de-select 
all the nodes adjacent to these nodes. This cannot create a problem as the nodes
of a color class cannot be adjacent. Then continue by doing the same with the 
nodes of the second color that are still active. And so on and so 
forth, until you have considered all the colors.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-coloring-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-coloring-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-coloring-3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-coloring-4.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This algorithm basically takes $k$ times steps, which is awesome if your mysterious 
friend gave you a 10-coloring.&lt;/p&gt;

&lt;p&gt;Now there are two problems:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;You do not have a mysterious friend, and computing a good coloring yourself is 
essentially as hard as computing the MIS.&lt;/li&gt;
  &lt;li&gt;The graph might not be colorable with a small number of colors: maybe it’s
chromatic number is $n/2$, and then the algorithm takes $n/2$ rounds, which is 
not much better than before.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;network-decomposition-to-the-rescue&quot;&gt;Network decomposition to the rescue&lt;/h2&gt;

&lt;p&gt;The idea of network decomposition is to relax the strong constraints of a 
coloring into something more handy, while keeping the idea of a schedule of the 
type:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;All nodes of group 1 do something and all the others are passive. At the end 
of this phase, they all have an output.&lt;/li&gt;
  &lt;li&gt;All nodes of group 2 do something and all the others are passive. At the end 
of this phase, they all have an output.&lt;/li&gt;
  &lt;li&gt;Etc.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In a nework decomposition, instead of having a coloring “at the level of the nodes” that 
is where every node has a color different from its neighbors, we will color 
clusters of nodes and have a coloring “at the level of the clusters”. In some 
sense we change scale. A network decomposition looks a bit like this.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/impact-decompo-6.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now there are three questions: What is exactly a network decomposition? 
How to use it? and How to compute it?&lt;/p&gt;

&lt;h2 id=&quot;definition&quot;&gt;Definition&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Definition&lt;/em&gt; A network decomposition with parameters $c$ and $d$ is a labeling of 
the nodes with colors from 1 to $c$, such that for any given color, the (maximal)
connected components with this color have diameter at most $d$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/impact-decompo-5.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;50%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;[There are some subtleties with the definition, but let’s wait a bit before 
looking into that.]&lt;/p&gt;

&lt;p&gt;So for example a proper $k$-coloring is a network decomposition with parameter 
$d=1$ and $c=k$. Also it is easy to have a network decomposition with parameters
$d=n$ and $c=1$: color all nodes with color 1. 
In all this series of posts, what we will look for is a decomposition where both 
parameters are (poly)logarithmic in $n$.&lt;/p&gt;

&lt;h2 id=&quot;how-to-use-it&quot;&gt;How to use it?&lt;/h2&gt;

&lt;p&gt;We cannot use the exact same strategy as when we had a proper coloring. Indeed, 
in a network decomposition several nodes of the same color can be adjacent, thus 
they cannot just wake up and select themselves. 
Now it’s useful to remember the last part of the previous post about a general
algorithm to solve any problem in time $O(n)$. 
Basically this algorithm was doing the following: at any point in time, every 
node sends to its neighbors everything it knows about the graph so far. Then
steps by steps we have the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;When it starts a node knows only its identifier, and it sends it to its 
neighbors.&lt;/li&gt;
  &lt;li&gt;Then it receives the identifiers of its neighbors, thus in some sense it knows 
the graph at distance one around itself: it knows its degree and the IDs of its 
neighbors.&lt;/li&gt;
  &lt;li&gt;Then the node sends this information to its neighbors, and it recives the 
analogue information from its neighbors. With this, it can reconstruct its 
neighborhood at distance 2. That is, it is exactly the same as if it could see 
at distance 2 in the graph.&lt;/li&gt;
  &lt;li&gt;Iterating this process, after $k$ steps all nodes know their neighborhoods 
at distance $k$.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In the proof of the general $O(n)$ algorithm, we iterated this process until 
every node could see all the graph. That is we waited for $D$ steps, where $D$ 
is the diameter of the graph (and then as $D \leq n$, we got the result). But this 
process can be useful even if we do not wait up to $D$ rounds, that is, even if 
the nodes do not see the whole graph.&lt;/p&gt;

&lt;p&gt;Given the network decomposition, let’s start by activating all the nodes of 
color 1. Now use the protocol above, for $d$ rounds. After this time, a node of
color 1 knows all the nodes of its connected component. Indeed it can see at 
distance $d$ and we have been promised that the diameter of each connected 
component is at most $d$. Once this is done, we ask each node of the connected 
component to forget about the rest of the graph, to compute an MIS in what 
remains, and to output whether it is selected or not in this MIS. Note that it 
is exactly the same thing as what we did in the previous post but on a subgraph.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/impact-decompo-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/impact-decompo-3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;At the end of the phase, we have only selected and non-selected nodes in all the 
connected components of the first color. Note that these local MIS are correct, 
in the sense that there is no conflict: two connected components are necessarily 
non-adjacent (otherwise they wouldn’t be maximal). To finish this phase with the 
first color class, we de-select the nodes of the other color classes that are 
adjacent to a newly selected node of the first color class. After this step, all
these nodes will not participate in the computation, and we can imagine that 
they are removed from the graph&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/impact-decompo-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/impact-decompo-4.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can iterate this for all the color classes, just as we did when we had a 
proper coloring. Let us check the complexity. For each color we need the view at 
distance $d$, which takes $d$ rounds, and there are $c$ colors, so we have an 
algorithm in basically $d\times c$ rounds. As we look for a network decomposition 
with polylogarithmic parameters, this gives us a polylogarithmic algorithm, 
which is awesome!&lt;/p&gt;

&lt;p&gt;But now we need to be able to build the network decomposition fast. This is the 
core topic of this series of posts.&lt;/p&gt;

</description>
        <pubDate>Fri, 10 Apr 2020 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///network-decomposition-2-impact</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///network-decomposition-2-impact</guid>
      </item>
    
      <item>
        <title>Network decomposition 1&amp;#58; Local algorithms</title>
        <description>&lt;p&gt;This the first real post of a series on distributed network decomposition. 
The introductory post of this series is 
&lt;a href=&quot;https://discrete-notes.github.io/network-decomposition-0&quot;&gt;here&lt;/a&gt;. 
This post is a quick introduction to local algorithms, with the example of the
maximal independent set problem. If you have heard about the local model before, 
you probably know everything in this post.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/caravane-1.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;a-problem58-computing-a-maximal-independent-set&quot;&gt;A problem: computing a maximal independent set&lt;/h2&gt;
&lt;p&gt;A typical problem of network distributed computing is computing a 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Maximal_independent_set&quot;&gt;maximal independent set&lt;/a&gt;
(MIS). An MIS is a set $S$ of nodes of the graph such that not two nodes of $S$
are adjacent, and for every node not in $S$, there is neighbor in $S$.&lt;/p&gt;

&lt;p&gt;The two pictures below &lt;em&gt;do not&lt;/em&gt; represent an MIS: the first one 
because of two adjacent selected nodes, and the second because of an “isolated node”.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-arete.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-noeud.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The two following pictures represent MISs. Note that one in &lt;em&gt;maximum&lt;/em&gt; (it has 3 
nodes, and no MIS on 4 nodes exists), but the other is just maximal, and it’s 
also fine.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-maxi.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt; &lt;img src=&quot;assets/MIS-pas-maxi.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;easy-to-solve-in-a-centralized-manner&quot;&gt;Easy to solve in a centralized manner&lt;/h2&gt;

&lt;p&gt;It’s very easy to solve this problem in a centralized manner. 
An algorithm is the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Label all nodes as &lt;em&gt;active&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;As long as it is possible:&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Take an arbitrary active node&lt;/li&gt;
  &lt;li&gt;Put it in the MIS&lt;/li&gt;
  &lt;li&gt;Label this node and all its neighbors as &lt;em&gt;inactive&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-seq-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-seq-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/MIS-seq-3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A first problem for us, with this algorithm, is that it is not distributed: you
need an external entity to chose the “arbitrary active node”. This is some kind 
of scheduler, who decides which node is “doing something” at any step.&lt;/p&gt;

&lt;h2 id=&quot;using-identifiers-to-simulate-a-centralized-scheduler&quot;&gt;Using identifiers to simulate a centralized scheduler&lt;/h2&gt;

&lt;p&gt;In our model, we will assume that every node has a unique identity. This 
identifier is a number in $[1,n^2]$, where $n$ is the size of the netork 
(in general we take a large enough 
polynomial for the upper bound, but for concreteness let’s say $n^2$). 
For a node $v$, let $ID(v)$ be its identifier.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/MIS-ID.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;65%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Using these identifier we will simulate the centralized scheduler.&lt;/p&gt;

&lt;p&gt;All nodes start at the same time, and follow time steps (time-step= 1, 2, 3 etc. ).
They start with a status that is &lt;em&gt;active&lt;/em&gt;.
The following algorithm is run at all nodes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If time-step = $ID(v)$ and status = &lt;em&gt;active&lt;/em&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Change status to &lt;em&gt;selected&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Send message “selected” to all neighbors&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;If the time-step $\neq ID(v)$ and status = &lt;em&gt;active&lt;/em&gt;:&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;Wait for a message “selected” from neighbors&lt;/li&gt;
  &lt;li&gt;If one arrives, change status to &lt;em&gt;not selected&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;One can check that on our example, with the identifier given above, the run of 
the algorithm simulates the run of the centralized algorithm. Another identifier 
assignment would correspond to another centralized scheduler, and would give 
another MIS.&lt;/p&gt;

&lt;p&gt;Note that the algorithm is correct because the identifiers are all distinct. 
Indeed, if two neighbors had the same identifier, they would be selected at the 
same time, and the outcome would not be an MIS.&lt;/p&gt;

&lt;p&gt;Now to evaluate the performance of a local algorithm, we measure the number of 
time steps before the solution is completed. Here it is $n^2$ in general, as 
one would have to wait for the node with the largest identifier. 
This is a very poor complexity. Indeed we finish this post with a proof that any
problem can be solved in $O(n)$ time steps.&lt;/p&gt;

&lt;h2 id=&quot;general-algorithm-in-on-steps&quot;&gt;General algorithm in $O(n)$ steps&lt;/h2&gt;

&lt;p&gt;Consider the following algorithm (that is described partially by the pictures 
below).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Send identifier to all neighbors&lt;/li&gt;
  &lt;li&gt;Receive the identifier of all neighbors, and build the list of the adjacent 
edges, e.g. $(ID(v),ID(w))$ for a node $v$ receiving a message from a neighbor 
$w$.&lt;/li&gt;
  &lt;li&gt;Send these edges to all neighbors.&lt;/li&gt;
  &lt;li&gt;For $n$ time steps: send the set of all the edges received so far.&lt;/li&gt;
  &lt;li&gt;Then build a local copy of the graph, solve the problem on this copy, and 
output the part of the solution that correspond to the node.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following set of pictures shows how the information about the existence of
the egde (2,5) is built and then broadcasted to the whole graph.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/flooding-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt; &lt;/td&gt;
      &lt;td&gt; &lt;img src=&quot;assets/flooding-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/flooding-3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This algorithm is correct because after $n$ steps of flooding, all nodes know 
about all the edges, thus the local copy of the graph that each node has is 
correct, and then the output of the algorithm is also correct.&lt;/p&gt;

</description>
        <pubDate>Thu, 09 Apr 2020 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///network-decomposition-1-local-algorithms</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///network-decomposition-1-local-algorithms</guid>
      </item>
    
      <item>
        <title>Network decomposition&amp;#58; Introduction</title>
        <description>&lt;p&gt;This post is an introduction (and a table of contents) for a series of posts on
distributed network decomposition.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/caravane-0.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;90%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One of the important papers of these recent years in distributed graph 
algorithms will appear at STOC this summer:&lt;/p&gt;

&lt;p&gt;“Polylogarithmic-Time Deterministic Network Decomposition and Distributed 
Derandomization” by &lt;a href=&quot;https://n.ethz.ch/~rozhonv/&quot;&gt;Václav Rozhoň&lt;/a&gt; and 
&lt;a href=&quot;https://people.inf.ethz.ch/gmohsen/&quot;&gt;Mohsen Ghaffari&lt;/a&gt; from ETH Zurich.&lt;/p&gt;

&lt;p&gt;It is basically the description of a distributed algorithm that performs what is 
called a &lt;em&gt;network decomposition&lt;/em&gt;, faster than before. This decomposition can 
then be used to do many other things fast, and the paper solves several important 
open problems of the field.&lt;/p&gt;

&lt;p&gt;I quickly looked at the paper when it appeared on arxiv, but I want to 
understand it better, and writing a series of posts about it is good way to do 
this.&lt;/p&gt;

&lt;p&gt;Here is the my current plan for this series:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://discrete-notes.github.io/network-decomposition-1-local-algorithms&quot;&gt;Local algorithms&lt;/a&gt;&lt;/em&gt;, 
an introduction to local algorithm, with the example of 
the maximal independent set problem.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;&lt;a href=&quot;https://discrete-notes.github.io/network-decomposition-2-impact&quot;&gt;Impact for distributed algorithms&lt;/a&gt;&lt;/em&gt;, 
that is, why is a network decomposition so useful.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Centralized construction&lt;/em&gt;, in particular, why such decomposition with good 
parameters exist.&lt;/li&gt;
  &lt;li&gt;(and more) TBA&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 08 Apr 2020 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///network-decomposition-0</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///network-decomposition-0</guid>
      </item>
    
      <item>
        <title>Notes from pre-COVID19 times</title>
        <description>&lt;p&gt;Hi there! After abruptly coming back to France because of the virus, I resume
blogging (instead of traveling, basically). Here is a set of notes that I wrote 
before the quarantine and everything.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/grafitti-donut.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;95%&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;shapley-value&quot;&gt;Shapley value&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Shapley_value&quot;&gt;Shapley value&lt;/a&gt; 
is a concept in game theory. It basically describes how a 
group of players that have played collaboratively, should share the pay-off of 
the game, taking into account that some players have contributed more than others. 
In other words, it is a way to measure how important is each player for the team. 
For some settings it is proved to be the optimal way to share the gain, with 
respect to some objective of fairness.&lt;/p&gt;

&lt;p&gt;The setting is the following. There are $N$ players, $1,2, …, N$, and a 
function $f$ from the subsets of players to the set of possible pay-offs (eg $R$). 
For a subset $S$ of players, $f(S)$ is the pay-off that the players of $S$ would 
get as a whole if they were to collaborate together.&lt;/p&gt;

&lt;p&gt;Now, assume that all players collaborate, and get some pay-off $P$. How should 
we distribute $P$, using $f$? The idea is the following. First chose an 
arbitrary order on the players, for simplicity, let say the natural order $1, 2, 
…,N$. Then player $1$, gets $f(${$1$}$)$, player $2$ gets $f(${$1,2$}$) - 
f(${$1$}$)$ etc. 
That seems pretty reasonable: every player gets the marginal value it adds
to the pay-off. Now this is not always fair, because of the ordering that we 
chose arbitrarily. Therefore one normalizes this by taking the average over all 
permutations of the individual pay-offs. This is the Shapley value.&lt;/p&gt;

&lt;p&gt;[Thanks to &lt;a href=&quot;https://perso.univ-st-etienne.fr/remila/&quot;&gt;Eric Remila&lt;/a&gt; for telling 
me about this.]&lt;/p&gt;

&lt;h2 id=&quot;stochastic-dominance&quot;&gt;Stochastic dominance&lt;/h2&gt;

&lt;p&gt;Stochastic dominance is a concept of probability that is useful in (algorithmic) 
game theoretical settings, such as 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Secretary_problem&quot;&gt;secretary-type problems&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let $A$ and $B$ be two real random variables. Then $A$ 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_dominance&quot;&gt;stochastically dominates&lt;/a&gt;
$B$ if for every $x$, $P(A\geq x)\geq P(B\geq x)$, and for some x, the 
inequality is strict. In terms of cumulative distribution function, this means 
$F_A(x)\leq F_B(x)$ for all $x$, and with strict inequality for some $x$.&lt;/p&gt;

&lt;p&gt;This notion is useful in the randomized online setting: you want to show that 
your online algorithm obtains, in expectation, at least half the payoff of a 
“prophet” that would play knowing all the game in advance. Then 
it is sometimes useful to show that your algorithm stochastically dominates 
“half the prophet”.&lt;/p&gt;

&lt;p&gt;[I heard about this by working in the group of José Correa in Santiago de Chile.]&lt;/p&gt;

&lt;h2 id=&quot;polygonization-a-problem-not-known-to-be-easy-or-hard&quot;&gt;Polygonization, a problem not known to be easy or hard&lt;/h2&gt;

&lt;p&gt;There are not so many reasonable problems for which we have neither a 
polynomial-time algorithm nor a proof of NP-hardness. Some well-known are 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_isomorphism_problem&quot;&gt;graph isomorphism&lt;/a&gt; and 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Integer_factorization&quot;&gt;integer factorization&lt;/a&gt;.
Wikipedia has a list in its 
&lt;a href=&quot;https://en.wikipedia.org/wiki/NP-intermediate&quot;&gt;NP-intermediate article&lt;/a&gt;.
Here is a counting problem that falls into this category.&lt;/p&gt;

&lt;p&gt;A polygonization of a set of points is a simple polygon that visits all the 
points. In the following picture, the points are black and a polygonization is 
drawn in blue.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/polygonization.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The algorithmic problem is: given the point set, count the number of 
polygonizations it has.&lt;/p&gt;

&lt;p&gt;See the two posts by Eppstein on special aspects of this problem, 
&lt;a href=&quot;https://11011110.github.io/blog/2020/01/12/counting-grid-polygonalizations.html&quot;&gt;here&lt;/a&gt; 
and 
&lt;a href=&quot;https://11011110.github.io/blog/2020/01/29/unflippable-polygon.html&quot;&gt;there&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;liquid-rope-coiling-and-discrete-model&quot;&gt;Liquid rope coiling and discrete model&lt;/h2&gt;

&lt;p&gt;When you pour some honey on a pancake, you can see that the honey behaves a bit 
like a rope and can get some rotational movement when touching the pancake. 
Something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/miel.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;[See also &lt;a href=&quot;https://www.youtube.com/watch?v=lZbOV8BIOt8&quot;&gt;this video&lt;/a&gt; by Jearl 
Walker.]&lt;/p&gt;

&lt;p&gt;Something strange about this is that there is no reaon a priori for the movement
to be rotational: it’s just something (the honey) falling on something else 
(the pancake). I was curious whether this could appear in a very simple discrete 
model.
I started thinking about a sandpile model (like the one mentioned 
&lt;a href=&quot;https://discrete-notes.github.io/october-2019-notes-distances&quot;&gt;here&lt;/a&gt; recently) 
to simulate the behaviour of the honey, but at the end I tried to design the 
most simple model that would “create rotation”. Here is a naive model, that does 
not have a sandpile flavour (and probably makes little sense), but shows some 
rotation, without explicitely refering to a rotation.&lt;/p&gt;

&lt;p&gt;Start with an hexagonal grid representing the pancake (because it’s easier than 
a square grid). The yellow cell is where the honey is currently arriving, and 
the orange circle is the projection of the origin of the honey (e.g. the spoon) 
on the pancake.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/miel1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now there are two forces. One is the “speed” of the yellow patch, that simulates
the fact that the honey tends to go where there is less honey, and the very last 
cell visited has more, so is repulsive. It is represented by the yellow 
arrow. The other one is the attraction of the orange circle, that simulates the 
fact that the honey is still “tied” to the spoon. It is represented by an 
orange arrow. Now the average of the two forces is the red arrow, that is 
pointing to the next cell.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/miel2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The proccess is repeated, and the yellow patch is circulating around the 
cell with a orange circle.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/miel3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Well it’s not a very fancy model, in particular it doesn’t make a difference 
between honey on a pancake, and a planet around the sun, but maybe it can be 
improved..!&lt;/p&gt;

&lt;p&gt;Anyway, physicists prefer continuous models, and a paper about the modelization 
of liquid rope coiling is available 
&lt;a href=&quot;https://www.annualreviews.org/doi/10.1146/annurev-fluid-120710-101244&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;[I learned about research on liquid rope coiling in 
&lt;a href=&quot;https://www.pourlascience.fr/sd/physique/les-acrobaties-des-filaments-liquides-8027.php&quot;&gt;this article&lt;/a&gt;
in the French popularization magazine “Pour la science”.]&lt;/p&gt;

&lt;h2 id=&quot;other-notes&quot;&gt;Other notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A latex commands that some of my coauthors didn’t know: 
&lt;code&gt;\scalebox{x}{picture}&lt;/code&gt; allows to scale a picture by a factor x.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;After trying various techniques and packages to write comments in latex files, 
I ended up simply using text in color with 
&lt;code&gt;\textcolor{color name}{text}&lt;/code&gt;, but sometimes (eg for the revision of
a journal paper), one needs to color a large patch of text, and 
&lt;code&gt;textcolor&lt;/code&gt; does not allow this. For example you cannot color two 
sections. Then I rediscovered, that one can simply change the text color at any 
point with &lt;code&gt;\color{color name}&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Eppstein has a 
&lt;a href=&quot;https://11011110.github.io/blog/2020/02/22/applications-maximum-matching.html&quot;&gt;blog post&lt;/a&gt; 
about applications of maximum matching algorithms, including kidney exchange, on 
which I have worked recentely. 
(As &lt;a href=&quot;./march-2019-notes-1&quot;&gt;already mentionned&lt;/a&gt; on this blog, 
&lt;a href=&quot;https://cstheory.stackexchange.com/questions/19759/core-algorithms-deployed&quot;&gt;here&lt;/a&gt; 
is a stack exchange thread on “core algorithms deployed”.)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 01 Apr 2020 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///notes-pre-COVID19</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///notes-pre-COVID19</guid>
      </item>
    
      <item>
        <title>First 2020 notes</title>
        <description>&lt;p&gt;The first set of notes of 2020.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/pinguinos.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;95%&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
Magellanic penguins.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;conference-model-outcome-of-the-podc-survey-and-remote-attendance&quot;&gt;Conference model: outcome of the PODC survey and remote attendance&lt;/h2&gt;

&lt;p&gt;As &lt;a href=&quot;./mid-november-2019-non-technical&quot;&gt;reported here&lt;/a&gt; in November, the
community of the theory of distributed computing is in the process of
changing some aspects of its conference model. A survey has been proposed
that has received many answers. The email summarizing these answers
is &lt;a href=&quot;https://listserv.acm.org/SCRIPTS/WA-ACMLPX.CGI?A2=PODC;3b2ab6fa.1911&amp;amp;S=&quot;&gt;here&lt;/a&gt;.
It is fairly short, and I don’t have much to say, so I’ll just list 
the topics discussed:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;changing to several deadlines a year, to avoid a large gap between
important deadlines,&lt;/li&gt;
  &lt;li&gt;a transition to a system with a journal,&lt;/li&gt;
  &lt;li&gt;collocation of the two main conferences.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A topic mentioned in a previous mail was that this kind of survey is 
more useful than business meetings: in a business meeting, most people are 
afraid to talk, some people are very vocal and do not let others talk, 
and more importantly, it’s late, and everybody wants to leave the room.&lt;/p&gt;

&lt;p&gt;Another related text is by Moshe Vardi in the Communication of the ACM, 
see 
&lt;a href=&quot;https://cacm.acm.org/magazines/2020/1/241717-publish-and-perish/fulltext&quot;&gt;here&lt;/a&gt;.
He basically says that conferences have a big environmental impact, and 
that we should allow people to participate via video. 
The usual answer to this is that you would loose a lot of informal 
interaction between participants. He says he thinks it’s not as bad as 
it looks.&lt;/p&gt;

&lt;h2 id=&quot;selfish-routing-andtraffic-lights&quot;&gt;Selfish routing and traffic lights&lt;/h2&gt;

&lt;p&gt;A &lt;a href=&quot;https://arxiv.org/pdf/1912.06513.pdf&quot;&gt;recent paper&lt;/a&gt; on the arxiv, 
consider the classic model of routing but with traffic lights. 
As discussed recently on this blog (see &lt;a href=&quot;./price-anarchy-flows&quot;&gt;here&lt;/a&gt;)
a classic problem in algorithmic game theory is to evaluate how good is 
the traffic on a network, if you allow each car to chose selfishly the 
best route. 
A surprising phenomenon in this model is that sometimes opening a new 
street can slow down the traffic 
(&lt;a href=&quot;https://en.wikipedia.org/wiki/Braess%27s_paradox&quot;&gt;Braess’s paradox&lt;/a&gt;). 
The authors show that this does not 
happen when the network is equipped with some traffic lights.&lt;/p&gt;

&lt;h2 id=&quot;sunset-geometry&quot;&gt;Sunset geometry&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Which of the two pictures below looks more like a sunset over a very 
calm lake?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/sunset-geometric.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;100%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If the Earth is flat then it’s the one on the left. If it’s spheric, it’s 
the one on the right, and you can even compute the radius of the planet
from the picture!&lt;/p&gt;

&lt;p&gt;See &lt;a href=&quot;https://vanderbei.princeton.edu/tex/sunset/ms.pdf&quot;&gt;this&lt;/a&gt; for an 
explanation using trigonometry, and 
&lt;a href=&quot;https://www.shapeoperator.com/2016/12/12/sunset-geometry/&quot;&gt;that&lt;/a&gt; for 
one using geometric algebra.&lt;/p&gt;

&lt;p&gt;[I learned about this on &lt;a href=&quot;https://11011110.github.io/blog/&quot;&gt;Eppstein’s blog&lt;/a&gt;.]&lt;/p&gt;

&lt;h2 id=&quot;other-notes&quot;&gt;Other notes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A bit more of geometry if you read French or Spanish: the former flag 
of Chile has a very nice geometric construction. See 
&lt;a href=&quot;http://images.math.cnrs.fr/Un-drapeau-en-or-perdu-dans-l-histoire.html?lang=fr&quot;&gt;here&lt;/a&gt;
for the article in French, and 
&lt;a href=&quot;http://images.math.cnrs.fr/Una-bandera-aurea-perdida-en-la-historia.html&quot;&gt;here&lt;/a&gt;
in Spanish.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://dblp.uni-trier.de/&quot;&gt;DBLP&lt;/a&gt; now keeps track of the citations of 
the papers. You can access them by clicking on the page symbol close to 
the colored square. Not all the citations are present because they use 
an open access database, and of course, not everything is open.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I used to use &lt;a href=&quot;http://latexdraw.sourceforge.net/index.html&quot;&gt;latexdraw&lt;/a&gt;
to generate pictures that can be included in latex. That is you draw, 
like on a software like Paint, and it generates the code of this picture. 
 Unfortunately the output is only pstricks code, and one would sometimes 
like a tikz code. 
I discovered yesterday &lt;a href=&quot;https://www.mathcha.io/&quot;&gt;mathcha.io&lt;/a&gt; which is an 
online latex editor, and does the same but generates tikz code.
[Thanks to 
&lt;a href=&quot;https://ingenieria.uai.cl/profesor/pedro-montealegre/&quot;&gt;Pedro Montealegre&lt;/a&gt;
for showing me this.]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We mentioned robust statistics 
&lt;a href=&quot;https://discrete-notes.github.io/june-2019-notes&quot;&gt;on this blog&lt;/a&gt; some 
time ago; if you’re interested, there is a survey on the recent advances 
on this topic &lt;a href=&quot;https://arxiv.org/pdf/1911.05911.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Wed, 22 Jan 2020 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///first-2020-notes</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///first-2020-notes</guid>
      </item>
    
      <item>
        <title>Smoothed analysis in distributed computing</title>
        <description>&lt;p&gt;Happy 2020! A short post about smoothed analysis in distributed 
computing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/arbre-patagonie.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;70%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Smoothed_analysis&quot;&gt;Smoothed analysis&lt;/a&gt; is 
about a complexity measure in between the complexity on random instances 
and the complexity on worst-case instances. 
It basically asks about the complexity on the worst instance,
but with a small random permutation.
The goal of this measure is to better capture the complexity observed in
practice.&lt;/p&gt;

&lt;p&gt;For example, the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Simplex_algorithm&quot;&gt;simplex algorithm&lt;/a&gt;
performs very well in practice
but is proved to be exponential in the worst-case. This means
that worst-case complexity is not the right tool to evaluate this algorithm.
But if you consider a bit of noise, then the simplex algorithm becomes 
polynomial! More precisely the complexity is bounded 
by a polynomial in $n$ and $1/\sigma$, where $\sigma$ is the standard 
deviation of the gaussian noise. This somehow explains why the simplex 
is so good in practice: the examples where it is exponential are very 
special constructions, that are eliminated by small perturbations.&lt;/p&gt;

&lt;p&gt;I was recentely asked whether there exists some smoothed analysis 
in network distributed computing. There is actually a 
&lt;a href=&quot;https://arxiv.org/pdf/1911.02628.pdf&quot;&gt;recent paper&lt;/a&gt; that started that. 
It does a smoothed analysis of distributed minimum 
spanning tree.&lt;/p&gt;

&lt;p&gt;A problem with smoothed analysis, or a feature maybe, is that it can be 
made in different ways, in particular a question is: What kind of noise 
do you consider? When there are 
numerical inputs, you can modify these inputs with a gaussian noise. But 
in the case of minimum spanning tree, small perturbations of the weights
do not change much.
More precisely, given a difficult instance, one 
would have to add a noise of the same order of magnitude as the 
weights to break the lower bound. 
Instead, the authors of the paper above consider a model 
where each node is allowed to ask for a new adjacent random edge at 
each round. These new edges have infinite weight thus they are not 
useful for the MST, only for the communication. 
This seems a rather strange model, but I can imagine that a lot of more
natural variants do not make sense.&lt;/p&gt;

&lt;p&gt;More generally, a problem I can see with smoothed 
analysis for the LOCAL model for example, is that it is based on the 
idea that random instances are easy. 
For graphs, a natural choice of random instances, is 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model&quot;&gt;Erdos-Renyi graphs&lt;/a&gt;,
but these are not always easy for distributed algorithms: they are 
sometimes used as lower bound instances (or more precisely they are 
expanders,  and have logarithmic girth, which are two properties that 
often pop up in lower bounds). 
Some graphs that are somehow easy are grids, but I don’t know what kind of 
random transformation you can apply to a graph to make it more grid-like.&lt;/p&gt;

&lt;p&gt;One could also play with the identifiers. For example a random identifier 
assignment often boils down to a randomized algorithms
(see &lt;a href=&quot;https://arxiv.org/abs/1704.05739&quot;&gt;this&lt;/a&gt;), and maybe some slightly 
random assignement could make sense.&lt;/p&gt;
</description>
        <pubDate>Mon, 13 Jan 2020 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///smoothed-analysis</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///smoothed-analysis</guid>
      </item>
    
      <item>
        <title>A cute &quot;open&quot; problem on polygons</title>
        <description>&lt;p&gt;Here is a cute problem that appeared on a chat channel of University of 
Chile a few months ago. To my knowledge this is still open, but as it 
seems rather natural, the answer is probably known somewhere.&lt;/p&gt;

&lt;p&gt;Consider the following transformation: take a polygon in the plane and 
then dilate it along the $x$-axis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/polygon-expansion.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In other words, the $x$ coordinates of the vertices
are multiplied by some expansion factor $\alpha$.
On the picture the expansion factor is $\alpha=2$.&lt;/p&gt;

&lt;p&gt;Now the question is: is it always true that the original polygon fits in 
the dilated polygon? Note that you are allowed to rotate and translate 
these as you like.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/polygon-inclusion.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We have thought a bit about this at some point, and we have a proof for 
triangles, but not much more…&lt;/p&gt;

</description>
        <pubDate>Wed, 11 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///polygon problem</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///polygon problem</guid>
      </item>
    
      <item>
        <title>Price of anarchy for dynamic flows</title>
        <description>&lt;p&gt;This post is about flows from a game theory perspective. 
It originates from a recent talk of 
&lt;a href=&quot;https://sites.google.com/view/timoosterwijk/home&quot;&gt;Tim Oosterwijk&lt;/a&gt; at 
the University of Chile about 
&lt;a href=&quot;https://drive.google.com/file/d/1u-NUQLppaTDdNUUh-BvsXYJ2QH9RM1K9/view&quot;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;a-model-for-dynamic-flows&quot;&gt;A model for dynamic flows&lt;/h2&gt;

&lt;p&gt;We use a model useful to study settings like urban traffic.
The flow is dynamic (that is we do not focus on 
some stationary state) and there 
can be congestion. It is called the &lt;em&gt;fluid queueing 
model&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The network is a graph, and there is one source node where the flow 
enters and one target node where the flow exits. Each edge of the 
network has a delay and a capacity per time unit. 
If more flows enters the edge than the capacity, a (FIFO) queue will 
form inside this edge.&lt;/p&gt;

&lt;p&gt;Maybe a good example is a network where on every edge there is a 
toll. If there is no queue, going through a toll $t$ takes some $s_t$ seconds,
and at most some $c_t$ cars can go through the toll at each second. 
If too many cars arrive, then a queue is forming, that will disappear 
later if not so many cars arrive.&lt;/p&gt;

&lt;h2 id=&quot;objective&quot;&gt;Objective&lt;/h2&gt;

&lt;p&gt;We consider a setting where a constant flow $u_0$ 
enters the network at each unit of time.&lt;/p&gt;

&lt;p&gt;Now at each intersection of degree $d$ a particule of flow can go in 
either of the $d-1$ directions. Given the choice of each particule at 
each intersection, the flow is completely defined, and you can measure 
how fast it is. For example routing every particule through the same edge
of small capacity would in general form a huge queue in this edge and 
make the flow very slow.&lt;/p&gt;

&lt;p&gt;We can consider at least two notions of efficiency: (1) for a given 
time, how much flow exits the network, and (2) for a given amount of flow 
to start with, when does the last particule exits the network. 
We we will consider the second one, called the &lt;em&gt;makespan&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;price-of-anarchy&quot;&gt;Price of anarchy&lt;/h2&gt;

&lt;p&gt;We study the makespan of different strategies for routing the flow.
As often in 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Algorithmic_game_theory&quot;&gt;algorithmic game theory&lt;/a&gt;,
one is interested in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Price_of_anarchy&quot;&gt;price of anarchy&lt;/a&gt;.
On a given instance this price is the ratio of the makespan of the best 
routing strategy divided by the makespan of the strategy where every 
particule optimizes its own travel time. 
In other words, the ratio between the strategy where an oracle decides 
optimally a route for every car, and the strategy where every driver 
optimizes its own travel time. Note that the setting where we let the 
particules (or drivers) decide is a kind of game, and we look at the 
equilibrium of this game. This might be called the &lt;em&gt;selfish&lt;/em&gt; solution.&lt;/p&gt;

&lt;p&gt;The price of anarchy of the problem is the largest 
(the supremum to be precise) price of anarchy among every instance of 
the problem.&lt;/p&gt;

&lt;h2 id=&quot;result&quot;&gt;Result&lt;/h2&gt;

&lt;p&gt;Tim and his co-authors show (among other results) an upper bound of 
$e/(e-1)$ on the price of anarchy for this problem, under some conditions.&lt;/p&gt;

&lt;h2 id=&quot;a-key-open-problem-the-monotonicity-conjecture&quot;&gt;A key open problem: the monotonicity conjecture&lt;/h2&gt;

&lt;p&gt;There is a very neat and puzzling conjecture that, if true, would imply 
that the upper bound above always hold.&lt;/p&gt;

&lt;p&gt;The so-called &lt;em&gt;monotonicity conjecture&lt;/em&gt; states that: if one reduces the 
flow that enters in the network by unit of time (but keeping the total 
amount to push in the network),  then the makespan of the selfish solution 
increases.&lt;/p&gt;

&lt;p&gt;This seems very natural, but it is still open, and sometimes unexpected
things happen in the such games (like in 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Braess%27s_paradox&quot;&gt;Braess’s paradox&lt;/a&gt;)&lt;/p&gt;

</description>
        <pubDate>Thu, 05 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///price-anarchy-flows</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///price-anarchy-flows</guid>
      </item>
    
  </channel>
</rss>
