<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Discrete notes</title>
    <description>Blog</description>
    <link>https://discrete-notes.github.io/</link>
    <atom:link href="https://discrete-notes.github.io//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>A cute &quot;open&quot; problem on polygons</title>
        <description>&lt;p&gt;Here is a cute problem that appeared on a chat channel of University of 
Chile a few months ago. To my knowledge this is still open, but as it 
seems rather natural, the answer is probably known somewhere.&lt;/p&gt;

&lt;p&gt;Consider the following transformation: take a polygon in the plane and 
then dilate it along the $x$-axis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/polygon-expansion.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;250px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In other words, the $x$ coordinates of the vertices
are multiplied by some expansion factor $\alpha$.
On the picture the expansion factor is $\alpha=2$.&lt;/p&gt;

&lt;p&gt;Now the question is: is it always true that the original polygon fits in 
the dilated polygon? Note that you are allowed to rotate and translate 
these as you like.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/polygon-inclusion.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;200px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We have thought a bit about this at some point, and we have a proof for 
triangles, but not much more…&lt;/p&gt;

</description>
        <pubDate>Wed, 11 Dec 2019 00:00:00 -0300</pubDate>
        <link>https://discrete-notes.github.io///polygon problem</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///polygon problem</guid>
      </item>
    
      <item>
        <title>Price of anarchy for dynamic flows</title>
        <description>&lt;p&gt;This post is about flows from a game theory perspective. 
It originates from a recent talk of 
&lt;a href=&quot;https://sites.google.com/view/timoosterwijk/home&quot;&gt;Tim Oosterwijk&lt;/a&gt; at 
the University of Chile about 
&lt;a href=&quot;https://drive.google.com/file/d/1u-NUQLppaTDdNUUh-BvsXYJ2QH9RM1K9/view&quot;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;a-model-for-dynamic-flows&quot;&gt;A model for dynamic flows&lt;/h2&gt;

&lt;p&gt;We use a model useful to study settings like urban traffic.
The flow is dynamic (that is we do not focus on 
some stationary state) and there 
can be congestion. It is called the &lt;em&gt;fluid queueing 
model&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The network is a graph, and there is one source node where the flow 
enters and one target node where the flow exits. Each edge of the 
network has a delay and a capacity per time unit. 
If more flows enters the edge than the capacity, a (FIFO) queue will 
form inside this edge.&lt;/p&gt;

&lt;p&gt;Maybe a good example is a network where on every edge there is a 
toll. If there is no queue, going through a toll $t$ takes some $s_t$ seconds,
and at most some $c_t$ cars can go through the toll at each second. 
If too many cars arrive, then a queue is forming, that will disappear 
later if not so many cars arrive.&lt;/p&gt;

&lt;h2 id=&quot;objective&quot;&gt;Objective&lt;/h2&gt;

&lt;p&gt;We consider a setting where a constant flow $u_0$ 
enters the network at each unit of time.&lt;/p&gt;

&lt;p&gt;Now at each intersection of degree $d$ a particule of flow can go in 
either of the $d-1$ directions. Given the choice of each particule at 
each intersection, the flow is completely defined, and you can measure 
how fast it is. For example routing every particule through the same edge
of small capacity would in general form a huge queue in this edge and 
make the flow very slow.&lt;/p&gt;

&lt;p&gt;We can consider at least two notions of efficiency: (1) for a given 
time, how much flow exits the network, and (2) for a given amount of flow 
to start with, when does the last particule exits the network. 
We we will consider the second one, called the &lt;em&gt;makespan&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;price-of-anarchy&quot;&gt;Price of anarchy&lt;/h2&gt;

&lt;p&gt;We study the makespan of different strategies for routing the flow.
As often in 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Algorithmic_game_theory&quot;&gt;algorithmic game theory&lt;/a&gt;,
one is interested in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Price_of_anarchy&quot;&gt;price of anarchy&lt;/a&gt;.
On a given instance this price is the ratio of the makespan of the best 
routing strategy divided by the makespan of the strategy where every 
particule optimizes its own travel time. 
In other words, the ratio between the strategy where an oracle decides 
optimally a route for every car, and the strategy where every driver 
optimizes its own travel time. Note that the setting where we let the 
particules (or drivers) decide is a kind of game, and we look at the 
equilibrium of this game. This might be called the &lt;em&gt;selfish&lt;/em&gt; solution.&lt;/p&gt;

&lt;p&gt;The price of anarchy of the problem is the largest 
(the supremum to be precise) price of anarchy among every instance of 
the problem.&lt;/p&gt;

&lt;h2 id=&quot;result&quot;&gt;Result&lt;/h2&gt;

&lt;p&gt;Tim and his co-authors show (among other results) an upper bound of 
$e/(e-1)$ on the price of anarchy for this problem, under some conditions.&lt;/p&gt;

&lt;h2 id=&quot;a-key-open-problem-the-monotonicity-conjecture&quot;&gt;A key open problem: the monotonicity conjecture&lt;/h2&gt;

&lt;p&gt;There is a very neat and puzzling conjecture that, if true, would imply 
that the upper bound above always hold.&lt;/p&gt;

&lt;p&gt;The so-called &lt;em&gt;monotonicity conjecture&lt;/em&gt; states that: if one reduces the 
flow that enters in the network by unit of time (but keeping the total 
amount to push in the network),  then the makespan of the selfish solution 
increases.&lt;/p&gt;

&lt;p&gt;This seems very natural, but it is still open, and sometimes unexpected
things happen in the such games (like in 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Braess%27s_paradox&quot;&gt;Braess’s paradox&lt;/a&gt;)&lt;/p&gt;

</description>
        <pubDate>Thu, 05 Dec 2019 00:00:00 -0300</pubDate>
        <link>https://discrete-notes.github.io///price-anarchy-flows</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///price-anarchy-flows</guid>
      </item>
    
      <item>
        <title>Bayesian mechanism design and Yao&#39;s principle</title>
        <description>&lt;p&gt;I attended a talk yesterday about 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Algorithmic_game_theory&quot;&gt;algorithmic game theory&lt;/a&gt; by 
&lt;a href=&quot;https://www.or.tum.de/en/group/alexandrostsigonias/&quot;&gt;Alexandros Tsigonias-Dimitriadis&lt;/a&gt;
as part of Santiago’s &lt;a href=&quot;http://www.dii.uchile.cl/acgo/seminar-acgo/&quot;&gt;AGCO seminar&lt;/a&gt;.
Here are a few elements from this talk.&lt;/p&gt;

&lt;h2 id=&quot;basic-bayesian-auction&quot;&gt;Basic Bayesian auction&lt;/h2&gt;

&lt;p&gt;The very basic setting we are looking at is the following: a client (the bidder)
comes to a seller (the auctioneer) with the goal of buying a particular item. 
The auctioneer has to set a price for the item. 
The bidder knows the maximum price at which she will buy the object (the value 
of the item for her).
If the auctioneer’s price is higher than the bidder’s value, the bidder does not 
buy the item, and if the price is lower then the bidder buys it, but the 
auctioneer “loses” the difference.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bayesian-optimal_mechanism&quot;&gt;Bayesian setting&lt;/a&gt;, 
the bidder’s value is taken following a probability 
distribution, and the auctioneer knows this distribution. 
Then, the expected revenue of the auctioneer is the price she announces, 
multiplied by the probability that this price is lower than the value taken by 
the bidder. In other words, if $F$ is the cumulative probability distribution 
of the value of the bidder, 
then the expected revenue for a price $p$ is $p \cdot (1-F(p))$.
Then the auctioneer chooses a price $p$ that maximizes this quantity.&lt;/p&gt;

&lt;h2 id=&quot;generalizations&quot;&gt;Generalizations&lt;/h2&gt;

&lt;p&gt;One can generalize this to work with several bidders. This is called 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Bayesian-optimal_mechanism#The_Myerson_mechanism&quot;&gt;Myerson mechanism&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The paper of Alexandros and his co-authors 
(&lt;a href=&quot;https://arxiv.org/abs/1907.04220&quot;&gt;Robust Revenue Maximization Under Minimal Statistical Information&lt;/a&gt;)
goes into another direction and explores the setting where the 
auctioneer does not know the full distribution of the bidder, but 
only the mean and an upper bound on the standard deviation. (That’s why it 
is called &lt;em&gt;robust&lt;/em&gt; revenue maximization.) Later they extend it to one 
bidder buying (or not) several items.&lt;/p&gt;

&lt;p&gt;They show matching upper and lower bounds, and their lower bound
is based on an argument similar to Yao’s minimax principle.&lt;/p&gt;

&lt;h2 id=&quot;minimax-principle&quot;&gt;Minimax principle&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Yao%27s_principle&quot;&gt;Yao’s minimax principle&lt;/a&gt; 
is a general theorem for randomized algorithms. 
Basically it is saying that the best randomized algorithm on its worst instance 
will get the same performance as the best deterministic algorithm on the worst 
distribution of instances. (This needs a precise statement, to say which thing is 
optimized first etc.).&lt;/p&gt;

&lt;p&gt;In the context of Alexandros, the instances are distributions (of which we know
only the mean and an upper bound on the standard deviation) thus a 
distribution of instances is a distribution of distributions. 
This can be made precise, by considering a mixture of distributions.&lt;/p&gt;

</description>
        <pubDate>Thu, 21 Nov 2019 00:00:00 -0300</pubDate>
        <link>https://discrete-notes.github.io///bayesian-auctions</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///bayesian-auctions</guid>
      </item>
    
      <item>
        <title>More November notes</title>
        <description>&lt;p&gt;Some more notes for November 2019.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/nueva-constitucion.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;network-creation-game&quot;&gt;Network creation game&lt;/h2&gt;

&lt;p&gt;Network generation models are mechanisms to create networks. 
In a classic setting the nodes arrive one after the other and are linked 
to nodes already in 
the network following some rules. 
In another setting, called &lt;em&gt;network creation game&lt;/em&gt; the nodes are players, 
and they play a game in which they can choose to pay to be linked to 
other nodes. 
The outcome of the game is a network. 
The cost that a player pays is $\alpha$ for every node it decides to be 
linked to, plus 
the sum of the distances from this node to all the other nodes. 
In other words, a node wants to have short distance to every node, but 
cannot add a link to every node, because it would be too expensive.&lt;/p&gt;

&lt;p&gt;For this game one can study the usual objects of 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Algorithmic_game_theory&quot;&gt;algorithmic game theory&lt;/a&gt;:
the &lt;a href=&quot;https://en.wikipedia.org/wiki/Nash_equilibrium&quot;&gt;Nash equilibrium&lt;/a&gt; 
and the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Price_of_anarchy&quot;&gt;price of anarchy&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is conjectured that the price of anarchy is constant for 
any value $\alpha$, and &lt;a href=&quot;https://arxiv.org/abs/1909.09799&quot;&gt;this recent preprint&lt;/a&gt; 
makes progress on the conjecture.&lt;/p&gt;

&lt;h2 id=&quot;lempel-ziv-compression-algorithms&quot;&gt;Lempel-Ziv compression algorithms&lt;/h2&gt;

&lt;p&gt;Lempel-Ziv algorithm is a classic compression algorithm (or more 
precisely a classic family of algorithms, are there are several versions). 
A &lt;a href=&quot;https://semidoc.github.io/lagarde-catastrophe&quot;&gt;blog post on Semidoc&lt;/a&gt; 
describes the algorithm and gives an overview of 
&lt;a href=&quot;https://arxiv.org/abs/1707.04312&quot;&gt;this paper&lt;/a&gt; which studies how the compression
rate can change when the original text is changed by one bit.&lt;/p&gt;

&lt;p&gt;Two recent papers on arxiv deal with Lempel-Ziv:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1910.00941.pdf&quot;&gt;The first one&lt;/a&gt; gives a new analysis of 
the fact that Lempel-Ziv is optimal for some models of random text (hidden 
Markov sources)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.10347&quot;&gt;The second one&lt;/a&gt; improves the complexity of 
the algorithm decompressing the text.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;multi-armed-bandit&quot;&gt;Multi-armed bandit&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Multi-armed bandit&lt;/em&gt; is an expression that appears here and there in 
TCS conference, and very often in theoretical machine learning. It is a type of 
problem where one has to make decisions one after the other, to 
maximize some pay-off. Basically, at each round, it has the choice 
between several options called the “arms” of the bandit (like the levers 
of different slot-machines).&lt;/p&gt;

&lt;p&gt;A basic version is the following framework:&lt;/p&gt;

&lt;p&gt;Given: $k$  arms, $T$ rounds.&lt;/p&gt;

&lt;p&gt;In each round $t\in[T]$:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Algorithm picks arm $a_t$.&lt;/li&gt;
  &lt;li&gt;Algorithm observes reward $r_t\in [0,1]$ for the chosen arm.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Pay-off: the sum of the rewards&lt;/p&gt;

&lt;p&gt;The reward for an arm comes from an unknown distribution, but if the 
algorithm chooses an arm repeatedly, it somehow learns this distribution. 
There is already a lot to say on this simple case, and there are a flurry
of papers about this, these days.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1904.07272.pdf&quot;&gt;Here&lt;/a&gt; is a recent introduction 
to multi-armed bandit. Also if you are in Rennes, France, on Wednesday
there is a 
&lt;a href=&quot;https://perso.crans.org/besson/phd/defense/&quot;&gt;PhD defense on this topic&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;delaunay-triangulations-have-perfect-matchings&quot;&gt;Delaunay triangulations have perfect matchings&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Delaunay_triangulation&quot;&gt;Delaunay triangulations&lt;/a&gt; 
are triangulations of point sets in the plane. I recentely learnt that
the graphs that are Delaunay triangulations, always have a perfect 
matching (that is a matching of size $n/2$ if $n$ is even, and $(n-1)/2$
is $n$ is odd).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/delaunay.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;250px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
A point set, its Delaunay triangulation, and the associated graph with a perfect matching.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;A short proof of this appeared on arxiv recently, 
&lt;a href=&quot;https://arxiv.org/pdf/1907.01617.pdf&quot;&gt;here&lt;/a&gt;. (Actually it is a stronger
result that is proved, about the so-called “toughness” of Delaunay 
triangulations.)&lt;/p&gt;

&lt;h2 id=&quot;learning-augmented-algorithms&quot;&gt;Learning-augmented algorithms&lt;/h2&gt;

&lt;p&gt;Learning-augmented algorithms are algorithms that can use informtation
coming from some machine learning source. 
Here is an example.&lt;/p&gt;

&lt;p&gt;Binary search takes $O(\log n)$ in the worst-case. 
Now if you have some neural network (NN) telling you that the element you’re 
looking for is around position $i$, how do you modify your search? 
Well you can begin by testing position $i$. Then, if the NN is not perfect, 
this might not be the right value, but maybe it’s close. Say the value 
you’re looking for is larger. Then you can try to find a position 
that has larger value than your element, for example by doing exponential guesses. 
Once you have both upper and lower bound, you can run the usual binary 
search.&lt;/p&gt;

&lt;p&gt;If the error (that is, the number of positions between your element
and the prediction of the NN) is $\mu$, then your algorithm runs in 
$O(\log \mu)$. This is good: if the prediction is good then you speed up 
the search, and if it’s bad, then you do not loose much.&lt;/p&gt;

&lt;p&gt;In more general terms, one looks for two properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;consistency: the better the prediction, the better the algorithm&lt;/li&gt;
  &lt;li&gt;robustness: if the predition is bad, then the algorithm does not get 
much worse.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that for real application, one might also be interested in the running 
time of the NN, and a lot of other things.&lt;/p&gt;

&lt;p&gt;Some material on this topic:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a &lt;a href=&quot;https://www.mit.edu/~andoni/algoS19/scribes/scribe24.pdf&quot;&gt;lecture note&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://theory.stanford.edu/~sergei/slides/HALG-slides.pdf&quot;&gt;the slides&lt;/a&gt; 
of a talk at &lt;a href=&quot;http://2019.highlightsofalgorithms.org/&quot;&gt;HALG 2019&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.mit.edu/~vakilian/ttic-workshop.html&quot;&gt;a workshop&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Mon, 18 Nov 2019 00:00:00 -0300</pubDate>
        <link>https://discrete-notes.github.io///more-november-2019</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///more-november-2019</guid>
      </item>
    
      <item>
        <title>Mid-November (non-technical) notes</title>
        <description>&lt;p&gt;Some notes about a new conference, a new research organization etc.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/comida-india.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;conference-model-survey&quot;&gt;Conference model survey&lt;/h2&gt;

&lt;p&gt;An online survey has been created &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSfOmbqTTfQfUYEXADCLLqat-OAl7XUh8gFceg27uDfpr_NaaQ/viewform&quot;&gt;here&lt;/a&gt; to gather the opinions of the distributed 
computing community about its model of conferences. Topics include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;changing from one deadline to three deadlines a year. Basically it’s like 
having the reviewing process made three times (with a smaller number of papers), 
and then having a conference with the papers accepted to any of the three phases.&lt;/li&gt;
  &lt;li&gt;collocating the two main conferences of the domain.&lt;/li&gt;
  &lt;li&gt;changing the format (more keynotes, or shorter talks etc.)&lt;/li&gt;
  &lt;li&gt;transitioning to a journal model.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Details can be found in the survey.&lt;/p&gt;

&lt;h2 id=&quot;paper-presentation-videos&quot;&gt;Paper presentation videos&lt;/h2&gt;

&lt;p&gt;One of the side topics of the survey is the possibility for the 
authors to upload a video presenting their papers. It’s something I have thought
of doing for my papers, but finally didn’t try.&lt;/p&gt;

&lt;p&gt;Till Miltzow is a researcher in graph theory and he records a talk for every 
paper he has, see &lt;a href=&quot;https://sites.google.com/view/miltzow/publications&quot;&gt;here&lt;/a&gt;. 
I think it’s good!&lt;/p&gt;

&lt;h2 id=&quot;the-polytcs-project&quot;&gt;The PolyTCS project&lt;/h2&gt;

&lt;p&gt;You may know the &lt;a href=&quot;https://en.wikipedia.org/wiki/Polymath_Project&quot;&gt;Polymath Project&lt;/a&gt;,
which is a project from the math community. It consists in choosing an open problem, 
and then working on this problem in a massively collaborative way: everything is
public, and everyone can help. This project has been quite successful, with great
collaborations, and great papers.&lt;/p&gt;

&lt;p&gt;A similar project has been launched in TCS: 
&lt;a href=&quot;https://polytcs.wordpress.com/&quot;&gt;The PolyTCS project&lt;/a&gt;.
The first problem is about boolean functions, see 
&lt;a href=&quot;https://polytcs.wordpress.com/2019/11/01/the-entropy-influence-conjecture/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;forc-conference&quot;&gt;FORC conference&lt;/h2&gt;

&lt;p&gt;A new conference in TCS: &lt;a href=&quot;https://responsiblecomputing.org/forc-2020-call-for-paper/&quot;&gt;Symposium on the Foundations of Responsible Computing (FORC)&lt;/a&gt;. Topics include privacy, fairness and electoral processes.&lt;/p&gt;

&lt;h2 id=&quot;symbolic-computations-in-python&quot;&gt;Symbolic computations in python&lt;/h2&gt;

&lt;p&gt;I recently had to do a lot of small computations on toy examples. To check the 
computations, I wanted to have some symbolic math software, but the usual
ones (e.g. Maple) are big machines, and often not open-source. If you are in the 
same situation, python with &lt;a href=&quot;https://www.sympy.org/en/index.html&quot;&gt;sympy&lt;/a&gt; is a 
good choice.&lt;/p&gt;

&lt;h2 id=&quot;pull-requests-for-this-blog&quot;&gt;Pull requests for this blog&lt;/h2&gt;

&lt;p&gt;This blog is a github page, that is, it works as a git repository. 
I recently got some pull requests for it, from my friend 
&lt;a href=&quot;https://perso.crans.org/besson/me/index.fr.html&quot;&gt;Lilian Besson&lt;/a&gt;. 
Pull requests is a way to suggest changes, e.g. correct a typo. It is very 
convenient (on my side): I just have to pull these commits. 
If you want to know more and correct one of the many typos of this blog, you can 
take a look at &lt;a href=&quot;https://www.freecodecamp.org/news/how-to-make-your-first-pull-request-on-github/&quot;&gt;this page&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Tue, 12 Nov 2019 00:00:00 -0300</pubDate>
        <link>https://discrete-notes.github.io///mid-november-2019-non-technical</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///mid-november-2019-non-technical</guid>
      </item>
    
      <item>
        <title>October 2019 notes&amp;#58; distances and moving stuff</title>
        <description>&lt;p&gt;Some notes for October 2019, related to distances and to moving stuff.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/farmacia.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;600px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
A lot is going on in Chile. Fortunately there are some good recipes.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;matching-graphs-via-gromov-hausdorff-distance&quot;&gt;Matching graphs via Gromov-Hausdorff distance&lt;/h2&gt;

&lt;p&gt;There are many contexts where one would like to compare two graphs, to 
measure if they are close or not. 
One way of doing this is to decide whether one is included in the other
(the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Subgraph_isomorphism_problem&quot;&gt;subgraph isomorphism problem&lt;/a&gt;) 
or more generally if they have a 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Maximum_common_edge_subgraph&quot;&gt;large isomorphic subgraph&lt;/a&gt;.
Another way is to measure the number of edits one has to make to go from 
one graph to the other (for example the number of edges to add and 
remove). This is what is done in 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Property_testing&quot;&gt;property testing&lt;/a&gt;, where having a 
distance on the objects is essential.&lt;/p&gt;

&lt;p&gt;More generally, there exists a distance for compact metric spaces called 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Gromov%E2%80%93Hausdorff_convergence#Gromov%E2%80%93Hausdorff_distance&quot;&gt;Gromov-Hausdorff distance&lt;/a&gt;, 
that applies to graphs.&lt;/p&gt;

&lt;p&gt;No surprise, this distance is a complicated notion 
(an inf of a max of a sup of an inf),
and computing it is NP-hard. The reduction is to the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Quadratic_bottleneck_assignment_problem&quot;&gt;quadratic bottleneck assignment problem&lt;/a&gt;, 
a &lt;a href=&quot;https://en.wikipedia.org/wiki/Facility_location_problem&quot;&gt;facility location problem&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&quot;https://arxiv.org/pdf/1909.09772.pdf&quot;&gt;fairly recent preprint&lt;/a&gt; studies how to 
estimate a modification of this distance in polynomial time.&lt;/p&gt;

&lt;h2 id=&quot;hardness-of-moving-earth&quot;&gt;Hardness of moving earth&lt;/h2&gt;

&lt;p&gt;Given two point sets of equal size in an Euclidian space, $A$ and $B$, and a 
bijection $f: A \rightarrow B$ , the cost of transporting $A$ to $B$ 
through $f$ is the sum over the elements of $a$ of the distances 
from $a$ to $f(a)$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/earth-moving.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;200px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now given two point sets, the earth mover distance is the minimum such 
distance over all bijection:
$
EMD(A,B)=\min_f \sum_{a\in A} d(a,f(a))
$&lt;/p&gt;

&lt;p&gt;It is the discrete analogue of 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Transportation_theory_(mathematics)&quot;&gt;Monge-Kantorovich metric&lt;/a&gt;
in probability theory, and is used in machine learning.&lt;/p&gt;

&lt;p&gt;Algorithms to compute the EMD are quadratic in $n$, and faster algorithms 
are known for approximation but only in small dimensions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1909.11068&quot;&gt;A recent preprint&lt;/a&gt; proves conditional 
hardness results that explain this situation.&lt;/p&gt;

&lt;h2 id=&quot;complexity-of-sandpiles&quot;&gt;Complexity of sandpiles&lt;/h2&gt;

&lt;p&gt;Sandpile models are models close to cellular automata, based on a grid 
in some dimension $d$, where every cell has a number (the number of 
grains of sand there is at this location), and there is a local rule to 
decide where the grains move at each step.&lt;/p&gt;

&lt;p&gt;There is &lt;a href=&quot;https://arxiv.org/pdf/1909.12150.pdf&quot;&gt;a recent survey&lt;/a&gt; about 
the complexity of predicting the final shape of sandpiles. 
There are some very nice things going on. For example the complexity of 
the prediction is related to the computational power of the sandpile itself:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If the prediction is P-hard, then the sandpile has the computational 
power of a Turing machine.&lt;/li&gt;
  &lt;li&gt;If the prediction is easier then it is not the case.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A classic sandpile model is called the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Abelian_sandpile_model&quot;&gt;abelian sandpile model&lt;/a&gt;
(or Bak–Tang–Wiesenfeld model) and is the following. 
On a grid $Z^d$, the rule is: every node that has $2d$ grains or more 
gives one grain to each neighboring cell.&lt;/p&gt;

&lt;p&gt;Here is an example with $d=1$, and a starting configuration where one 
cell has 5 grains. The cells that have 2 or more grains are “unstable” 
and give one grain to their left neighbor and one grain to their right 
neighbor.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/sandpile.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;180px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that the dynamic is not exactly what you would expect from a real 
sandpile, but it is very simple and has very nice properties.&lt;/p&gt;

&lt;p&gt;For this model, the following hold:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In dimension 1, prediction is in &lt;a href=&quot;https://en.wikipedia.org/wiki/NC_(complexity)&quot;&gt;NC&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;In dimension 3 or more the prediction is P-hard.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The survey gives a lot results, sketches and conjectures.&lt;/p&gt;

&lt;h2 id=&quot;k-opt-ratio-for-tsp&quot;&gt;k-OPT ratio for TSP&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/2-opt&quot;&gt;2-OPT&lt;/a&gt; and its generalization 
k-OPT, are popular heuristics for 
the (metric) &lt;a href=&quot;https://en.wikipedia.org/wiki/Travelling_salesman_problem&quot;&gt;traveling salesman problem&lt;/a&gt;.
They consist in iteratively looking for 2 (respectively $k$ edges) to modify to improve the 
cost of the tour. Here is an example for 2-OPT.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/2opt.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;200px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This heuristic performs poorly in the worst-case: exponential time, and 
approximation ratio in $\theta(\sqrt n)$. But it performs well in practice.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&quot;https://arxiv.org/pdf/1909.12025.pdf&quot;&gt;recent preprint&lt;/a&gt; computes the 
precise approximation ratio for 2-OPT, which is $\sqrt(n)/2$.&lt;/p&gt;

&lt;p&gt;Other papers from the literature prove that :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The approximation ratio is in $O(\sqrt n)$ for random edge weights 
(which are not metric in general), see &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S016763770900011X?via%3Dihub&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;For Euclidian instances, the worst ratio is in $O(\log n)$.&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Smoothed_analysis&quot;&gt;smoothed analysis&lt;/a&gt;
of the problem has been studied, eg &lt;a href=&quot;https://wwwhome.ewi.utwente.nl/~mantheyb/full/MantheyVeenstra_TwoOpt.pdf&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The fine-grain analysis of $k$-OPT has been done &lt;a href=&quot;http://drops.dagstuhl.de/opus/volltexte/2016/6277/pdf/LIPIcs-ICALP-2016-5.pdf&quot;&gt;here&lt;/a&gt;
with improved complexity for $k\geq 4$.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 07 Nov 2019 00:00:00 -0300</pubDate>
        <link>https://discrete-notes.github.io///october-2019-notes-distances</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///october-2019-notes-distances</guid>
      </item>
    
      <item>
        <title>Graph classes and forbidden patterns&amp;#58; Introduction</title>
        <description>&lt;p&gt;Michel Habib and I have quite recentely finished the paper 
&lt;a href=&quot;https://arxiv.org/abs/1812.05913&quot;&gt;Graph classes and forbidden patterns on three vertices&lt;/a&gt;. 
This blog post is the first of a small series that will present the paper.
It follows the structure of a talk I gave yesterday at the University 
of Chile.&lt;/p&gt;

&lt;h2 id=&quot;why-studying-graph-classes&quot;&gt;Why studying graph classes?&lt;/h2&gt;

&lt;p&gt;This paper is about graph classes, and it seems that it is a topic 
that is not popular with everybody, so let’s start with a couple of 
reasons to study graph classes.&lt;/p&gt;

&lt;h4 id=&quot;graphs-are-fundamental-objects&quot;&gt;Graphs are fundamental objects&lt;/h4&gt;
&lt;p&gt;Just like sets and languages, graphs are basic objects, thus gathering 
knowledge about them is useful. For example, the pumping lemma
for regular languages appears in distributed computing, because 
languages are basic objects, and thus they pop up everywhere.&lt;/p&gt;

&lt;h4 id=&quot;to-use-algorithms-in-the-real-world&quot;&gt;To use algorithms in the “real world”&lt;/h4&gt;
&lt;p&gt;If one wants to use algorithms for real-world problems, it is likely 
that looking at results for general graphs is not the most useful 
approach. There is a good proportion of the real-world instances that
belong to very special classes, and if (1) you can recognize such 
special classes fast, and (2) you have a fast algorithm for your problem 
on this class, then you are happy. In other words,
your transportation problem may be hard on expanders, but road networks 
are not expanders, so let’s look at what road networks look like.&lt;/p&gt;

&lt;h2 id=&quot;why-not-studying-graph-classes&quot;&gt;Why &lt;em&gt;not&lt;/em&gt; studying graph classes?&lt;/h2&gt;

&lt;p&gt;To be fair, there is a problem with graph classes: 
there are way too many of them! The website 
&lt;a href=&quot;http://graphclasses.org&quot;&gt;graphclasses.org&lt;/a&gt; lists 1600 classes, and it’s 
difficult to navigate in this jungle, to know what is an interesting
class, to know whether the class you’re working on is known etc.
(although the website is very useful for that).&lt;/p&gt;

&lt;h2 id=&quot;this-paper&quot;&gt;This paper&lt;/h2&gt;
&lt;p&gt;This paper brings a new point of view on some very classic graph classes, 
putting them all in the same framework, with algorithmic consequences.
(Thus it goes in the right direction!).&lt;/p&gt;

&lt;p&gt;Actually “new” should be used with a lot of quotation marks: this point of view 
has been known for a long time for several classes. I cannot cite all 
the papers here, so I’ll cite none of them, but keep in mind that most of 
what I’ll write about is not new. Take a look at the paper if you want 
to see the 70 citations.&lt;/p&gt;

&lt;p&gt;Now, let’s get started with two examples.&lt;/p&gt;

&lt;h2 id=&quot;example-1--forests&quot;&gt;Example 1 : forests&lt;/h2&gt;

&lt;p&gt;Here is a complicated characterization of the forests (e.g. the acyclic 
graphs).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Theorem:&lt;/em&gt; A graph $G=(V,E)$ is a forest, if and only if, there exists an ordering 
of the nodes, such that: there does &lt;em&gt;not&lt;/em&gt; exist three nodes $a&amp;lt;b&amp;lt;c$, with 
 $(a,b)\in E$ and $(a,c)\in E$.&lt;/p&gt;

&lt;p&gt;That is, we forbid this pattern:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/tree.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;100px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof sketch&lt;/em&gt;
$(\Rightarrow)$ : Consider a tree of the forest. Put the leaves 
first in the ordering and remove them from the tree; then repeat 
with the remaining nodes of the tree, until the tree is empty. 
Then move on to the next tree, do the same etc. 
It is easy to check that the pattern will not appear.&lt;/p&gt;

&lt;p&gt;$(\Leftarrow)$ : If the graph is not a forest, then there is a cycle. 
Now consider any ordering of the graph. The node of the cycle that is 
the left-most in the ordering must have both its cycle neighbors on 
its right, thus the pattern appears.&lt;/p&gt;

&lt;h2 id=&quot;example-2--interval-graphs&quot;&gt;Example 2 : interval graphs&lt;/h2&gt;

&lt;p&gt;A more interesting example is interval graphs. Given a set of intervals
$S$, one can define the intersection graph of it, $I(S)$, by creating one 
node for each interval and putting an edge between two nodes if the two 
corresponding intervals intersect.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/interval-1.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;150px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Definition:&lt;/em&gt; A graph $G$ is an interval graph if $G=I(S)$ for some set 
of intervals $S$.&lt;/p&gt;

&lt;p&gt;From the picture above, we know that a path on four vertices is an 
interval graph. A graph that is not an interval graph is the cycle on 
four vertices. Consider the following picture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/interval-2.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;150px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As the red node and the 
blue node are not adjacent, they must correspond to two disjoint 
intervals, and without loss of generality, the red interval comes first. 
The black interval should intersect both the red and the blue intervals. 
Thus it uses the space between these two.
The same holds for the green interval, but the black and the green 
intervals should not intersect, thus the construction is impossible.&lt;/p&gt;

&lt;p&gt;Here is a characterization of interval graphs.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Theorem:&lt;/em&gt; A graph $G=(V,E)$ is an interval graph, if and only if, 
there exists an ordering of the nodes, such that: there does not exist 
three nodes $a&amp;lt;b&amp;lt;c$, with $(a,b)\notin E$ and $(a,c)\in E$.&lt;/p&gt;

&lt;p&gt;In other words, the following pattern is forbidden:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/interval-pattern.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;100px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof sketch:&lt;/em&gt; 
The key idea for the proof is to consider the ordering of the left 
endpoints of the intervals. First, given a set of intervals 
it is easy to see that the ordering given by these left endpoints avoids 
the pattern. Second, to build a set of intervals, given the ordering, 
one just as to put the left endpoint of the intervals in the right order
and then to make put the right endpoint at the spot where the right most 
neighbor starts. (The pattern insures that this construction is correct.)&lt;/p&gt;

&lt;h2 id=&quot;similar-characterizations&quot;&gt;Similar characterizations&lt;/h2&gt;

&lt;p&gt;Thus these two classes can be characterized in a 
similar way: the existence of a vertex ordering that 
avoids some small pattern. Our paper is about understanding what are the
classes that can be defined this way. In the next post, we will define 
this more formally.&lt;/p&gt;

</description>
        <pubDate>Thu, 17 Oct 2019 00:00:00 -0300</pubDate>
        <link>https://discrete-notes.github.io///patterns-1</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///patterns-1</guid>
      </item>
    
      <item>
        <title>Summer-winter notes</title>
        <description>&lt;p&gt;Some notes for summer 2019, or actually winter 2019, as I moved to Chile.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/azotea.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
The Andes.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;queue-number-again-and-applications&quot;&gt;Queue number again, and applications&lt;/h2&gt;

&lt;p&gt;A recent result about the so-called &lt;em&gt;queue number&lt;/em&gt; was mentioned on this blog in March 
(see &lt;a href=&quot;./stoc-socg-picks&quot;&gt;here&lt;/a&gt;). The result says that this graph parameter is bounded 
on planar graph that have bounded degree.
The result has now been generalized to any planar graph! 
The &lt;a href=&quot;https://arxiv.org/pdf/1904.04791.pdf&quot;&gt;paper is on arxiv&lt;/a&gt; and will be presented 
at FOCS 2019.
I haven’t looked into the paper, but I know from 
&lt;a href=&quot;https://11011110.github.io/blog/2019/08/10/report-from-cccg.html&quot;&gt;David Epptein’s blog&lt;/a&gt; 
that it is a byproduct of showing that “every planar graph is a subgraph of a strong 
product of a path graph and a bounded-treewidth graph”.&lt;/p&gt;

&lt;p&gt;Another &lt;a href=&quot;https://arxiv.org/abs/1908.03341&quot;&gt;recent paper on the arxiv&lt;/a&gt; 
uses this result to design shorter labeling schemes for planar graphs.
As the abstract says: 
“In graph-theoretical terms, this implies an explicit construction 
of a graph on $n^{4/3}+o(1)$ vertices that contains all planar graphs 
on n vertices as induced subgraphs”.
(Thanks to Cyril Gavoille for pointing out this paper.)&lt;/p&gt;

&lt;h2 id=&quot;unfolding-polytopes-durers-conjecture&quot;&gt;Unfolding polytopes: Durer’s Conjecture&lt;/h2&gt;

&lt;p&gt;Given a polyhedra, one can cut along the edges to unfold it on the plane as in the following drawing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/durer-1.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But sometimes, if you cut along some edges, you may have an overlap in the unfolding, as the
second unfolding of the 
following  example (borrowed from &lt;a href=&quot;http://mathworld.wolfram.com/Unfolding.html&quot;&gt;here&lt;/a&gt;) shows.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/durer-2.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.openproblemgarden.org/op/d_urers_conjecture&quot;&gt;Durer’s conjecture&lt;/a&gt; states that 
“Every convex polytope has a non-overlapping edge unfolding”.
A non-overlapping edge unfolding is called &lt;a href=&quot;https://en.wikipedia.org/wiki/Net_(polyhedron)&quot;&gt;a net&lt;/a&gt;, 
so the conjecture can be reformulated as: “Every convex polytope has a net”.
It is surprising that such a cute and simple result is still open.&lt;/p&gt;

&lt;p&gt;I learned about this conjecture in 
&lt;a href=&quot;https://11011110.github.io/blog/2019/08/10/report-from-cccg.html&quot;&gt;Eppstein’s report on CCCG&lt;/a&gt;. 
More information can be found in 
&lt;a href=&quot;https://www.mi.fu-berlin.de/math/groups/discgeom/ziegler/Preprintfiles/127PREPRINT.pdf&quot;&gt;Ten Problems in Geometry&lt;/a&gt;
by Moritz W. Schmitt and Günter M. Ziegler.&lt;/p&gt;

&lt;h2 id=&quot;more-on-graphs-inspired-by-objects-and-nature&quot;&gt;More on graphs inspired by objects and nature&lt;/h2&gt;

&lt;p&gt;We had a &lt;a href=&quot;./april-may-2019-notes&quot;&gt;post in april&lt;/a&gt; on graphs that have some meaning 
in terms of real-world objects.&lt;/p&gt;

&lt;p&gt;Two additional pointers on this topic:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a &lt;a href=&quot;https://11011110.github.io/blog/2013/12/07/kinematic-chains-and.html&quot;&gt;blog post&lt;/a&gt; about graph that have one degree of freedom when you want to move them.&lt;/li&gt;
  &lt;li&gt;the &lt;a href=&quot;https://www.ics.uci.edu/~eppstein/pubs/Epp-WADS-19.pdf&quot;&gt;slides&lt;/a&gt; of a talk about graphs inspired by nature, for example by crystals and by bubbles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/cristaux-bulles.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
The red circles are the nodes on the right drawing, but on the left ones they are part of the procedure to draw the crystals. See the slides for more details.
&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;automata-size-to-separate-two-words&quot;&gt;Automata size to separate two words&lt;/h2&gt;

&lt;p&gt;Yet another very simple and still open problem: consider two strings of length $n$, what is the size of the smallest deterministic automaton than accepts one and rejects the other? 
Or more precisely, what is the maximum over all such pairs of this size? 
The upper bound is polynomial in $n$ (something like $\sqrt(n)$) and the lower bound is $\Omega(\log n)$. An exponential gap!&lt;/p&gt;

&lt;p&gt;For more on this see these two posts by Lipton: &lt;a href=&quot;https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/&quot;&gt;here&lt;/a&gt; and
&lt;a href=&quot;https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/&quot;&gt;there&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;other-notes&quot;&gt;Other notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;The paper about the matching lower bound that I mentioned here several times won the best paper award at FOCS! I think it’s a remarkable research story: identifying a fundamental problem, telling everybody about it, learning more and more, and finally solving it, and getting an award for it!&lt;/li&gt;
  &lt;li&gt;Some day, I’ll learn about spanners, I hope. &lt;a href=&quot;https://arxiv.org/pdf/1909.03152.pdf&quot;&gt;Here&lt;/a&gt; is a recent survey that may help.&lt;/li&gt;
  &lt;li&gt;A &lt;a href=&quot;https://arxiv.org/abs/1907.05257&quot;&gt;paper appeared on the arxiv&lt;/a&gt; on the recognition of intersection graphs of objects touching a diagonal line, related to &lt;a href=&quot;https://www.dii.uchile.cl/~feuilloley/publications/rectangles_DCG15.html&quot;&gt;this paper of mine&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 17 Sep 2019 00:00:00 -0300</pubDate>
        <link>https://discrete-notes.github.io///summer-winter-2019-notes</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///summer-winter-2019-notes</guid>
      </item>
    
      <item>
        <title>June notes</title>
        <description>&lt;p&gt;Some notes for June.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/saint-laurent.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;600px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;
&lt;a href=&quot;http://www.st-laurent-de-la-cabrerisse.com/eng/&quot;&gt;Saint Laurent de la Cabrerisse&lt;/a&gt;
where the &lt;a href=&quot;https://www.irit.fr/algotel2019/index.html&quot;&gt;Algotel conference&lt;/a&gt; 
took place.&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;recorded-talks-and-collaborating-virtually&quot;&gt;Recorded talks and collaborating virtually&lt;/h2&gt;

&lt;p&gt;Continuing on the topic of video conferences (e.g. to avoid plane travel),
an important question is: can virtual conferences, and more generally 
communication via video-conference, be really efficient?&lt;/p&gt;

&lt;p&gt;I have to admit that, although I really like the idea of video conference, 
for talks or for work, I have 
difficulties following recorded talks, and I’m not very comfortable with 
video calls. 
Here are the reasons I could find for why video talks and calls are not as good 
as their physical analogues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;in a recorded talk, you can escape, take a coffee, answer an email, that is 
you can “escape the room”, thus you are less focused.&lt;/li&gt;
  &lt;li&gt;videos are less immersive: the sound is bad, what you watch 
occupies a very small part of your visual field, and in a talk you don’t feel 
that you are part of a crowd participating in something.&lt;/li&gt;
  &lt;li&gt;A consequence of the previous bullet is that the experience is socially less 
comfortable: in a real meeting, there can be a long silence and it’s fine, but 
during a video call, it’s often awkward.&lt;/li&gt;
  &lt;li&gt;Also video conferences are very static. This is especially true for talks: the 
main part of the screen is taken by the slide, which moves once every minute on 
average, and even if you see the speaker, you just see a face, no body movements.&lt;/li&gt;
  &lt;li&gt;Related to the previous point: I don’t know good ways to have a shared 
whiteboard when working through video, which reduces a lot the efficiency of the 
conversation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some of these problems are kind of solved by some frameworks. For example 
&lt;a href=&quot;https://sites.google.com/site/plustcs/&quot;&gt;TCS+&lt;/a&gt; is an online seminar where the 
speaker does not record a video alone: it is more like a large video conference
with a dozen of labs connected, and one person giving the talk. (The 
talks are actually recorded so you can watch them offline, but it is not the 
main goal.) 
This means that there is a crowd, and that you cannot escape. Also if you have a 
good video/sound system, then it might be quite immersive. 
I never had the opportunity to test this so I can’t tell.&lt;/p&gt;

&lt;p&gt;Note that some people think the exact opposite of me: they actually prefer 
watching a recorded talk, because it’s offline: you can stop, rethink what was 
said, check a reference, jump to the next section etc. 
Also note that attending a live talk can also be boring, so it also depends a 
lot on the speaker.&lt;/p&gt;

&lt;p&gt;If you know good alternatives to skype (ideally open-source, with a possibility of 
drawing, and multi-users), send me an email. This will be useful not only to me 
but also to other people: I timidly signed to be part of a pool of people 
thinking about such technical topics, in the 
&lt;a href=&quot;https://labos1point5.org/en/home/&quot;&gt;Labo 1.5 collective&lt;/a&gt; I talked about last 
month.&lt;/p&gt;

&lt;h2 id=&quot;terence-tao-on-the-radius-of-the-earth&quot;&gt;Terence Tao on the radius of the Earth&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Terence_Tao&quot;&gt;Terence Tao&lt;/a&gt; has a blog, 
&lt;a href=&quot;https://terrytao.wordpress.com/&quot;&gt;What’s new&lt;/a&gt;. Most of the content is way too 
complicated for me, but once in a while he writes excellent posts about simpler
things. 
A very recent one is 
&lt;a href=&quot;https://terrytao.wordpress.com/2019/05/25/the-spherical-cayley-menger-determinant-and-the-radius-of-the-earth/&quot;&gt;about the radius of the Earth and determinants&lt;/a&gt;. An older one is about 
&lt;a href=&quot;https://terrytao.wordpress.com/2009/03/23/sailing-into-the-wind-or-faster-than-the-wind/&quot;&gt;sailing&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;basic-and-advanced-tools-in-combinatorics&quot;&gt;Basic and advanced tools in combinatorics&lt;/h2&gt;

&lt;p&gt;I have heard that some people tend to despise combinatorics as being “very basic”.
To some extent, my research is very basic: most of the time I consider very 
simple objects, a few edges and a few nodes in a graph. I almost never use 
complicated tools which have been improved over the centuries and which 
need time to master. Sometimes it is a bit unsettling: one can feel like playing
child games, compared to what one was taught at the university.&lt;/p&gt;

&lt;p&gt;On the other hand of course, it is very annoying when people boast about using
complicated stuff, and it is always very nice to find a basic proof of a theorem.&lt;/p&gt;

&lt;p&gt;Something I like is when you have a basic proof that is a bit of a mess, with
many cases for example, and using the point of view of a more general 
theory you suddenly understand things better. I had this experience with some 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Matroid&quot;&gt;matroid&lt;/a&gt; structure in
&lt;a href=&quot;https://pages.lip6.fr/Laurent.Feuilloley/publications/error_sensitive.html&quot;&gt;this paper&lt;/a&gt;
(although it does not appear at all in the final write-up).&lt;/p&gt;

&lt;p&gt;I was reminded of this by 
&lt;a href=&quot;https://11011110.github.io/blog/2019/05/25/more-matching-mimicking.html&quot;&gt;this post&lt;/a&gt;
on David Eppstein’s blog, where he describes a new point of view he has on a 
matching problem thanks to a more advanced notion of matroid (yes matroids, again).&lt;/p&gt;

&lt;h2 id=&quot;john-ellipsoid-and-the-s&quot;&gt;John ellipsoid and the “‘s”&lt;/h2&gt;

&lt;p&gt;This &lt;a href=&quot;https://arxiv.org/pdf/1905.11580.pdf&quot;&gt;arxiv preprint&lt;/a&gt; made me discover 
&lt;a href=&quot;https://en.wikipedia.org/wiki/John_ellipsoid&quot;&gt;John ellipsoid&lt;/a&gt;. Given a polytope
in $n$ dimensions, John ellipsoid is the largest-volume ellipsoid included in 
the polytope. On the picture below it is the red ellipse (more or less).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/john-ellipsoid.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;250px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;An interesting property is that if you take the ellipsoid and dilate it by a 
factor $n$, then this new ellipsoid contains the polytope (more or less the blue 
ellipsoid on the picture). At first I thought that dimension 3 should not require 
more dilatation than dimension 2, but if you think about an equilateral triangle 
in the plane, and a tetrahedron in a 3D space, you see that the inner ball of the 
tetrahedron has to be smaller than the inner disk of the equilateral triangle, 
and that the outer ball has to be larger.&lt;/p&gt;

&lt;p&gt;The arxiv preprint presents an algorithm to approximate John ellipsoid.&lt;/p&gt;

&lt;p&gt;By the way, why is it “John ellipsoid” and, say, “Dijktra’s algorithm”, why is 
there a “‘s” sometimes but not always?&lt;/p&gt;

&lt;h2 id=&quot;eppsteins-socg-report-and-robust-statistics&quot;&gt;Eppstein’s SOCG report and robust statistics&lt;/h2&gt;

&lt;p&gt;Eppstein wrote a nice
&lt;a href=&quot;https://11011110.github.io/blog/2019/06/21/report-from-socg.html&quot;&gt;report of SOCG&lt;/a&gt;,
with a selection of talks that caught his interest.&lt;/p&gt;

&lt;p&gt;He refers to &lt;a href=&quot;https://en.wikipedia.org/wiki/Centerpoint_(geometry)&quot;&gt;Tukey depth&lt;/a&gt;, 
which is related to Tukey median, which is a 
generalization of the median in higher dimension. I discovered this notion in a great 
talk by &lt;a href=&quot;https://people.csail.mit.edu/moitra/&quot;&gt;Ankur Moitra&lt;/a&gt; about the 
computational aspects of
&lt;a href=&quot;https://en.wikipedia.org/wiki/Robust_statistics&quot;&gt;robust statistics&lt;/a&gt;, at 
&lt;a href=&quot;http://2018.highlightsofalgorithms.org/&quot;&gt;HALG 2018&lt;/a&gt;. 
The basic story is the following. Suppose you have data, and you want to 
summarize it by one point. You want to use the average, but because your data 
has some adversarial noise, the average of the noisy data might be far from the 
average of the “real data”. If you are in 1D then you can take the median, which 
is robust to such noise. But if you are in $d$ dimension, then there are several 
generalizations of the median, 
and either they are not robust to noise or they are NP-hard to compute, and then 
you have to think.&lt;/p&gt;

&lt;p&gt;Two references on robust statistics : 
&lt;a href=&quot;http://people.csail.mit.edu/moitra/docs/robust2.pdf&quot;&gt;here&lt;/a&gt;
and 
&lt;a href=&quot;https://www.csun.edu/~ctoth/Handbook/chap58.pdf&quot;&gt;there&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;other-notes&quot;&gt;Other notes&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The paper I talked about in a 
&lt;a href=&quot;https://discrete-notes.github.io/simulation-1&quot;&gt;series of posts in February&lt;/a&gt;, by 
the Aalto distributed computing people has been accepted to 
&lt;a href=&quot;http://focs2019.cs.jhu.edu/&quot;&gt;FOCS 2019&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;a href=&quot;http://eatcs.org/images/bulletin/beatcs128.pdf&quot;&gt;128th bulletin of the EATCS&lt;/a&gt; 
is out, with a chapter on matching with preference lists, and a chapter on 
leader election in directed dynamic graphs.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 02 Jul 2019 00:00:00 -0400</pubDate>
        <link>https://discrete-notes.github.io///june-2019-notes</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///june-2019-notes</guid>
      </item>
    
      <item>
        <title>Material on distributed graph algorithms</title>
        <description>&lt;p&gt;This post is a list of pointers to books and surveys about distributed graph 
algorithms (LOCAL model, CONGEST model, and friends).
I probably missed some references, as typing “local model” in a search engine 
is not very helpful if you are not looking for top model agencies. 
Other references are most welcome!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/local.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;distributed-computing-a-locality-sensitive-approach-by-peleg-and-other-references&quot;&gt;Distributed computing: a locality-sensitive approach, by Peleg, and other references&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://epubs.siam.org/doi/book/10.1137/1.9780898719772&quot;&gt;Distributed computing: a locality-sensitive approach&lt;/a&gt;
by &lt;a href=&quot;http://www.weizmann.ac.il/math/peleg/&quot;&gt;David Peleg&lt;/a&gt; is the classic book 
about the local model. It’s from 2000, so it’s getting a bit outdated in terms 
of results.&lt;/p&gt;

&lt;h2 id=&quot;distributed-graph-coloring-by-barenboim-and-elkin&quot;&gt;Distributed graph coloring, by Barenboim and Elkin&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cs.bgu.ac.il/~elkinm/book.pdf&quot;&gt;Distributed graph coloring&lt;/a&gt;
by 
&lt;a href=&quot;https://www.openu.ac.il/personal_sites/leonid-barenboim/&quot;&gt;Leonid Bareboim&lt;/a&gt;
and &lt;a href=&quot;https://www.cs.bgu.ac.il/~elkinm/&quot;&gt;Michael Elkin&lt;/a&gt;, is a more recent book, 
with a focus on coloring. It explains quite a few techniques, and has a list of 
open problems (some of these problems have been solved already).&lt;/p&gt;

&lt;h2 id=&quot;survey-of-local-algorithms-by-suomela&quot;&gt;Survey of local algorithms, by Suomela&lt;/h2&gt;
&lt;p&gt;The &lt;a href=&quot;https://users.ics.aalto.fi/suomela/doc/local-survey.pdf&quot;&gt;survey of local algorithms&lt;/a&gt;
by &lt;a href=&quot;https://users.ics.aalto.fi/suomela/&quot;&gt;Jukka Suomela&lt;/a&gt; is the reference for 
results about constant-time computations in the local model.&lt;/p&gt;

&lt;h2 id=&quot;distributed-algorithms-by-suomela&quot;&gt;Distributed algorithms, by Suomela&lt;/h2&gt;

&lt;p&gt;A neat online textbook is
&lt;a href=&quot;https://users.ics.aalto.fi/suomela/da/da-print.pdf&quot;&gt;Distributed algorithm&lt;/a&gt;
by Jukka Suomela.
In addition to the classic topics such as coloring, that are contained in most 
references listed here, it has a focus on showing the similarities and differences 
between different models (such as port numbers and unique identifiers), and on the 
graph theory tools that can be used (such as covering maps and Ramsey theory).&lt;/p&gt;

&lt;h2 id=&quot;the-swiss-german-lecture-notes&quot;&gt;The Swiss-German lecture notes&lt;/h2&gt;

&lt;p&gt;There are several courses related to the local model that are taught in 
Switzerland and South Germany. They are rather close one from another, as they 
stem from the same Zurich source (but then they evolved on their own).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The current version of the original source is 
&lt;a href=&quot;https://disco.ethz.ch/courses/podc/&quot;&gt;Principles of Distributed Computing&lt;/a&gt;, 
by &lt;a href=&quot;https://disco.ethz.ch/members/wroger&quot;&gt;Roger Wattenhofer&lt;/a&gt; (and more recently
&lt;a href=&quot;https://people.csail.mit.edu/ghaffari/&quot;&gt;Mohsen Ghaffari&lt;/a&gt; but his part is 
covered below). In addition to the classic topics of synchronous computing, it 
covers some topics at the boundary with asynchronous computing (such as 
synchronizers), or fully asynchronous computing (such as shared objects).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A set of lecture notes by &lt;a href=&quot;http://ac.informatik.uni-freiburg.de/kuhn/&quot;&gt;Fabian Kuhn&lt;/a&gt;
is available chapter by chapter on
&lt;a href=&quot;http://ac.informatik.uni-freiburg.de/teaching/ss_18/network-algorithms.php&quot;&gt;the course webpage&lt;/a&gt;.
The topics are very close from the ones of the bullet above. Two topics that 
appear only here: dynamic networks and
&lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_network_coding&quot;&gt;network coding&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Another set of lecture notes is 
&lt;a href=&quot;https://www.mpi-inf.mpg.de/departments/algorithms-complexity/teaching/winter18/tods/&quot;&gt;Theory of Distributed Systems&lt;/a&gt;, 
by &lt;a href=&quot;http://people.mpi-inf.mpg.de/~clenzen/&quot;&gt;Christoph Lenzen&lt;/a&gt;. It covers 
(in addition to the classic material) self-stabilization and 
routing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Probably the most recent course is
&lt;a href=&quot;https://disco.ethz.ch/courses/podc/lecturenotes/LOCAL.pdf&quot;&gt;Distributed graph algorithms&lt;/a&gt;
by 
&lt;a href=&quot;https://people.csail.mit.edu/ghaffari/&quot;&gt;Mohsen Ghaffari&lt;/a&gt;. 
It is a shorter text, with a focus on algorithmic techniques for the local model, 
e.g. network decomposition.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;material-covering-only-the-basics-or-only-specialized-content&quot;&gt;Material covering only the basics, or only specialized content&lt;/h2&gt;

&lt;p&gt;A standard book is 
&lt;a href=&quot;https://www.elsevier.com/books/distributed-algorithms/lynch/978-1-55860-348-6&quot;&gt;Distributed Algorithms&lt;/a&gt;
by &lt;a href=&quot;http://people.csail.mit.edu/lynch/&quot;&gt;Nancy Lynch&lt;/a&gt;, but most of the book is 
off-topic for this post, because it deals with asynchronous systems.&lt;/p&gt;

&lt;p&gt;Yet another reference (with little material on the LOCAL model) is the online 
textbook 
&lt;a href=&quot;http://www.cs.yale.edu/homes/aspnes/classes/465/notes.pdf&quot;&gt;Notes on Theory of Distributed Systems&lt;/a&gt;
by &lt;a href=&quot;http://www.cs.yale.edu/homes/aspnes/&quot;&gt;James Aspnes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you look for &lt;a href=&quot;https://en.wikipedia.org/wiki/Self-stabilization&quot;&gt;self-stabilizing algorithms&lt;/a&gt;
then a reference from 2000 is 
&lt;a href=&quot;https://mitpress.mit.edu/books/self-stabilization&quot;&gt;Self-Stabilization &lt;/a&gt; 
by
&lt;a href=&quot;https://in.bgu.ac.il/en/natural_science/cs/dolev//Pages/default.aspx&quot;&gt;Shlomi Dolev&lt;/a&gt;, 
and a very recent one is 
&lt;a href=&quot;https://www.morganclaypool.com/doi/abs/10.2200/S00908ED1V01Y201903DCT015&quot;&gt;Introduction to Distributed Self-Stabilizing Algorithms&lt;/a&gt;
by
&lt;a href=&quot;http://www-verimag.imag.fr/Karine-Altisen,102.html?lang=en&quot;&gt;Karine Altisen&lt;/a&gt;,
&lt;a href=&quot;http://www-verimag.imag.fr/~devismes/WWW/introduction.html&quot;&gt;Stéphane Devismes&lt;/a&gt;,
&lt;a href=&quot;https://pages.lip6.fr/Swan.Dubois/&quot;&gt;Swan Dubois&lt;/a&gt;,
and 
&lt;a href=&quot;https://pages.lip6.fr/Franck.Petit/&quot;&gt;Franck Petit&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;in-french&quot;&gt;In French&lt;/h3&gt;
&lt;p&gt;Also, if you read French, you may be interested in 
&lt;a href=&quot;https://www.irif.fr/_media/users/pierref/notes_algo_distribue.pdf&quot;&gt;Algorithmique distribuée pour les réseaux&lt;/a&gt;
by &lt;a href=&quot;https://www.irif.fr/users/pierref/index&quot;&gt;Pierre Fraigniaud&lt;/a&gt;, and 
&lt;a href=&quot;http://dept-info.labri.fr/~gavoille/UE-AD/cours.pdf&quot;&gt;Algorithmes distribués&lt;/a&gt; 
by &lt;a href=&quot;http://dept-info.labri.fr/~gavoille/&quot;&gt;Cyril Gavoille&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Thanks to Jukka Suomela for pointing out some references.&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Jun 2019 00:00:00 -0400</pubDate>
        <link>https://discrete-notes.github.io///local-model</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///local-model</guid>
      </item>
    
  </channel>
</rss>
