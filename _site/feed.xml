<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Discrete notes</title>
    <description>Blog</description>
    <link>https://discrete-notes.github.io/</link>
    <atom:link href="https://discrete-notes.github.io//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Algorithms and natural history</title>
        <description>&lt;p&gt;Until recently there was in Paris an exhibition about some techniques used for 
research in natural history.
It raises some algorithmic questions and comments about bones, diamonds and 
polytopes.
(More details about this great exhibition at the end of the post.)&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/grenouille.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;small&gt;&lt;i&gt;Researchers measure the teeth of the tadpoles this frog 
species, and learn stuff.&lt;/i&gt;&lt;/small&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;computing-skull-volumes&quot;&gt;Computing (skull) volumes&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/crane.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When you get a skull, something you want to measure is how much brain you can 
fit in, that is, what is its inside volume.
This used to be done by filling the skull with some kind of grains, and then 
measuring the volume of grain. 
It is now done by with sensor measurements and computations. 
But if I give you some triangulation of an object, how do you compute the volume?
If you assume the object to be convex, then one can surely do some kind of discrete 
integrals, suming some basic polytope volumes. 
&lt;a href=&quot;https://www.ams.org/journals/mcom/1991-57-195/S0025-5718-1991-1079024-2/S0025-5718-1991-1079024-2.pdf&quot;&gt;This paper&lt;/a&gt; 
(or more precisely its introduction) seems to validate this intuition. 
It also raises the question about how the object to measure is given.&lt;/p&gt;

&lt;p&gt;This made me remember that some price was awarded for something related to 
volume computation. 
I dug out the reference: 1991 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Fulkerson_Prize&quot;&gt;Fulkerson prize&lt;/a&gt; was awarded to 
Dyer, Frieze and Kannan for works of this flavour.
Their model is black-box: you ask for a point and you are answered whether it is 
inside or outside. 
They provide a randomized PTAS&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; for approximating
the volume of high-dimensional polytopes using 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo&quot;&gt;Markov chain Monte Carlo&lt;/a&gt; 
methods. 
As many counting problems can be rephrased in terms of polytopes, this is much 
more useful than just computing high-dimensional skull volumes.
For a bit more on this, see 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Convex_volume_approximation&quot;&gt;this wikipedia page&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;inclusions-ofdiamonds-and-polytopes&quot;&gt;Inclusions of diamonds and polytopes&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/diamant-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The diamond above is the &lt;a href=&quot;Tavernier Blue&quot;&gt;Blue Diamond of the French Crown&lt;/a&gt; 
that Louis XIV bought at some point of the 17th century. 
Or actually, it’s what it used to look like, because this diamond disappeared. 
It was suspected that it has been recut and is now the diamond known as the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Hope_Diamond&quot;&gt;Hope diamond&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This was presented in the exhibition because the museum in Paris has a lead cast 
of the original diamond, and used it to validated the link between the two. 
Basically the two diamonds fit so well one in the other, that is very likely 
that they are the same with only a light recut.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/diamant-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;250px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But how can you decide if two polytopes could be included one in the other?
And what’s the complexity? (Note that contrary to skulls, diamonds are pretty 
much polytopes.)&lt;/p&gt;

&lt;p&gt;First for the decision problem: the two polytopes are somehow aligned and you 
just want to check the inclusion of one into the other.
If both polytopes are given by sets of vertices, then some methods similar to
&lt;a href=&quot;https://en.wikipedia.org/wiki/Convex_hull_algorithms&quot;&gt;convex hull computations&lt;/a&gt; 
should do the job.&lt;/p&gt;

&lt;p&gt;Now how to find this alignment? For our diamonds, the spikes and planar 
symmetries surely help. But what if your polytopes are say, 
very close to spheres, but with random perturbations? Doesn’t seem very easy. 
This looks similar to some robotics problem, such as the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Motion_planning&quot;&gt;piano mover’s problem&lt;/a&gt;, but it’s 
not quite the same.&lt;/p&gt;

&lt;h2 id=&quot;symmetrizing-old-bones&quot;&gt;Symmetrizing old bones&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/dinosaures.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;350px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Yet another problems that one can transfer to polytopes. 
Here the paleontologists find skulls like the one on the left (I didn’t take 
notes of the name of this fellow), that has been deformed by non-uniform forces 
in the ground.
Then they try to reconstruct the correct shape, like the one on the right.&lt;/p&gt;

&lt;p&gt;Again if you are a human, if you know a lot about such creatures, it is possible 
to find a plausible shape by adjusting the parameters of some transformation.
In particular, you try to have a left-right symmetry.
But what if I give you an arbitrary triangulation, and tell you: find the best 
way to modify it in order to have a symmetry?&lt;/p&gt;

&lt;p&gt;Could be related to 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Principal_component_analysis&quot;&gt;principal component analysis&lt;/a&gt;, 
that gives you some notion of “this object is somehow aligned with this 
direction”, but again if you have a random near-spherical objects, this does not 
help you (but in this case, you may be happy with any plane, as an approximation).&lt;/p&gt;

&lt;h3 id=&quot;about-the-exhibition&quot;&gt;About the exhibition&lt;/h3&gt;
&lt;p&gt;The name of the exhibition in French was 
&lt;em&gt;&lt;a href=&quot;https://www.mnhn.fr/en/node/5277&quot;&gt;Secrets dévoilés : voir l’imperceptible&lt;/a&gt;&lt;/em&gt;, 
which basically means &lt;em&gt;Unveiling secrets : seeing the imperciptible&lt;/em&gt;.
It was created by the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/National_Museum_of_Natural_History,_France&quot;&gt;National Museum of Natural History of Paris&lt;/a&gt;
and consisted in panels, hung in the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Jardin_des_plantes&quot;&gt;Jardin des Plantes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Some of the pictures can be seen on the 
&lt;a href=&quot;https://marieducom.com/portfolio/exhibition-secrets-devoiles-voir-limperceptible/?lang=fr&quot;&gt;website of the illustrator&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;For PTAS and related acronyms, see &lt;a href=&quot;https://discrete-notes.github.io/october-batch-forgotten&quot;&gt;this post&lt;/a&gt;.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 09 May 2019 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///natural-history</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///natural-history</guid>
      </item>
    
      <item>
        <title>March notes II.</title>
        <description>&lt;p&gt;Second set of notes for March 2019.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/pivoines.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;a-pair-of-distributed-computing-talks&quot;&gt;A pair of distributed computing talks&lt;/h2&gt;

&lt;p&gt;We had a couple of distributed computing talks this month. Here are a few words 
about the concepts involved.&lt;/p&gt;

&lt;h3 id=&quot;beeping-model&quot;&gt;Beeping model&lt;/h3&gt;
&lt;p&gt;The &lt;em&gt;beeping model&lt;/em&gt; is a very weak model of distributed network computing.
In this model, the nodes of the network communicate by beeping. 
At each round, a node decides to beep or not. 
And a node can receive only one information: either someone in the neighborhood 
has beeped, or not. 
One cannot know how many nodes beeped. 
In particular, if the node chooses	 to beep, then it cannot know if another node 
has beeped.&lt;/p&gt;

&lt;p&gt;The beeping is used to model primitive communication, for example between cells.
The surprising point is that you can actually do things in this model !
For example compute a maximal independent set 
(see &lt;a href=&quot;http://www.cs.tau.ac.il/~afek/MISdisc.pdf&quot;&gt;this paper&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;superimposed-codes&quot;&gt;Superimposed codes&lt;/h3&gt;

&lt;p&gt;Beeps are binary information, thus to transmit more than one bit, nodes have to 
encode information into sequences of beeps. 
The problem is that a node may receive beeps from several neighbors, and a 
priori cannot know if beeps it heard form a single sequence, or if it is a 
mix of several sequences.&lt;/p&gt;

&lt;p&gt;A nice tool to solve that is &lt;em&gt;superimposed codes&lt;/em&gt;: these codes are such that if one superimpose 
them (that is, perform a bit-wise OR), one can still decode the different words. 
In other words any sequence can be decomposed uniquely into several code words.&lt;/p&gt;

&lt;p&gt;It seems that these codes were already used for punched-cards…&lt;/p&gt;

&lt;h3 id=&quot;fixing-blocking-edges-in-stable-marriage&quot;&gt;Fixing blocking edges in stable marriage&lt;/h3&gt;

&lt;p&gt;A marriage (or bipartite matching) is a matching in a balanced 
bipartite graph, where every node is has a preference list. 
It is &lt;em&gt;&lt;a href=&quot;Stable marriage problem&quot;&gt;stable&lt;/a&gt;&lt;/em&gt; if not two participants would prefer to 
be matched together instead of their current matching (such a pair is called a 
&lt;em&gt;blocking edge&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Gale and Shapley designed a well-known algorithm to compute such a marriage. 
But it starts from an empty solution. Suppose you want to start from a non-stable
solution and improve it step by step, for example because you are designing a
self-stabilizing algorithm. This is not easy.&lt;/p&gt;

&lt;p&gt;In the following example, 
attributed to &lt;a href=&quot;https://en.wikipedia.org/wiki/Donald_Knuth&quot;&gt;Knuth&lt;/a&gt;, 
we start on the left from 
a solution that is unstable (the blocking pair is in red), and solve this pair 
on the right picture, and then iterate the procedure. Unfortunately, at the end 
of the procedure, we are back to the first instance!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/mariages.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;700px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;privacy-in-stable-marriage&quot;&gt;Privacy in stable marriage&lt;/h3&gt;

&lt;p&gt;The classic centralized algorithms for stable marriage use the full list of 
preferences, that is there is no privacy for the participants. 
For distributed algorithms, it makes sense to try to minimize the amount of 
information the participants have to share to solve the task.
For example the algorithm presented in the talk uses little information 
(e.g. “this player is already
matched to someone higher in his/her list”).&lt;/p&gt;

&lt;p&gt;[The talks were by 
&lt;a href=&quot;https://sites.google.com/view/dufoulon/accueil&quot;&gt;Fabien Dufoulon&lt;/a&gt; and 
&lt;a href=&quot;https://www.lri.fr/~laveau/&quot;&gt;Marie Laveau&lt;/a&gt;, 
both PhD students in Paris-Sud University.
Fabien told us about his new (not yet public) result in the beeping model, 
using a variant of superimposed codes. 
Marie told us about her result on self-stabilizing 
stable matching. 
It is &lt;a href=&quot;https://hal.archives-ouvertes.fr/hal-01576055/document&quot;&gt;this paper&lt;/a&gt;.]&lt;/p&gt;

&lt;h2 id=&quot;different-techniques-for-different-regimes-in-rockets-and-algorithms&quot;&gt;Different techniques for different regimes (in rockets and algorithms)&lt;/h2&gt;

&lt;p&gt;I discovered recently that the flames of different space rockets have different 
colors, partly because they use different mix of fuels.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/rockets.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;550px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Space shuttle (yellowish flames) and Soyouz (pinkish flames).&lt;/p&gt;

&lt;p&gt;This was surprising to me, as I would naively think that there must be a solution 
that is considered “the best to push stuff upward”, and that everybody would use it.&lt;/p&gt;

&lt;p&gt;But I guess different regimes (how much you want to lift, at which speed etc.) 
ask for different solutions. 
In the world of algorithms, it is similar to the following scenario.
Say you want an algorithm for instances that depend on two parameters $n$ and 
$k$. Then you may use different technique for different regimes. 
For example, expressing $k$ as a function of $n$, you could have: for constant 
$k$ do brute-force, for logarithmic $k$ do some divide and conquer, for 
$k$ around $\sqrt{n}$ do dynamic programming, etc.&lt;/p&gt;

&lt;p&gt;I wonder if we have such examples with many different regimes asking for many 
different solutions. 
In distributed graph algorithms, an example is coloring 
(and similar problems) where for 
bounded degree and unbounded degree you have completely different techniques.&lt;/p&gt;

&lt;p&gt;For the related question of problems (with one parameter) having many different 
equally good solutions, I see $O(\log n)$-approximation of 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Set_cover_problem&quot;&gt;Set-Cover&lt;/a&gt;, for which you can 
basically use all the standard tools of approximation: greedy, LP-rounding, 
primal-dual etc.&lt;/p&gt;

&lt;p&gt;[I semi-randomly stumbled on 
&lt;a href=&quot;https://www.youtube.com/watch?v=EO_gwxon764&quot;&gt;this video&lt;/a&gt; (or more precisely 
the French-speaking version of it) that explains a lot of stuff about rockets 
flames. 
For example why one can see the kind of patterns below in rocket flames 
(it’s actually in the second part of the video).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/shock-diamonds.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;170px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These are called &lt;a href=&quot;https://en.wikipedia.org/wiki/Shock_diamond&quot;&gt;Mach disks&lt;/a&gt; or 
shock diamonds, and come from the fact that the flames expand when they get 
out of the engine, but because the outside pressure is higher, it is then 
recompressed, it heats up again, and then again 
expands etc. Maybe there is a discrete analogue for this too (convergence by 
oscillations?).]&lt;/p&gt;

&lt;h2 id=&quot;abel-prize-and-limitations-of-the-discrete-approach&quot;&gt;Abel prize and limitations of the discrete approach&lt;/h2&gt;

&lt;p&gt;Lipton and Regan 
&lt;a href=&quot;https://rjlipton.wordpress.com/2019/03/21/the-shortest-path-to-the-abel-prize/&quot;&gt;blog about&lt;/a&gt; 
the new Abel prize recipient, 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Karen_Uhlenbeck&quot;&gt;Karen Uhlenbeck&lt;/a&gt;, or actually about
her research. They take the interesting approach of first trying to solve a 
problem with a discrete natural approach, and then to show how it fails, and how 
analysis in the style of Uhlenbeck’s research solves the problem.&lt;/p&gt;

&lt;p&gt;The question is simply to prove that in the plane the shortest path between two 
points is a straight line. The natural discrete approach is to consider 
polygonal lines, to prove the statement by induction (on the picture below the 
blue line is better by triangle inequality), and then to say “every curve is 
polygonal line up to small stuff”.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/uhlenbeck.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;200px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The reason why it fails is all the nasty functions (fractals and other monsters) 
that ruin the last step.&lt;/p&gt;

&lt;h2 id=&quot;sigact-news-year-and-conference-reviews&quot;&gt;SIGACT news, year and conference reviews&lt;/h2&gt;

&lt;p&gt;I was surprised to receive SIGACT news at home, and then remembered than I had 
registered to ACM for FOCS. It is first time I glance at SIGACT news, as I don’t
have access to it online.&lt;/p&gt;

&lt;p&gt;I was especially interested in the online algorithm review. 
For the first issue of the year, the author, 
&lt;a href=&quot;https://www.uni-siegen.de/fb6/aan/optimierung/mitarbeiter/vanstee/?lang=d&quot;&gt;Rob van Stee&lt;/a&gt;, 
does a review of the key results of 2018 in his area. 
This is very nice format, that gives a higher perspective on a field.&lt;/p&gt;

&lt;p&gt;A more classic format is the review of a conference. In my experience, this is 
less useful, because (1) one cannot be knowledgeable about every topic in a 
conference, (2) one tries to be quite exhaustive ; consequently 
the review often ends up being a list of small, not very informative
sentences about many many papers.&lt;/p&gt;

&lt;p&gt;[By the way, it’s sad that SIGACT News is not open-access.]&lt;/p&gt;

&lt;h2 id=&quot;point5-and-conference-travel&quot;&gt;1point5 and conference travel&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Le_Monde&quot;&gt;Le Monde&lt;/a&gt;, one of the major French 
newpapers, published 
&lt;a href=&quot;https://labos1point5.org/&quot;&gt;the letter of the “1point5” group&lt;/a&gt;. 
This name comes from the objective of keeping global warming
upper bounded by 1.5 degree Celsius. The collective is interested in the impact of 
research on climate. They basically argue that research should be made 
differently to reduce its impact on the planet.&lt;/p&gt;

&lt;p&gt;I have been thinking about this for a while. 
It happened to me several times to go 
to a conference, and think it was not worth the kerosene. 
Conferences are often nice moments, you indeed learn stuff and make new projects,
but it’s difficult to argue that this is as convincing as the following picture.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/histogram-CO2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The precise numbers can be discussed, but I got them from very reliable sources,
and everywhere you will find numbers in the same ballpark.&lt;/p&gt;

&lt;p&gt;In the long term, we can hope to make conferences less numerous, more efficient, 
more local. But in the short, term it seems that the only solution is to avoid 
submitting to far away conferences. Obviously this is a very broad topic…&lt;/p&gt;

&lt;h2 id=&quot;place-in-a-queue&quot;&gt;Place in a queue&lt;/h2&gt;

&lt;p&gt;I recently went to a doctor who does not take appointments, thus people wait. 
The rule is “first-in first-cured” and people have to remember when it’s their 
turn.
It is usually fine, but sometimes, maybe by mistake, maybe by slyness, people 
disagree. 
I noticed that people in the room have somehow random sampling of the 
order, e.g. “I arrived before this person, that person was here before, these two 
I don’t know”.&lt;/p&gt;

&lt;p&gt;You get diagrams like this one (with some inconsistencies):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/queue-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Making this into a linear order has a feedback-arcset flavor.&lt;/p&gt;

&lt;p&gt;In other countries, I noticed that people, when they arrive say to a restaurant,
ask “who is the latest arrived?”, which gives a simpler picture:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/queue-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But maybe it’s less robust to slyness..?&lt;/p&gt;

</description>
        <pubDate>Tue, 09 Apr 2019 00:00:00 +0200</pubDate>
        <link>https://discrete-notes.github.io///march-2019-notes-2</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///march-2019-notes-2</guid>
      </item>
    
      <item>
        <title>Lightning and search algorithms</title>
        <description>&lt;p&gt;I recently stumbled on &lt;a href=&quot;https://www.youtube.com/watch?v=nBYZpsbu9ds&quot;&gt;this video&lt;/a&gt;
of lightning. I knew that lightning kind of “search for the good way”, but 
I was stunned by how it looks like the run of a search algorithm: exploration 
phases, backtracking, compromise between depth and breadth etc.
For fun, I drew a lightning bolt, second by second. You may find it in the 
video around 0:25-0:35.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/eclair-1a.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-1b.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-2a.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-2b.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-3a.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-3b.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-4a.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-4b.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-5a.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-5b.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-6a.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;
&lt;img src=&quot;assets/eclair-6b.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Tue, 26 Mar 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///lightning</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///lightning</guid>
      </item>
    
      <item>
        <title>March notes I.</title>
        <description>&lt;p&gt;First half of the March 2019 notes.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;assets/mimosa-2.JPG&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;450px&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Mimosa in Jardin des Plantes.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tverbergs-theorem&quot;&gt;Tverberg’s theorem&lt;/h2&gt;

&lt;p&gt;For geometric algorithms in the plane, one sometimes has go through case by case 
analysis along the lines of “if this point is below this line, then this and 
that intersect, if not then…”. 
Such proofs are a bit boring and it is easy to make mistakes. 
So when you have a general theorem that does the work for you, it’s good news. 
Tverberg’s theorem looks like a theorem that could be useful from this point of 
view.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Tverberg%27s_theorem&quot;&gt;Tverberg’s theorem&lt;/a&gt; states 
a condition such that the convex hulls of several sets of points intersect. 
Precisely: in a $d$-dimensional euclidian space, for any integer $r$, for any 
set of $(d+1)(r-1)+1$ points, there exists a partition in $r$ subsets such that 
the convex hulls of the $r$ subsets intersect. 
The picture below present the case $d=2$ and $r=3$, for $(d+1)(r-1)+1=7$ points, 
and for one less point. 
In this last case the theorem does not hold (we just show one partition).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/tverberg.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;270px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;[I saw the name of this theorem on the SOCG accepted papers list, unfortunately
the paper is not available online, and we don’t know what they do with this 
theorem.]&lt;/p&gt;

&lt;h2 id=&quot;criteria-for-fair-item-assignment&quot;&gt;Criteria for fair item assignment&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Fair_item_assignment&quot;&gt;Fair item assignement&lt;/a&gt; 
consists, given items and participants, to assign the items to the participants 
in a fair manner, for some definition of fair. There are many variants of the 
problem and many ways to define fairness.&lt;/p&gt;

&lt;p&gt;Here are a few fairness criteria, to decide if the assignment is fair or not:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Max-min fair-share (“I cut, you choose”): every participant is least as happy 
as if she had cut the set of items first, and then let all the other 
participants choose before her.&lt;/li&gt;
  &lt;li&gt;Max-min fair-share (“You cut, I choose”): the same but reversed, that is every
participant is at least as happy as if someone else did the cut, and she could 
decide first.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Envy-freeness&quot;&gt;Envy-freeness&lt;/a&gt;: 
no participant would like to change her items for the items of 
another participant.&lt;/li&gt;
  &lt;li&gt;Competitive equilibrium from equal incomes: there exists a price for each item
such that, given the same budget, the participants would choose different items.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[I learnt about this at the CS PhD seminar of Sorbonne university, by Parham 
Shams.]&lt;/p&gt;

&lt;h2 id=&quot;tai-chi-problem&quot;&gt;Tai chi problem&lt;/h2&gt;

&lt;p&gt;When crossing the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Jardin_des_plantes&quot;&gt;Jardin des plantes&lt;/a&gt; 
I often witness the following kind of scene.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/taichi.JPG&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is people practising &lt;a href=&quot;https://en.wikipedia.org/wiki/Tai_chi&quot;&gt;taichi&lt;/a&gt;. 
There is a professor in front of the group (with a white cap on the picture)
who is showing the movements, and everybody is supposed to perform them in 
real-time (it’s pretty slow).&lt;/p&gt;

&lt;p&gt;The thing is: people on the first row can see the professor, but the ones on the 
back cannot, so they follow the moves of the people on the rows closer to the 
professor. Therefore there is a kind of wave from the front to the back. 
Maybe it can make an interesting problem: how fast does the wave propagate, is 
it close to a straight line, how does it depend on the size of the participants?&lt;/p&gt;

&lt;h2 id=&quot;core-algorithms-deployed&quot;&gt;Core algorithms deployed&lt;/h2&gt;

&lt;p&gt;It is common as a reseacher to have doubt about how useful your research is. 
In my case, I sometimes wonder whether the algorithmic problem we try to solve 
really have an impact. 
It could well be the case that the algorithmic problems that 
are really useful are the ones that have only basic answers.
That is, we focus on the sweet spot between trivially easy and trivially hard 
problems, and this set could have an empty intersection with real-world 
questions.&lt;/p&gt;

&lt;p&gt;I was really happy to discover a few years ago 
&lt;a href=&quot;https://cstheory.stackexchange.com/questions/19759/core-algorithms-deployed&quot;&gt;the topic “core algorithms deployed”&lt;/a&gt;
on stack exchange,
that removes any doubt on this regard.&lt;/p&gt;

&lt;h2 id=&quot;numerical-errors-in-missile-trajectories&quot;&gt;Numerical errors in missile trajectories&lt;/h2&gt;

&lt;p&gt;I discovered in the introduction of
&lt;a href=&quot;https://www.lri.fr/~melquion/doc/19-hdr.pdf&quot;&gt;this  PhD thesis&lt;/a&gt; the following 
story, illustrating why computer arithmetics is important and difficult.&lt;/p&gt;

&lt;p&gt;In 2011, a US “&lt;a href=&quot;https://en.wikipedia.org/wiki/Missile_defense&quot;&gt;defence missile&lt;/a&gt;” 
missed a “real missile”, with tragic consequences, 
because of computer arithmetic. 
The basic reason is the following. 
There used to be a software doing the trajectory computations, with rounding 
operations, including on the time variable. This  variable slowly shifted 
compared to the real time because of these rounding. 
It sounds dangerous, but it was actually ok: 
the trajectory computations would consider fast movements 
so between the start and end of the trajectory, the shift was negligible, and 
the absolute time did not matter. The problem is that part of the system was 
updated with more accurate time variable. Then the shift would not be the same 
in two different parts of the system. Then the shift would not cancel out and 
this was the bug.&lt;/p&gt;

&lt;p&gt;[A better explanation can be found in 
&lt;a href=&quot;http://www-users.math.umn.edu/~arnold/disasters/Patriot-dharan-skeel-siam.pdf&quot;&gt;this document&lt;/a&gt;.
The PhD thesis has a more light-hearted story about gamers trying to finish a 
video game level without jumping, and using a slow shift of a platform 
(also due to rounding errors) to do so.]&lt;/p&gt;

&lt;h2 id=&quot;max-cut-and-planar-graphs&quot;&gt;Max cut and planar graphs&lt;/h2&gt;

&lt;p&gt;Two results about &lt;a href=&quot;https://en.wikipedia.org/wiki/Maximum_cut&quot;&gt;max-cut&lt;/a&gt; that I 
didn’t know:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;a cut is maximum if and only if its complement is a minimum odd-circuit cover 
(this is easy to check, see for example 
&lt;a href=&quot;https://web.engr.oregonstate.edu/~glencora/wiki/uploads/planar-max-cut.pdf&quot;&gt;here&lt;/a&gt;,
or simply stare a bit at the picture below.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This can be used to obtain a polynomial-time algorithm for max-cut in planar 
graphs.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;assets/maxcut.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;[I got aware of this by
&lt;a href=&quot;https://arxiv.org/abs/1903.06061&quot;&gt;this preprint&lt;/a&gt;
which presents an algorithm for max-cut whose complexity is parametrized by the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Crossing_number_(graph_theory)&quot;&gt;number of crossing&lt;/a&gt; 
in the drawing of the graph.]&lt;/p&gt;

</description>
        <pubDate>Mon, 25 Mar 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///march-2019-notes-1</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///march-2019-notes-1</guid>
      </item>
    
      <item>
        <title>STOC and SOCG picks</title>
        <description>&lt;p&gt;A few weeks ago the accepted papers lists of 
&lt;a href=&quot;http://acm-stoc.org/stoc2019/&quot;&gt;STOC&lt;/a&gt; 
and 
&lt;a href=&quot;http://eecs.oregonstate.edu/socg19/&quot;&gt;SOCG&lt;/a&gt; 
were made public. 
A bunch of titles caught my attention, and here are a few bits of information on
some papers I could find online.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/saucisses.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;350px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;testing-graphs-in-vertex-distribution-free-models&quot;&gt;Testing graphs in vertex-distribution-free models&lt;/h2&gt;

&lt;p&gt;Graph &lt;a href=&quot;https://en.wikipedia.org/wiki/Property_testing&quot;&gt;property testing&lt;/a&gt; 
basically consists in deciding if a graph has a property 
or not, by looking only at some parts of it. 
More precisely one queries a few nodes, and ask for their neighbors for example, 
and then outputs whether the graph has the property or is far from having 
it. Note that such a statement can only be true with some probability.
An introduction to graph property testing is 
&lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~/oded/COL/tgp-intro.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the classic model, one is allowed to query a random node, with “random” 
meaning “uniformly at random”. In a new 
&lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~/oded/VO/vdf.pdf&quot;&gt;paper&lt;/a&gt;
the author considers the case where the random access is not uniform but depends 
on an arbitrary distribution. This in turn implies a change in the definition of 
being far from a property.&lt;/p&gt;

&lt;p&gt;I didn’t dive in the paper, but I imagine the following scenario. 
Some nodes are more “important” than others. This translates into two things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It’s not a very big deal if you don’t detect that something is wrong around
an unimportant node.&lt;/li&gt;
  &lt;li&gt;Your random queries have more chance to visit an important node than an 
unimportant node.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, you have a dynamic graph, you may not know about newly arrived 
nodes, but these are less important, so it’s no big deal if you don’t query them
now.&lt;/p&gt;

&lt;p&gt;[The paper is 
&lt;em&gt;&lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~/oded/VO/vdf.pdf&quot;&gt;Testing Graphs in Vertex-Distribution-Free Models&lt;/a&gt;&lt;/em&gt;,
by &lt;a href=&quot;http://www.wisdom.weizmann.ac.il/~oded/&quot;&gt;Oded Goldreich&lt;/a&gt;, 
and will appear at STOC 2019.
It was listed in 
&lt;a href=&quot;https://ptreview.sublinear.info/?p=1044&quot;&gt;October 2018 property testing review&lt;/a&gt;.]&lt;/p&gt;

&lt;h2 id=&quot;transportation-problem&quot;&gt;Transportation problem&lt;/h2&gt;

&lt;p&gt;The transportation problem is the following. 
Given a graph, where each node $v$ is given a (positive or negative) supply 
$\mu(v)$, such that $\sum_v \mu(v)=0$, one has to find a flow to transport the 
supplies in order to reach the configuration where every node has supply 0. 
See the picture below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/transportation.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;250px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is very similar to the 
&lt;a href=&quot;Transportation theory (mathematics)&quot;&gt;optimal transport problem&lt;/a&gt; in non-discrete 
mathematics. The &lt;a href=&quot;https://arxiv.org/pdf/1902.08384.pdf&quot;&gt;paper&lt;/a&gt; presents an 
approximation algorithm for fixed dimensions via continuous optimization.&lt;/p&gt;

&lt;p&gt;I don’t know how much continuous optimization is used, but it reminds me of an 
excellent invited talk by 
&lt;a href=&quot;https://people.csail.mit.edu/madry/&quot;&gt;Aleksander Mądry&lt;/a&gt; at 
&lt;a href=&quot;http://2016.highlightsofalgorithms.org/&quot;&gt;HALG 2016&lt;/a&gt;, that convinced me that 
continuous optimization can be a good approach to solve combinatorial problems.
There is no video of the talk, but 
&lt;a href=&quot;https://www.youtube.com/watch?v=noRNcDbqtVY&quot;&gt;this one&lt;/a&gt;
seems pretty close.&lt;/p&gt;

&lt;p&gt;[The paper is 
&lt;em&gt;&lt;a href=&quot;https://arxiv.org/pdf/1902.08384.pdf&quot;&gt;Preconditioning for the Geometric Transportation Problem&lt;/a&gt;&lt;/em&gt;
by &lt;a href=&quot;http://www.math.toronto.edu/khesin/&quot;&gt;Boris A. Khesin&lt;/a&gt;,
&lt;a href=&quot;http://www.cs.toronto.edu/~anikolov/&quot;&gt;Aleksandar Nikolov&lt;/a&gt;,
and Dmitry Paramonov, and will appear at SOCG.]&lt;/p&gt;

&lt;h2 id=&quot;lp-roundings-iterated-meets-randomized&quot;&gt;LP roundings: iterated meets randomized&lt;/h2&gt;

&lt;p&gt;A classic approach in combinatorial optimization is to express the problem as a 
linear program. 
Unfortunately, only the fractional case is known to be solvable 
efficiently, and only the integer solutions can be transfered back to solution 
for the original problem. 
A solution is to compute a fractional solution and then to round it to an integer 
solution. This approach is very powerful for approximation algorithms.&lt;/p&gt;

&lt;p&gt;There are two important types of rounding: randomized rounding and iterated 
rounding. 
In &lt;a href=&quot;https://en.wikipedia.org/wiki/Randomized_rounding&quot;&gt;randomized rounding&lt;/a&gt;, 
a fractional variable $x_i$ is simply rounded to 1 
with probability $x_i$. 
In iterated rounding, one iteratively modify the fractional solution until it 
gets to an integral solutions (for example adding some small amount to a set of 
variables, until they reach 1, etc.). 
Both roundings have their pros and cons.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1811.01597.pdf&quot;&gt;The paper&lt;/a&gt; presents a method that 
combines the two approaches into one common framework, and shows how to use it.&lt;/p&gt;

&lt;p&gt;[The paper is 
&lt;em&gt;&lt;a href=&quot;https://arxiv.org/pdf/1811.01597.pdf&quot;&gt;On a generalization of iterated and randomizedrounding&lt;/a&gt;&lt;/em&gt;
by &lt;a href=&quot;https://www.win.tue.nl/~nikhil/&quot;&gt;Nikhil Bansal&lt;/a&gt;, and will appear at STOC.]&lt;/p&gt;

&lt;h2 id=&quot;queue-layout&quot;&gt;Queue layout&lt;/h2&gt;

&lt;p&gt;Given a graph, a $k$-queue layout is an ordering of the vertices and a partition 
of the
edges into $k$ sets, such that there are not two edges of the same partition, 
that are nested. 
Below is an example of a graph and a 2-queue layout of it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/queue-layout.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;250px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Queue_number&quot;&gt;queue number&lt;/a&gt; of a graph is 
the minimum $k$ such that there exists a $k$ layout of the graph. 
An important open question is whether planar graph have bounded queue number. 
&lt;a href=&quot;https://arxiv.org/pdf/1811.00816.pdf&quot;&gt;The paper&lt;/a&gt; makes a step towards a positive
answer, by proving that planar graphs with bounded degree have bounded queue 
number.&lt;/p&gt;

&lt;p&gt;[The paper is 
&lt;em&gt;&lt;a href=&quot;https://arxiv.org/pdf/1811.00816.pdf&quot;&gt;Planar Graphs of Bounded Degree have Constant Queue Number&lt;/a&gt;&lt;/em&gt;
by 
&lt;a href=&quot;http://algo.inf.uni-tuebingen.de/?site=mitarbeiter/michaelbekos/index&quot;&gt;Michael A. Bekos&lt;/a&gt;, 
&lt;a href=&quot;http://www-pr.informatik.uni-tuebingen.de/?site=mitarbeiter/henryfoerster/index&quot;&gt;Henry Förster&lt;/a&gt;,
&lt;a href=&quot;https://informatik.uni-koeln.de/ls-juenger/people/gronemann/&quot;&gt;Martin Gronemann&lt;/a&gt;, 
&lt;a href=&quot;https://i11www.iti.kit.edu/en/members/tamara_mchedlidze/index&quot;&gt;Tamara Mchedlidze&lt;/a&gt;,
&lt;a href=&quot;http://mozart.diei.unipg.it/montecchiani/&quot;&gt;Fabrizio Montecchiani&lt;/a&gt;, 
Chrysanthi Raftopoulou, and
&lt;a href=&quot;https://i11www.iti.kit.edu/en/members/torsten_ueckerdt/index&quot;&gt;Torsten Ueckerdt&lt;/a&gt;.
It will appear at STOC (even though the topic is very SOCG-friendly).
I didn’t know about queue layouts, and it’s good to discover it, as it is yet 
another example of graph parameter that correspond to a pattern, in the sense of 
&lt;a href=&quot;https://arxiv.org/abs/1812.05913&quot;&gt;this paper&lt;/a&gt;.]&lt;/p&gt;

&lt;h2 id=&quot;reachability-of-petri-nets&quot;&gt;Reachability of Petri nets&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Petri_net&quot;&gt;Petri nets&lt;/a&gt; are very common in 
theoretical computer science, for 
example in &lt;a href=&quot;https://en.wikipedia.org/wiki/Model_checking&quot;&gt;model checking&lt;/a&gt;. 
Nevertheless, it is horribly hard to decide the reachability problem for this 
model: can you get from a configuration $A$ to a configuration $B$?
The decidability of the problem was proved only in the 80s, and the best 
upper bound is non-primitive recursive cubic-Ackermannian (don’t ask what it 
means, exponential space is already scaring me).&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://arxiv.org/pdf/1809.07115.pdf&quot;&gt;paper&lt;/a&gt; proves that the problem is 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Nonelementary_problem&quot;&gt;non-elemetary&lt;/a&gt;, that is, 
its time complexity cannot be bounded by a power tower.&lt;/p&gt;

&lt;p&gt;[The paper is 
&lt;em&gt;&lt;a href=&quot;https://arxiv.org/pdf/1809.07115.pdf&quot;&gt;The Reachability Problem for Petri Nets is Not Elementary&lt;/a&gt;&lt;/em&gt;
by &lt;a href=&quot;https://www.mimuw.edu.pl/~wczerwin/&quot;&gt;Wojciech Czerwiński&lt;/a&gt;,
&lt;a href=&quot;https://mimuw.edu.pl/~sl/&quot;&gt;Sławomir Lasota&lt;/a&gt;,
&lt;a href=&quot;https://warwick.ac.uk/fac/sci/dcs/people/ranko_lazic&quot;&gt;Ranko Lazić&lt;/a&gt;,
&lt;a href=&quot;https://www.labri.fr/perso/leroux/&quot;&gt;Jérôme Leroux&lt;/a&gt; and 
&lt;a href=&quot;https://www.labri.fr/perso/fmazowiecki/&quot;&gt;Filip Mazowiecki&lt;/a&gt;; and will appear at STOC.
In France, &lt;a href=&quot;http://www.lsv.fr/~schmitz/index.html.en&quot;&gt;Sylvain Schmitz&lt;/a&gt; is one 
of the researcher working on this kind of stratospherical complexities. 
&lt;a href=&quot;http://www.lsv.fr/~halfon/&quot;&gt;Simon Halfon&lt;/a&gt; one his PhD students at the time, 
gave an excellent talk on this topic at the 
&lt;a href=&quot;https://www.irif.fr/en/seminaires/doctorants/index&quot;&gt;IRIF PhD seminar&lt;/a&gt; in 2017.]&lt;/p&gt;

&lt;h2 id=&quot;quartet-distance-and-4-cycles&quot;&gt;Quartet distance and 4-cycles&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Quartet_distance&quot;&gt;quartet distance&lt;/a&gt; is a 
distance between phylogenetic trees. More precisely it is a distance between two 
unrooted trees with labeled leaves. It basically takes all the tuples of four 
leaves and count how many of them are in different topology in the two trees.&lt;/p&gt;

&lt;p&gt;For example in the picture below, for the two trees on the left, we want to 
decide whether the leaves $a$, $b$, $c$ and $d$ are in the same topology or not. 
We simplify the tree until we have only these leaves, and we see on the pictures
on the right&lt;br /&gt;
that it is not the case. Thus this quartet will add one to the distance. 
(Note that on the left, all leaves should be labeled, but I indicate only the 
ones we are interested in).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/quartet.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://arxiv.org/pdf/1811.06244.pdf&quot;&gt;paper&lt;/a&gt; shows that computing the 
problem of computing 
distance between two trees is equivalent to the problem of computing the number 
of 4-cycles in a graph, up to 
polylogarithmic factors. This implies better algorithms and better insights
on the complexity.&lt;/p&gt;

&lt;p&gt;[The paper is
&lt;em&gt;&lt;a href=&quot;https://arxiv.org/pdf/1811.06244.pdf&quot;&gt;Computing Quartet Distance is Equivalent to Counting 4-Cycles&lt;/a&gt;&lt;/em&gt;
 by Bartłomiej Dudek (whom I have had the chance to meet in EPFL), 
and &lt;a href=&quot;https://sites.google.com/a/cs.uni.wroc.pl/gawry/&quot;&gt;Paweł Gawrychowski&lt;/a&gt;, and 
it
will appear at STOC.]&lt;/p&gt;

</description>
        <pubDate>Wed, 13 Mar 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///stoc-socg-picks</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///stoc-socg-picks</guid>
      </item>
    
      <item>
        <title>February notes</title>
        <description>&lt;p&gt;Notes for February 2019.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/lierre.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;minorities-in-network&quot;&gt;Minorities in network&lt;/h2&gt;

&lt;p&gt;I attended a talk about minorities in network,
by &lt;a href=&quot;http://claudiawagner.info/&quot;&gt;Claudia Wagner&lt;/a&gt; at the 
&lt;a href=&quot;http://www.complexnetworks.fr/events/&quot;&gt;Complex network seminar&lt;/a&gt; of Sorbonnes 
University. 
There was a lot of content, here are a few things I noted.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Contrary to what I thought, a &lt;a href=&quot;https://en.wikipedia.org/wiki/K-core&quot;&gt;$k$-core&lt;/a&gt; 
is not another name for a $k$-clique. 
A $k$-core of a graph is a maximal connected subgraph where all the nodes have 
degree at least $k$. It can have much more nodes than just $k$
(a $k$-regular graph is its own $k$-core). Such subgraphs can be considered as 
coherent communities in social networks.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A part of the talk was about minorities in wikipedia. 
One would like to consider statements such as “women are more 
linked to other women than to men”. 
This is not true in general because there are more men pages, thus 
links have more chance to point to men, but could still be true, proportionally.
But it’s a bit too rough to just look at proportions because the graph may be 
complicated and there might be many correlations going on.
One way to deal with this is following: consider the graph of wikipedia 
bibliographies, note the global gender proportions, then erase the gender of the 
nodes, and reassign them at random, keeping the right proportions. 
Now you can compare the neighbourhoods in this new graph and in the original 
graph, and try to understand what’s going on. One paper on the topic is the following: 
&lt;a href=&quot;https://arxiv.org/pdf/1501.06307.pdf&quot;&gt;It’s a Man’s Wikipedia? Assessing Gender Inequality in an Online Encyclopedia&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A notion known as &lt;em&gt;Burt efficiency&lt;/em&gt;, or &lt;em&gt;brokerage&lt;/em&gt;, or 
&lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Structural_holes&quot;&gt;structural hole&lt;/a&gt;&lt;/em&gt;, is more or 
less the following. 
A node that belongs to (or is close to) two clusters in a 
network, can have an advantage over the other nodes,
because it can enjoy the information gathered by both communities, and 
can choose to transfer or not such information. 
One can define coefficients to measure if a node is or not in such a 
position.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;multi-stage-optimization&quot;&gt;Multi-stage optimization&lt;/h2&gt;

&lt;p&gt;For dynamic algorithms, one is usually concerned with having a good solution
 at any time, but these solutions do not need to be related.
Multi-stage optimization, introduced in 
&lt;a href=&quot;https://arxiv.org/abs/1404.3768&quot;&gt;this paper&lt;/a&gt;, considers the cases where one 
should not change the solution too much between the two steps. 
In other words, in this framework one maximizes the quality of the solution, 
while minimizing the churn.&lt;/p&gt;

&lt;p&gt;[I stumble on the notion in &lt;a href=&quot;https://arxiv.org/abs/1901.11260&quot;&gt;this preprint&lt;/a&gt;.]&lt;/p&gt;

&lt;h2 id=&quot;conjecture&quot;&gt;1-2-3 Conjecture&lt;/h2&gt;

&lt;p&gt;Another edition of the Complex Network seminar by 
&lt;a href=&quot;http://www.labri.fr/index.php?n=Annuaires.Profile&amp;amp;id=Senhaji_ID1441185629&quot;&gt;Mohammed Senhaji&lt;/a&gt; 
(that I couldn’t attend) was about the 1-2-3 conjecture, which is the following.&lt;/p&gt;

&lt;p&gt;In any graph, one can label the edges with label 1, 2, or 3, such that, when each node 
computes the sum of the labels of its adjacent labels, not two neighbours have 
the same sum.&lt;/p&gt;

&lt;p&gt;A survey about the conjecture is &lt;a href=&quot;https://arxiv.org/pdf/1211.5122.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;lovszs-new-book&quot;&gt;Lovász’s new book&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://fr.wikipedia.org/wiki/L%C3%A1szl%C3%B3_Lov%C3%A1sz&quot;&gt;László Lovász&lt;/a&gt; 
wrote a new book: 
&lt;a href=&quot;http://web.cs.elte.hu/~lovasz/bookxx/geombook2019-01-20.pdf&quot;&gt;Graphs and geometry&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;vandermonde-identity&quot;&gt;Vandermonde identity&lt;/h2&gt;

&lt;p&gt;Vandermonde’s identity is the following:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\binom{m+n}{r} = \sum_{k=0}^{r}\binom{m}{k} \binom{n}{r-k}.&lt;/script&gt;

&lt;p&gt;I thought it was only a bachelor exercise, until it naturally popped up in the 
calculation in &lt;a href=&quot;https://arxiv.org/pdf/1812.09120.pdf&quot;&gt;a recent paper&lt;/a&gt;.&lt;/p&gt;

</description>
        <pubDate>Tue, 05 Mar 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///february-2019-notes</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///february-2019-notes</guid>
      </item>
    
      <item>
        <title>Simulation argument IV. Maximal matching</title>
        <description>&lt;p&gt;This is the fourth and last post of a series about the simulation argument, that 
started with &lt;a href=&quot;./simulation-1&quot;&gt;this post&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/puzzle-4.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;In this post we tackle the maximal matching problem. 
Or actually we will show 
why establishing a lower bound for this problem is not as easy as for the 
sinkless orientation problem. 
The real lower bound is in &lt;a href=&quot;https://arxiv.org/abs/1901.02441&quot;&gt;this paper&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;encoding&quot;&gt;Encoding&lt;/h3&gt;

&lt;p&gt;A maximal matching is a set of edges of the graph, such that no two of these
edges are adjacent, and no two unmatched node are linked by an edge.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/couplage.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A natural encoding for this problem would be to label the edges of the matching 
with a label $A$, and edges not in the matching with a label $B$. 
But this does not work for our setting. 
Instead, we will do the following. 
(As in the previous post we will deal with 2-colored trees.)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The edges of the matching are labeled with the label $M$.&lt;/li&gt;
  &lt;li&gt;If a white node is not matched then its edges are labeled with $P$. 
These are pointers to matched black nodes.&lt;/li&gt;
  &lt;li&gt;The remaining edges are labeled with $O$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On the following picture, red edges are for $M$, green edges are for $P$, and 
blue edges are for $O$ (the missing edge should be blue!).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/couplage-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The languages we use are then described by the following polynomials:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$L_W = MO^{\Delta-1}+P^{\Delta}$,&lt;/li&gt;
  &lt;li&gt;$L_B = M(P+O)^{\Delta-1} + O^{\Delta}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;transformation&quot;&gt;Transformation&lt;/h2&gt;

&lt;h3 id=&quot;simulation&quot;&gt;Simulation&lt;/h3&gt;

&lt;p&gt;We perform the simulation on a black node $u$, and get a polynomial $P_u$.&lt;br /&gt;
By definition $P_u\subseteq (M+O+P)^{\Delta}$, and is factorized.&lt;/p&gt;

&lt;h3 id=&quot;product-property&quot;&gt;Product property&lt;/h3&gt;

&lt;p&gt;As the product rule applies, we know that
$P_u \subseteq M(P+0)^{\Delta-1}+O^{\Delta}$.&lt;br /&gt;
Thus there is at most one factor of $P_u$ with an $M$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Claim 1&lt;/em&gt;: This factor is either $(M)$ or $(M+O)$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof&lt;/em&gt;: Suppose the factor with $M$ has a $P$. 
Then it means that when we develop $P_u$,
there are two monomials $M\times K$ and $P\times K$, with $K$ a polynomial
of degree $\Delta-1$, that does not contain an $M$. 
But the monomial $P\times K$ is not included in 
$M(P+0)^{\Delta-1}+O^{\Delta}$. which contradicts the product property.&lt;/p&gt;

&lt;p&gt;Then we are left with 5 possible sums as factors in $P_u$: 
$(M), (O), (P), (M+O), (P+0)$.&lt;/p&gt;

&lt;p&gt;Now it seems that we cannot get much more out of our properties, so let’s try a 
simplification step.&lt;/p&gt;

&lt;h3 id=&quot;tentative-simplification-step&quot;&gt;(Tentative) Simplification step&lt;/h3&gt;

&lt;p&gt;If we can map $(M+O)$ and $(P+O)$ to a simple label, 
and still match the language, 
then we are done, and we can conclude like in the &lt;a href=&quot;./simulation-3&quot;&gt;previous post&lt;/a&gt;. 
But this is not going to happen.&lt;/p&gt;

&lt;p&gt;Suppose you are in following situation, which is supposed to be easy because 
there is not even a $(P+O)$. (On the picture, every black node writes on its 
adjacent edges.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/couplage-3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ok, let’s just take one of the two edges labeled with $M+O$
(let say the one with the smallest port-number on the white node), 
label it with $M$, label the other one with $O$, and we are done.&lt;/p&gt;

&lt;p&gt;This does notwork.
The problem is the one we highlighted in the &lt;a href=&quot;./simulation-2&quot;&gt;second post&lt;/a&gt;: 
the edges are not uniformly set-labeled by all the nodes. 
A concrete bad case:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;let $(u,v)$ and $(v,w)$ be the two edges labeled by $(M+0)$&lt;/li&gt;
  &lt;li&gt;in its simulation, $u$ has (M+O) for both edges, and based on port-numbers, 
decides that $(u,v)$ gets $M$.&lt;/li&gt;
  &lt;li&gt;in its simulation $w$ has $(M+O)$ for $(v,w)$, but only $(O)$ for $(u,v)$. Thus 
it labels $(v,w)$ with $M$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To solve this problem you have to synchronize, and this is forbidden as it takes 
extra time.&lt;/p&gt;

&lt;h2 id=&quot;no-lower-bound-this-way&quot;&gt;No lower bound this way&lt;/h2&gt;

&lt;p&gt;So at the end, we cannot conclude like in the case of sinkless orientation.&lt;/p&gt;

&lt;p&gt;Comments on that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;This makes sense: actually there is a $O(\Delta)$ 
algorithm for this problem, thus no $\Omega(\log n)$ lower bound exists.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The above alone does not prove that there is no $\Omega(\log n)$ lower 
bound: we could use another definition of the problem, or we could have tried 
more exotic label replacement ($M$ transformed into $P$, or whatever).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If you want to prove a $\Omega(\Delta)$ lower bound then you need to be 
smarter. In particular you need that, after the transformation, the language is 
different. Basically there should be a parameter that starts with something like 
$\Delta$ and decreases at each transformation. 
For that, see &lt;a href=&quot;https://arxiv.org/abs/1901.02441&quot;&gt;the paper&lt;/a&gt;!&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Fri, 15 Feb 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///simulation-4</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///simulation-4</guid>
      </item>
    
      <item>
        <title>Simulation argument III. Sinkless orientation</title>
        <description>&lt;p&gt;This is the third post of a series that starts &lt;a href=&quot;./simulation-1&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/puzzle-3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;In this post, we show how to use the simulation argument to prove a lower bound on 
the &lt;em&gt;sinkless orientation&lt;/em&gt; problem. 
This is done in the context of the &lt;a href=&quot;./simulation-2&quot;&gt;previous post&lt;/a&gt;, that is,
2-colored $\Delta$-regular trees.&lt;/p&gt;

&lt;h2 id=&quot;sinkless-orientation-encoding&quot;&gt;Sinkless orientation encoding&lt;/h2&gt;

&lt;p&gt;The sinkless orientation problem consists in orienting the edges of the graph, 
such that no node is a sink, that is, no node has only edges pointing to it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/sinkless.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In a bipartite graph, whose nodes are labeled black and white, 
it is easy to encode an orientation with edge labels: an edge is 
labeled $b$ if it is pointing to the black endpoint, and $w$ if it is pointing 
to the white endpoint.&lt;/p&gt;

&lt;p&gt;Now the languages, described as polynomials, are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$L_W=b(b+w)^{\Delta-1}$,&lt;/li&gt;
  &lt;li&gt;$L_B=w(b+w)^{\Delta-1}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Because white nodes must have an adjacent edge pointing to a black node, and 
vice-versa.&lt;/p&gt;

&lt;h2 id=&quot;transformation&quot;&gt;Transformation&lt;/h2&gt;

&lt;p&gt;We will show a very strong property: from a $T$-round algorithm for sinkless 
orientation, we can get a $(T-1)$-round algorithm for… the exact same problem 
of sinkless orientation!&lt;/p&gt;

&lt;h3 id=&quot;simulation&quot;&gt;Simulation&lt;/h3&gt;
&lt;p&gt;After one step of simulation centered at a black node $u$, the labeling of the 
edges adjacent to $u$ is described by a factorized polynomial $P_u$. 
By definition $P_u$ is included in $(w+b)^{\Delta}$.&lt;/p&gt;

&lt;h3 id=&quot;product-and-common-label-property&quot;&gt;Product and common label property&lt;/h3&gt;
&lt;p&gt;We now use the key properties to have a better upper bound on $P_u$.
Thanks to the product property, we know that $P_u\subseteq w(b+w)^{\Delta-1}$.
Now consider a white node $v$, and the set labels given by its black neighbours. 
Because of the common label property, there must at least one of its edges 
labeled with $b$, that is $P_v$ cannot be $w^{\Delta}$.
And well, that’s all we need!&lt;/p&gt;

&lt;h3 id=&quot;simplification-step&quot;&gt;Simplification step&lt;/h3&gt;
&lt;p&gt;Consider the simplification: $b+w \rightarrow b$.&lt;/p&gt;

&lt;p&gt;If we apply this simplification, we have all the edges labeled with unique 
labels (not set labels), and this labeling is correct with respect to the black 
language. In other words, after simplification, we have a polynomial $\hat{P_u}$, 
that is a monomial, and $\hat{P_u}\subseteq L_B$.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;
But what about the white nodes?
We know from the previous section that $P_v$ was not $w^{\Delta}$, thus 
$\hat{P_v}$ is not $w^{\Delta}$ either, thus $\hat{P_v}\subseteq L_W$.&lt;/p&gt;

&lt;p&gt;Thus we have a new labeling, for the exact same language, in one less round!&lt;/p&gt;

&lt;h2 id=&quot;lower-bound&quot;&gt;Lower bound&lt;/h2&gt;

&lt;p&gt;The same reasoning would work if we center the analysis on the white nodes. 
This means that from any $T$-round algorithm for sinkless orientation, we get 
down to a 0-round algorithm for sinkless orientation. 
And sinkless orientation is not a trivial language.&lt;/p&gt;

&lt;p&gt;So is sinkless orientation impossible to solve?&lt;/p&gt;

&lt;p&gt;No, remember that our lower bound technique works only up to $O(\log n)$ rounds.
Thus we have just proved an $\Omega(\log n)$ lower bound for this problem.&lt;/p&gt;

&lt;p&gt;Actually there is a $O(\log n)$ algorithm for this language, hence this bound is 
tight.&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;We always have the property that the simplification step does not destroy the correctness of the labeling on the black node, as long as we do an “hereditary” simplification, that is we replace a set of labels by a label of the set. This is because of the product property.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 13 Feb 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///simulation-3</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///simulation-3</guid>
      </item>
    
      <item>
        <title>Simulation argument II. Edge-labelings on 2-colored trees, and polynomials</title>
        <description>&lt;p&gt;This is the second post of a series that starts 
&lt;a href=&quot;https://discrete-notes.github.io/simulation-1&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/puzzle-2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;In the previous post, we saw an overview of the simulation technique. 
In this post, we are going to see a more precise and usable approach, for the case edge 
labelings on 2-colored regular trees.&lt;/p&gt;

&lt;p&gt;The explanation differs a bit from the 
&lt;a href=&quot;https://arxiv.org/abs/1901.02441&quot;&gt;original paper&lt;/a&gt;, 
because we talk about polynomials, whereas they talk about regular expressions. 
This is mainly a vocabulary change, because there is not 
much algebra going on (but it is easier for me to see it this way).&lt;/p&gt;

&lt;h2 id=&quot;arestricted-setting&quot;&gt;A restricted setting&lt;/h2&gt;
&lt;p&gt;Let us describe the special case we are interested in, and why it is relevant.&lt;/p&gt;

&lt;h3 id=&quot;delta-regular-trees&quot;&gt;$\Delta$-regular trees&lt;/h3&gt;

&lt;p&gt;We consider that we are in the middle of a $\Delta$-regular tree. Here “middle”
means that we cannot see the leaves. 
As a consequence, the method works only for the regime below time 
$\Theta(\log n)$, because in time $\Omega(\log n)$ you can always see a leaf in a 
$\Delta$-regular tree.
If we can prove a lower bound for this area of the tree, then we
have a lower bound for our problem.&lt;/p&gt;

&lt;h3 id=&quot;coloring&quot;&gt;2-coloring&lt;/h3&gt;
&lt;p&gt;We will consider graphs that are 2-colored (trees are bipartite), and we assume 
that every node knows on which side of the partition it is (black or white). So 
we work on this kind of graph (with omitted port-numbers):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/fig-delta-regulier.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This, in addition to port-numbers, is a powerful way to break symmetry between 
adjacent nodes.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;A &lt;em&gt;white algorithm&lt;/em&gt; in $k$ rounds for a problem $\Pi$ is an algorithm such that, 
after $k$ rounds the white nodes label their edges in a correct way, with 
respect to $\Pi$. 
In such an algorithm, the 
black nodes do not label the edges, they “trust” the white nodes. 
A &lt;em&gt;black algorithm&lt;/em&gt; is defined the same way, but for black nodes.&lt;/p&gt;

&lt;h2 id=&quot;encoding-of-edge-problems&quot;&gt;Encoding of edge problems&lt;/h2&gt;

&lt;h3 id=&quot;using-the-2-coloring&quot;&gt;Using the 2-coloring&lt;/h3&gt;
&lt;p&gt;We consider edge problems defined the following way. 
The multiset of edges adjacent to any vertex should follow some rule, that
depends on the color of the node. 
For example: there are three labels $a,b,c$, the white nodes should either 
have 2 edges labeled with $a$, and the rest with $c$, or 3 edges labeled with 
$a$ and the rest with $b$; and black nodes should have at least one label $a$, 
one label $b$ and one label $c$. (I just made up this example, it’s probably 
silly.)&lt;/p&gt;

&lt;p&gt;Most problems we are usually interested in are defined in general graphs, not in 
bipartite graphs, thus the problem does not refer to a coloring. 
Hence one could expect the constraints on white nodes and black nodes to be the same, 
unlike in the example above. 
Actually, it is often useful to make them different (we’ll see that in the two 
next posts).&lt;/p&gt;

&lt;h3 id=&quot;polynomial-point-of-view&quot;&gt;Polynomial point of view&lt;/h3&gt;

&lt;p&gt;We now introduce the polynomial point of view. 
Consider a node $u$ in a graph where the edges are labeled.
We can define the product of the labels of $u$ as a polynomial $M_u$, whose 
variables are the labels of the problem. 
Note that $M_u$ is a monomial: it’s just a product of labels.&lt;/p&gt;

&lt;p&gt;One can now express the toy problem above in terms of two polynomials:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$L_W(a,b,c)=a^2c^{\Delta-2}+a^3b^{\Delta-3}$&lt;/li&gt;
  &lt;li&gt;$L_B(a,b,c)=abc(a+b+c)^{\Delta-3}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We denote $P \subseteq P’$ the fact that the monomials of $P$ are all 
present in $P’$. Then the labeling of $u$ is correct for problem $\Pi$, if and only if, 
$M_u \subseteq L_{C(u)}$ (where $C(u)$ is the color of $u$).&lt;/p&gt;

&lt;p&gt;Note that, in our example, all the polynomials we play with have three variables, 
because there are three labels, and that they are homogeneous of degree 
$\Delta$, because every node has $\Delta$ adjacent edges.&lt;/p&gt;

&lt;h2 id=&quot;simulation-step-and-independence&quot;&gt;Simulation step and independence&lt;/h2&gt;

&lt;h3 id=&quot;polynomial-point-of-view-1&quot;&gt;Polynomial point of view&lt;/h3&gt;
&lt;p&gt;In the previous post, we said that the simulation step is basically about having 
a view at distance $T-1$, imagining everything that could appear in the nodes 
at distance $T$, and labeling edges with all the labels that could be correct 
in one of these extensions.&lt;/p&gt;

&lt;p&gt;Now let us restate this in terms of polynomials. 
After the simulation, every edge is labeled with a set of labels, that can be 
transfered to a sum of labels for polynomials. 
Then the polynomial associated with a set labeling at a node $u$ could be for 
example $P_u=(a+b)^3(a+b+c)^4c^{\Delta-7}$, which means that three edges are 
labeled with $a$ and $b$, four edges are labeled with $a$, $b$ and $c$ and the 
rest is labeled with only $c$. 
(This polynomial would not work for our toy language as we will see later).&lt;/p&gt;

&lt;p&gt;Note that the polynomial we get for a set labeling is not a monomial in general, 
but it is nevertheless in a factorized form.&lt;/p&gt;

&lt;h3 id=&quot;simulation-for-2-colored-trees&quot;&gt;Simulation for 2-colored trees&lt;/h3&gt;
&lt;p&gt;For 2-colored trees we can be more specific in the description of the simulation 
(and actually we will change the simulation outline a bit too).&lt;/p&gt;

&lt;p&gt;We have a white algorithm in time $T$, and we want a black algorithm 
in time $T-1$ (this will be our setting until the end of the post). 
Consider a black node $u$.
The black node $u$ will first imagine all the extensions of its $(T-1)$-view 
into a $(T+1)$-view. 
(Note that we simulate at distance $T+1$ and not just $T$, as stated in the 
previous post.) 
The black node will then simulate the run of its white neighbors with the 
algorithm in time $T$, and gather the set of labels possible for each edge.&lt;/p&gt;

&lt;p&gt;Note that we have fixed the topology to $\Delta$-regular trees, so the only 
thing to imagine for the extension is the port-number assignment.&lt;/p&gt;

&lt;h3 id=&quot;independence&quot;&gt;Independence&lt;/h3&gt;
&lt;p&gt;The key point here is the following: the $T$-view of a white 
neighbour $v$ of $u$ consists of: 
(1) the $(T-1)$-view of $u$, and 
(2) the extension of this view &lt;em&gt;in the direction of $v$&lt;/em&gt;. 
In the following picture, this means that this view includes only the 
black part and the red part.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/fig-simulation-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As a consequence when simulating node $v$, the black node does not need to 
imagine something for the other parts of its imaginary $(T+1)$-view (e.g. the blue 
parts on the figure). 
In other words the labeling of the edge $(u,v)$ comes only from the different 
version of the red part, and is independent of what happens in the blue parts. 
Obviously this independence property is true for every white neighbor of $u$, 
with its “own” extension.&lt;/p&gt;

&lt;h2 id=&quot;two-key-properties&quot;&gt;Two key properties&lt;/h2&gt;

&lt;p&gt;There are two key properties about the set labelings given by the simulation.&lt;/p&gt;

&lt;h3 id=&quot;product-property&quot;&gt;Product property&lt;/h3&gt;
&lt;p&gt;This property is about the neighborhood of the black nodes.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Claim:&lt;/em&gt;
Let $S_1, S_2, …, S_{\Delta}$ be the sets of labels that a black nodes gives 
to its adjacent edges after the
simulation step (with an arbitrary order of the edges). Then any tuple of the form
$(s_1, s_2,…, s_{\Delta})$, with $s_i\in S_i$, has to be in the language (for 
the black side).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Proof:&lt;/em&gt; Suppose it is not the case, and let $(s_1, s_2,…, s_{\Delta})$ be a 
tuple of $S_1, S_2, …, S_{\Delta}$ that is not in the language. 
Then we build an extension such that the $T$-round 
algorithm would label the edges with $(s_1, s_2,…, s_{\Delta})$, which is a 
contradiction with the correctness of the algorithm.
Start with $s_1$. 
If $s_1$ is in $S_1$ it means that there is an extension, in 
the direction of the first edge (in the figure, suppose $(u,v)$ is the first 
edge, then we are talking about the red part), such that the first edge is 
labeled with $s_1$, and we take this extension. 
But, because of the independence property stated above, we can continue with 
$s_2$, and then $s_3$ etc., which leads to the desired structure.&lt;/p&gt;

&lt;p&gt;We can restate this in terms of polynomials.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Product property:&lt;/em&gt;
$P_u \subseteq L_B$.&lt;/p&gt;

&lt;p&gt;This means that every monomial of $P_u$ has to be a monomial of $L_B$, which is
just a reformulation of the claim above.&lt;/p&gt;

&lt;h3 id=&quot;common-label-property&quot;&gt;Common label property&lt;/h3&gt;

&lt;p&gt;This property is for the neighborhoods of the white nodes. 
It is not as powerful as the previous ones, but sometimes it can be crucial.&lt;/p&gt;

&lt;p&gt;Consider a white node $w$ and two black neighbors $v_1$ and $v_2$. 
The black node $v_1$ is mostly interested in the edge $(w,v_1)$ 
(and not $(w,v_2)$), because it is the edge that matters for the product 
property, and the edge for which it is somehow “responsible”. 
But when it simulates the white algorithm on $w$, it also labels virtually 
$(w,v_2)$. 
This is getting dangerous, because the set labeling that $v_1$ and $v_2$ give to 
$(w,v_2)$ are different in general.
But they are a bit related, by the following property:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Claim:&lt;/em&gt;
Take a white node $w$.
For each edge around $w$, all the black neighbors agree on at least one label. 
That is for each edge, there is a label that is in all set labels.&lt;/p&gt;

&lt;p&gt;This label is simply the one that the white node would give if it were running&lt;br /&gt;
the $T$-round algorithm in the real graph (not a simulated one).&lt;/p&gt;

&lt;h2 id=&quot;typical-transformation-step&quot;&gt;Typical transformation step&lt;/h2&gt;

&lt;p&gt;The typical way to prove that one has a transformation from an algorithm in $T$ 
rounds for a problem $\Pi$, to an algorithm in $T-1$ rounds for a problem $\Pi’$,
is the following.&lt;/p&gt;

&lt;p&gt;First make the simulation. 
In our example, we know that the black node $u$ gets a polynomial included in 
$(a+b+c)^{\Delta}$. 
But this is a very rough over-approximation, and $P_u$ is probably much smaller. 
Then one can use the two key properties to rule out many labelings and have a 
more precise idea of what $P_u$ is. 
Once this is done, we can go for a simplification step: replace sets of labels by labels. 
If everything works fine you have a labeling that is correct for your problem 
$\Pi’$.&lt;/p&gt;

&lt;h2 id=&quot;subtleties&quot;&gt;Subtleties&lt;/h2&gt;
&lt;p&gt;There are two subtleties that blocked me at some point.&lt;/p&gt;

&lt;p&gt;The first one is this danger I warned you about in the common label property 
section: an edge is labeled differently in different simulations.&lt;/p&gt;

&lt;p&gt;The second is that in this 2-colored framework, it is not enough to have a 
general way to 
go from a white $T$-round algorithm to a black $(T-1)$-round algorithm, you also 
need to go from a black algorithm to a white algorithm. In some cases, the two 
are very different.&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Indeed &lt;a href=&quot;https://users.ics.aalto.fi/suomela/mm-lb/&quot;&gt;previous lower bound techniques&lt;/a&gt; cannot work in the 2-colored model.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 12 Feb 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///simulation-2</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///simulation-2</guid>
      </item>
    
      <item>
        <title>Simulation argument I. General technique</title>
        <description>&lt;p&gt;As
&lt;a href=&quot;https://discrete-notes.github.io/january-2019-notes&quot;&gt;said earlier&lt;/a&gt; 
on this blog, a 
&lt;a href=&quot;https://arxiv.org/abs/1901.02441&quot;&gt;recent preprint&lt;/a&gt; 
proves a set of long-expected lower bounds for distributed graph algorithms. 
This post is the first of a (short) series of (short) posts about the basics of 
this paper.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;assets/puzzle-1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;a-series-of-posts&quot;&gt;A series of posts&lt;/h2&gt;

&lt;p&gt;In this first post we give an overview of the &lt;em&gt;simulation argument&lt;/em&gt;, which is 
the framework used for the lower bound.&lt;/p&gt;

&lt;p&gt;The next posts will be about:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;specific construction for edge labelings on bicolored trees&lt;/li&gt;
  &lt;li&gt;Example 1: sinkless orientation&lt;/li&gt;
  &lt;li&gt;Example 2: maximal matching&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most of the content of this series is probably better explained in the 
preprint cited above, so you may want to look at it instead of these posts! 
The main difference will appear in the second post where I propose a slightly 
different vocabulary, based on polynomials. The posts assume familiarity with 
the local model.&lt;/p&gt;

&lt;h3 id=&quot;a-few-bits-of-context&quot;&gt;A few bits of context&lt;/h3&gt;

&lt;p&gt;The simulation technique can be traced back to Linial, 
and his $\Omega(\log^*n)$ lower bound for coloring.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;
However, it did a come-back with 
&lt;a href=&quot;https://arxiv.org/pdf/1511.00900.pdf&quot;&gt;a 2015 paper&lt;/a&gt; that had a different point 
of view. 
It was then simplified and improved.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 
The technique was an important part of 
&lt;a href=&quot;http://adga.hiit.fi/2017/hirvonen.pdf&quot;&gt;the talk of Juho Hirvonen&lt;/a&gt; 
at the 
&lt;a href=&quot;http://adga.hiit.fi/2017/&quot;&gt;2017 ADGA workshop&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;overview-of-the-simulation-argument&quot;&gt;Overview of the simulation argument&lt;/h2&gt;

&lt;p&gt;The core question of the simulation argument is the following. 
Suppose that in time $T$ you can solve a problem. 
Then what can you solve if you have only $T-1$ rounds? 
For example, if you can solve coloring with $c$ colors in $T$ rounds, can you 
solve coloring with $2^c$ colors (which is easier) is $T-1$ rounds?
For lower bounds, the basic line of reasoning is the following.&lt;/p&gt;

&lt;h3 id=&quot;base-step-0-rounds&quot;&gt;Base step: 0 rounds&lt;/h3&gt;
&lt;p&gt;Fix a problem $P$.
Suppose you have a way to do the following transformation.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Start with:&lt;/em&gt;&lt;br /&gt;
an algorithm $A$ in $T$ rounds for a problem $P$. &lt;br /&gt;
&lt;em&gt;Change it into:&lt;/em&gt; 
an algorithm $A’$ in $T-1$ rounds for another problem $P’$.&lt;/p&gt;

&lt;p&gt;Then, say you want to prove that solving $P$ requires more than one
round. 
Then you only need to prove that you have a transformation as above, with $T=1$, 
and that $P’$ is not trivial (that is, to prove that 
$P’$ cannot be solved in zero round).
Indeed if there is an algorithm in one round for $P$, then you can transform it 
into an algorithm in 0 round for $P’$, which would contradict the 
non-triviality of $P’$. 
At this point, you know that $P$ requires at least two rounds. 
This may sound silly as we have just moved the difficulty from one problem to
another: for this technique to work, we need to be able to prove that $P’$ is 
non-trivial. But this is usually much simpler.&lt;/p&gt;

&lt;h3 id=&quot;induction&quot;&gt;Induction&lt;/h3&gt;
&lt;p&gt;Lower bounds of one rounds are not super exciting, and one would like to prove
bounds of $k+1$ rounds, for some $k$. 
The argument goes the following way.
For the sake of contradiction, suppose there is an algorithm in $k$ rounds for 
your problem $P$.
Now you prove that there exists a family of problems $P_0, P_1, P_2, …,P_k$, with 
$P_0=P$, such that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;none of them is trivial&lt;/li&gt;
  &lt;li&gt;given an algorithm for $P_i$ in $k-i$ rounds, you can transform it into an 
algorithm in $k-i-1$ rounds for $P_{i+1}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second bullet implies that $P_k$ can be solved in $0$ rounds, which impossible 
because the first bullet states that it is non-trivial. 
Thus $P$ needs at least $k+1$ rounds.&lt;/p&gt;

&lt;h3 id=&quot;simulation-argument&quot;&gt;Simulation argument&lt;/h3&gt;
&lt;p&gt;The question now: how do you define a transformation from one problem to another? &lt;br /&gt;
Suppose you know an algorithm in $T$ rounds, but you have only a view of 
$T-1$ rounds. Then you can do the following.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Imagine all the possible ways your $(T-1)$-neighborhood could be extended to a 
$T$-neighborhood.&lt;/li&gt;
  &lt;li&gt;Compute a solution for each of these extensions, using your $T$-round algorithm.&lt;/li&gt;
  &lt;li&gt;Label your node/edges with the set of all the labels that the T-round algorithm
would use in at least one of these extensions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Obviously you are not solving the original problem because you are labeling your
node/edges with sets of labels, instead of labeling them with only one label. 
Also this labeling may be uninteresting: every node/edge could be labeled with 
all the possible labels. 
But maybe it &lt;em&gt;is&lt;/em&gt; interesting. 
And then you may be able to define a non-trivial problem $P’$ 
(probably a quite artificial problem but it’s ok) such that this set-labeling 
is a proper labeling for $P’$.&lt;/p&gt;

&lt;h3 id=&quot;simplification-step&quot;&gt;Simplification step&lt;/h3&gt;
&lt;p&gt;You may also want to have a simplification step. 
This is a step that you perform after you have labeled your nodes/edges with 
sets of labels.
The goal is to simplify the proof, by replacing the sets of labels by something 
simpler, typically simple labels. For example you decide that every set of labels 
{$a,b$} is replaced by $a$. For this step to be useful you need that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;one can compute the simplification without further communication (e.g. no 
synchronization with neighbors)&lt;/li&gt;
  &lt;li&gt;the new labels fit into a language that has good properties, in particular, it 
is not trivial.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;The simulation argument appears more clearly in the &lt;a href=&quot;https://users.ics.aalto.fi/suomela/doc/linial-easy.pdf&quot;&gt;modern version of the proof&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;See &lt;a href=&quot;https://arxiv.org/abs/1902.09958&quot;&gt;this recent note&lt;/a&gt; by &lt;a href=&quot;https://disco.ethz.ch/alumni/brandts&quot;&gt;Sebastian Brandt&lt;/a&gt; that formalizes precisely the approach.&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 11 Feb 2019 00:00:00 +0100</pubDate>
        <link>https://discrete-notes.github.io///simulation-1</link>
        <guid isPermaLink="true">https://discrete-notes.github.io///simulation-1</guid>
      </item>
    
  </channel>
</rss>
