---
layout: post
title: January notes
redirect_from: "/2019/01/30/january-2019-notes/"
permalink: january-2019-notes
---

A few notes for January 2019.

---

## Maximal matching lower bound

They did it! A key problem of distributed computing on graphs has 
been solved by a team supervised by
[Jukka Suomela](https://users.ics.aalto.fi/suomela/). 
[The preprint](https://arxiv.org/abs/1901.02441) has been 
uploaded to arxiv recently, and is not reviewed yet, so this should be taken 
with a grain of salt, but given the authors list, and what I have read of the 
paper, there is little doubt it is correct. 

The setting can be explain with the following setting: there are jobs available 
and people looking for jobs, such that each job has at most $\Delta$ condidates, 
and each person has at most $\Delta$ jobs he or she is interested in. 
There is no central entity, so the decision have to be taken based on communication 
between the "jobs" and the people. 
At the end, we want that every person
either has been assigned a job, or all the jobs (s)he was intersted in have be 
assiged to someone else, and every job is either assigned to someone, or all the 
candidates have been assigned a job. 
Note that there is no preference list, and 
this problem would be very easy if we had a central entity managing the job 
market. 

A strategy to solve the problem is the following: first every person choose a 
job among the ones it has selected and sends a message to this job, second the 
"jobs" choose one of the persons that have send a message to it (if any). 
After this first round, some people and jobs are already matched, and they leave the 
game. 
The other jobs and persons continue, until have reached a situation as 
described above.
This strategy requires $O(\Delta)$ phases. The new result tells us
that this is basically optimal.

## Search vs decision

My PhD was about distributed decision, and a sentence that often appears in 
papers on this topic is some variation of "unlike in the centralized setting,
search and decision are very different in the distributed setting". This makes
me a bit uncomfortable because I don't have a very strong statement to support 
the claim that in centralized computing these are quite similar.

Lance Fortnow 
[blogged about this](https://blog.computationalcomplexity.org/2019/01/search-versus-decision.html) 
early this month.

## Fragile complexity

An interesting recent line of research is to go "beyond worst-case complexity", 
that is to consider other measures of complexity/efficiency than the time on the
worst input, as the later can be inadequate for many purposes.
There are very nice concepts there, such as the 
[smoothed complexity](https://en.wikipedia.org/wiki/Smoothed_analysis). 
See also the [top 10 ideas](http://timroughgarden.org/f14/l/top10.pdf) in this 
area, by [Tim Roughgarden](http://timroughgarden.org/).

A new measure was introduced in 
[an arxiv preprint](https://export.arxiv.org/abs/1901.02857) this month: fragile 
complexity. I just read the abstract, and I don't know why it is called 'fragile', 
but I understand the definition for sorting: the fragile complexity of a sorting
algorithm is the maximal number of comparisons that an element of the list can 
be part of.

## LIPIcs without logos 

I like LIPIcs latex class, that is now used for many conferences (the ones that 
switched to open acces, which is itself a very nice thing). 
I would like to use 
it for my preprints (because it looks nice, and because if the conference is in 
lipics, it avoids extra-work). One problem is that preprints should not have the
official lipics logos, and other feature that are relevant only for conference 
publications. 
Following the example of a collegue, I used to use a modified version of the 
class file. This is not useful anymore: the class now provide a command 
\hideLIPIcs that hides the irrelevant features. (See the
[authors guidelines](http://drops.dagstuhl.de/styles/lipics-v2019/lipics-v2019-authors/lipics-v2019-authors-guidelines.pdf), 
page 8.)

## PAC learning and deep learning

It seems that deep learning is becoming popular among almost everybody (at least 
from a scientific point of view), except theoretical computer scientists, who 
critize it for its lack of proven garantees (on diverse aspects). As a reaction, 
there are several efforts to better understand ML from a theoretical point of 
view (for example [Alexander MÄ…dry's group](http://people.csail.mit.edu/madry/lab/)
and the [ML thoery group at Princeton](http://mltheory.cs.princeton.edu/). 

The month in the theory dish blog, Amit Daniely and Roy Frostig 
[blog about](https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/)
the performances of deep learning on well-defined theoretical tasks in the 
context of [PAC learning](https://en.wikipedia.org/wiki/Probably_approximately_correct_learning).

Incidentally, Leslie Valiant published a [book](http://www.probablyapproximatelycorrect.com/)
about PAC learning (that he designed), and its realtion with nature and evolution.

## Wind turbines, machine learning and algorithms

Lance Fortnow aslo [bloged about wind turbines and ML](https://blog.computationalcomplexity.org/2019/01/machine-learning-and-wind-turbines.html).

Basically, a problem for wind turbines is to predict sudden change of the wind, 
that could cause damage. One could use complex fluid simulations, but these are 
slow therefore there is an increasing trend in using ML for these predictions.

So there is a way to make things in a "deterministic" well-defined way, but one 
prefers the ML version that is quicker. 
This reminds me of a 
[stack exchange topic](https://cstheory.stackexchange.com/questions/38095/if-machine-learning-techniques-keep-improving-whats-the-role-of-algorithmics-i)
that was basically asking: will algorithms be really useful in the future, knowing
that most of the time we are interested in "good enough" solution, and that we 
don't even want some approximation garantees, or even worse, we want solutions 
that are good, with the definition of good given only by examples. Unfortunately 
there were not many answers...

## Power diagrams to represents fluids

[11011110 blog](https://11011110.github.io/blog/2019/01/15/linkage.html) links 
to
[nice fluid simulations](https://twitter.com/BrunoLevy01/status/1080085027210309632)
using [power diagram](https://en.wikipedia.org/wiki/Power_diagram), 
to picture units of fluid. Power diagrams are generalizations of 
[Voronoi diagrams](https://en.wikipedia.org/wiki/Voronoi_diagram) but special 
cases of [weighted Voronoi diagrams](https://en.wikipedia.org/wiki/Weighted_Voronoi_diagram).

## Order types

Suppose you have a configuration with four points in the plane, usch that no 
three of them are alligned. Then, either all the points are extreme points, and 
they form a kind of quadrilateral, or there are three points forming a triangle, 
and the last point is in the triangle. These two cases are called the order types.

There was a [paper at SODA 2019](https://epubs.siam.org/doi/10.1137/1.9781611975482.27)
about this topic.

